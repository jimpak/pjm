{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "x_data = [[0,0],[0,1],[1,0],[1,1]]\n",
    "t_data_and= [[0],[0],[0],[1]]\n",
    "t_data_or= [[0],[1],[1],[1]]\n",
    "t_data_nand= [[1],[1],[1],[0]]\n",
    "t_data_xor= [[0],[1],[1],[0]]\n",
    "\n",
    "x_train=torch.FloatTensor(x_data)\n",
    "t_train_and=torch.FloatTensor(t_data_and)\n",
    "t_train_or=torch.FloatTensor(t_data_or)\n",
    "t_train_nand=torch.FloatTensor(t_data_nand)\n",
    "t_train_xor=torch.FloatTensor(t_data_xor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logic_func(x_train,t_train):\n",
    "    model=nn.Sequential(\n",
    "    nn.Linear(2,1),\n",
    "    nn.Sigmoid())\n",
    "\n",
    "    optimizer=optim.SGD(model.parameters(), lr=0.1)\n",
    "    epochs=1001\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        h=model(x_train)\n",
    "        cost=F.binary_cross_entropy(h, t_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch%100==0:\n",
    "            print(epoch, cost.item())\n",
    "\n",
    "    result=model(x_train)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7152550220489502\n",
      "100 0.34177976846694946\n",
      "200 0.2663002908229828\n",
      "300 0.21686872839927673\n",
      "400 0.182096928358078\n",
      "500 0.15643197298049927\n",
      "600 0.1367729753255844\n",
      "700 0.12127205729484558\n",
      "800 0.1087634488940239\n",
      "900 0.09847612679004669\n",
      "1000 0.08988014608621597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_or=logic_func(x_train, t_train_or)\n",
    "result_or=(result_or>=torch.FloatTensor([0.5])).float()\n",
    "result_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6943425536155701\n",
      "100 0.4643380045890808\n",
      "200 0.36436447501182556\n",
      "300 0.30256763100624084\n",
      "400 0.260067880153656\n",
      "500 0.22866642475128174\n",
      "600 0.20430675148963928\n",
      "700 0.18474730849266052\n",
      "800 0.16863781213760376\n",
      "900 0.15510861575603485\n",
      "1000 0.14356935024261475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_nand=logic_func(x_train, t_train_nand)\n",
    "result_nand=(result_nand>=torch.FloatTensor([0.5])).float()\n",
    "result_nand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.612721860408783\n",
      "100 0.5063209533691406\n",
      "200 0.4261166751384735\n",
      "300 0.36447468400001526\n",
      "400 0.31626197695732117\n",
      "500 0.2779186964035034\n",
      "600 0.2469417005777359\n",
      "700 0.22154879570007324\n",
      "800 0.20045380294322968\n",
      "900 0.1827157437801361\n",
      "1000 0.16763582825660706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=[]\n",
    "for i in range(result_or.size(0)):\n",
    "    input.append([result_or[i][0].item(), result_nand[i][0].item()])\n",
    "    \n",
    "x_train=torch.FloatTensor(input)\n",
    "xor_result=logic_func(x_train, t_train_xor)\n",
    "xor_result=(xor_result>=torch.FloatTensor([0.5])).float()\n",
    "xor_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
