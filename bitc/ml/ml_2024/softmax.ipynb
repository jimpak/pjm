{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "z=torch.FloatTensor([1,2,3])\n",
    "y_hat=F.softmax(z, dim=0)\n",
    "print(y_hat)\n",
    "print(y_hat.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1768, 0.8248, 0.8036, 0.9434, 0.2197],\n",
      "        [0.4177, 0.4903, 0.5730, 0.1205, 0.1452],\n",
      "        [0.7720, 0.3828, 0.7442, 0.5285, 0.6642]], requires_grad=True)\n",
      "tensor([[0.1253, 0.2396, 0.2345, 0.2698, 0.1308],\n",
      "        [0.2106, 0.2265, 0.2460, 0.1565, 0.1604],\n",
      "        [0.2308, 0.1564, 0.2245, 0.1810, 0.2073]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z=torch.rand(3,5,requires_grad=True)\n",
    "y_hat=F.softmax(z, dim=1)\n",
    "print(z)\n",
    "print(y_hat)\n",
    "print(y_hat.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 0, 4])\n",
      "tensor([[0.1253, 0.2396, 0.2345, 0.2698, 0.1308],\n",
      "        [0.2106, 0.2265, 0.2460, 0.1565, 0.1604],\n",
      "        [0.2308, 0.1564, 0.2245, 0.1810, 0.2073]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[3],\n",
      "        [0],\n",
      "        [4]])\n",
      "tensor([[0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "y=torch.randint(5,(3,)).long()\n",
    "print(y)\n",
    "print(y_hat)\n",
    "y_one_hot=torch.zeros_like(y_hat)\n",
    "print(y_one_hot)\n",
    "print(y.unsqueeze(1))\n",
    "y_one_hot.scatter_(1,y.unsqueeze(1),1)\n",
    "print(y_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "x_data=[[1,2,1,1],\n",
    "        [2,1,3,2],\n",
    "        [3,1,3,4],\n",
    "        [4,1,5,5],\n",
    "        [1,7,5,5],\n",
    "        [1,2,5,6],\n",
    "        [1,6,6,6],\n",
    "        [1,7,7,7]]\n",
    "y_data=[2,2,2,1,1,1,0,0]\n",
    "\n",
    "x_train=torch.FloatTensor(x_data)\n",
    "y_train=torch.LongTensor(y_data)\n",
    "print(x_train.size())\n",
    "print(y_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y_one_hot=torch.zeros(8,3)\n",
    "y_one_hot.scatter_(1,y_train.unsqueeze(1),1)\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], requires_grad=True)\n",
      "tensor([[0., 0., 0.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w=torch.zeros((4,3), requires_grad=True)\n",
    "b=torch.zeros((1,3), requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 cost: 1.0986123085021973\n",
      "epoch: 100 cost: 0.7041996121406555\n",
      "epoch: 200 cost: 0.6229995489120483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 300 cost: 0.5657169222831726\n",
      "epoch: 400 cost: 0.5152913331985474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\it\\AppData\\Local\\Temp\\ipykernel_1564\\4218742925.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_hat=F.softmax(x_train.matmul(w)+b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 500 cost: 0.467661589384079\n",
      "epoch: 600 cost: 0.4212779700756073\n",
      "epoch: 700 cost: 0.37540146708488464\n",
      "epoch: 800 cost: 0.3297656178474426\n",
      "epoch: 900 cost: 0.2850724160671234\n",
      "epoch: 1000 cost: 0.24815461039543152\n",
      "epoch: 1100 cost: 0.23267605900764465\n",
      "epoch: 1200 cost: 0.22139872610569\n",
      "epoch: 1300 cost: 0.2111290991306305\n",
      "epoch: 1400 cost: 0.2017364501953125\n",
      "epoch: 1500 cost: 0.19311320781707764\n",
      "epoch: 1600 cost: 0.18516962230205536\n",
      "epoch: 1700 cost: 0.177829310297966\n",
      "epoch: 1800 cost: 0.17102722823619843\n",
      "epoch: 1900 cost: 0.16470743715763092\n",
      "epoch: 2000 cost: 0.1588211953639984\n",
      "epoch: 2100 cost: 0.15332652628421783\n",
      "epoch: 2200 cost: 0.14818623661994934\n",
      "epoch: 2300 cost: 0.1433679759502411\n",
      "epoch: 2400 cost: 0.13884282112121582\n",
      "epoch: 2500 cost: 0.13458563387393951\n",
      "epoch: 2600 cost: 0.1305735558271408\n",
      "epoch: 2700 cost: 0.126786470413208\n",
      "epoch: 2800 cost: 0.12320637702941895\n",
      "epoch: 2900 cost: 0.11981715261936188\n",
      "epoch: 3000 cost: 0.1166040301322937\n",
      "epoch: 3100 cost: 0.11355400085449219\n",
      "epoch: 3200 cost: 0.11065523326396942\n",
      "epoch: 3300 cost: 0.10789673775434494\n",
      "epoch: 3400 cost: 0.10526889562606812\n",
      "epoch: 3500 cost: 0.10276288539171219\n",
      "epoch: 3600 cost: 0.1003703624010086\n",
      "epoch: 3700 cost: 0.09808401763439178\n",
      "epoch: 3800 cost: 0.09589691460132599\n",
      "epoch: 3900 cost: 0.09380307793617249\n",
      "epoch: 4000 cost: 0.09179650992155075\n",
      "epoch: 4100 cost: 0.08987216651439667\n",
      "epoch: 4200 cost: 0.0880250483751297\n",
      "epoch: 4300 cost: 0.08625070005655289\n",
      "epoch: 4400 cost: 0.08454480022192001\n",
      "epoch: 4500 cost: 0.08290372043848038\n",
      "epoch: 4600 cost: 0.08132388442754745\n",
      "epoch: 4700 cost: 0.07980190217494965\n",
      "epoch: 4800 cost: 0.07833455502986908\n",
      "epoch: 4900 cost: 0.07691936194896698\n",
      "epoch: 5000 cost: 0.07555314153432846\n",
      "epoch: 5100 cost: 0.07423388212919235\n",
      "epoch: 5200 cost: 0.07295890152454376\n",
      "epoch: 5300 cost: 0.07172627747058868\n",
      "epoch: 5400 cost: 0.07053367048501968\n",
      "epoch: 5500 cost: 0.06937956809997559\n",
      "epoch: 5600 cost: 0.06826180964708328\n",
      "epoch: 5700 cost: 0.06717897951602936\n",
      "epoch: 5800 cost: 0.06612923741340637\n",
      "epoch: 5900 cost: 0.06511133909225464\n",
      "epoch: 6000 cost: 0.06412373483181\n",
      "epoch: 6100 cost: 0.06316520273685455\n",
      "epoch: 6200 cost: 0.062234364449977875\n",
      "epoch: 6300 cost: 0.06133011728525162\n",
      "epoch: 6400 cost: 0.06045139208436012\n",
      "epoch: 6500 cost: 0.059597041457891464\n",
      "epoch: 6600 cost: 0.05876612663269043\n",
      "epoch: 6700 cost: 0.05795775726437569\n",
      "epoch: 6800 cost: 0.05717095732688904\n",
      "epoch: 6900 cost: 0.05640485882759094\n",
      "epoch: 7000 cost: 0.05565883219242096\n",
      "epoch: 7100 cost: 0.0549318864941597\n",
      "epoch: 7200 cost: 0.05422351509332657\n",
      "epoch: 7300 cost: 0.053532786667346954\n",
      "epoch: 7400 cost: 0.05285930633544922\n",
      "epoch: 7500 cost: 0.05220220237970352\n",
      "epoch: 7600 cost: 0.051561079919338226\n",
      "epoch: 7700 cost: 0.050935324281454086\n",
      "epoch: 7800 cost: 0.05032433569431305\n",
      "epoch: 7900 cost: 0.04972760006785393\n",
      "epoch: 8000 cost: 0.04914465919137001\n",
      "epoch: 8100 cost: 0.04857514053583145\n",
      "epoch: 8200 cost: 0.04801830276846886\n",
      "epoch: 8300 cost: 0.047474123537540436\n",
      "epoch: 8400 cost: 0.04694186896085739\n",
      "epoch: 8500 cost: 0.04642133414745331\n",
      "epoch: 8600 cost: 0.0459119938313961\n",
      "epoch: 8700 cost: 0.045413628220558167\n",
      "epoch: 8800 cost: 0.04492580145597458\n",
      "epoch: 8900 cost: 0.04444821923971176\n",
      "epoch: 9000 cost: 0.04398063197731972\n",
      "epoch: 9100 cost: 0.04352262616157532\n",
      "epoch: 9200 cost: 0.043073881417512894\n",
      "epoch: 9300 cost: 0.04263424873352051\n",
      "epoch: 9400 cost: 0.042203307151794434\n",
      "epoch: 9500 cost: 0.041780974715948105\n",
      "epoch: 9600 cost: 0.041366904973983765\n",
      "epoch: 9700 cost: 0.040960900485515594\n",
      "epoch: 9800 cost: 0.040562596172094345\n",
      "epoch: 9900 cost: 0.04017191380262375\n",
      "epoch: 10000 cost: 0.03978875279426575\n"
     ]
    }
   ],
   "source": [
    "optimizer=optim.SGD([w,b],lr=0.1)\n",
    "epochs=10001\n",
    "for epoch in range(epochs):\n",
    "    y_hat=F.softmax(x_train.matmul(w)+b)\n",
    "    cost=(y_one_hot* -torch.log(y_hat)).sum(dim=1).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%100 == 0:\n",
    "        print('epoch:',epoch, 'cost:',cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "tensor([[7.9508e-11, 6.5691e-06, 9.9999e-01],\n",
      "        [1.7811e-04, 1.9474e-02, 9.8035e-01],\n",
      "        [1.1671e-13, 4.1809e-02, 9.5819e-01],\n",
      "        [6.1380e-10, 9.6248e-01, 3.7520e-02],\n",
      "        [7.2622e-02, 9.2453e-01, 2.8516e-03],\n",
      "        [3.8537e-02, 9.6146e-01, 7.0805e-08],\n",
      "        [9.1230e-01, 8.7704e-02, 8.1008e-08],\n",
      "        [9.9212e-01, 7.8797e-03, 5.7660e-11]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_hat = F.softmax(x_train.matmul(w)+b, dim=1)\n",
    "print(y_one_hot)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for y in y_hat:\n",
    "    print(y.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.Linear(4,3) #input_dim, output_dim\n",
    "optimizer=optim.SGD(model.parameters(), lr=0.1)\n",
    "epochs=10001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 cost: 1.6167852878570557\n",
      "epoch: 100 cost: 0.6588907837867737\n",
      "epoch: 200 cost: 0.5734435319900513\n",
      "epoch: 300 cost: 0.5181514620780945\n",
      "epoch: 400 cost: 0.47326555848121643\n",
      "epoch: 500 cost: 0.4335159659385681\n",
      "epoch: 600 cost: 0.3965631425380707\n",
      "epoch: 700 cost: 0.3609141409397125\n",
      "epoch: 800 cost: 0.32539206743240356\n",
      "epoch: 900 cost: 0.2891784608364105\n",
      "epoch: 1000 cost: 0.25414785742759705\n",
      "epoch: 1100 cost: 0.23497334122657776\n",
      "epoch: 1200 cost: 0.2234925627708435\n",
      "epoch: 1300 cost: 0.21305325627326965\n",
      "epoch: 1400 cost: 0.20350946485996246\n",
      "epoch: 1500 cost: 0.1947513222694397\n",
      "epoch: 1600 cost: 0.18668678402900696\n",
      "epoch: 1700 cost: 0.1792379468679428\n",
      "epoch: 1800 cost: 0.1723378747701645\n",
      "epoch: 1900 cost: 0.16592955589294434\n",
      "epoch: 2000 cost: 0.15996335446834564\n",
      "epoch: 2100 cost: 0.1543959081172943\n",
      "epoch: 2200 cost: 0.14918915927410126\n",
      "epoch: 2300 cost: 0.14431045949459076\n",
      "epoch: 2400 cost: 0.1397300362586975\n",
      "epoch: 2500 cost: 0.13542188704013824\n",
      "epoch: 2600 cost: 0.1313631236553192\n",
      "epoch: 2700 cost: 0.12753306329250336\n",
      "epoch: 2800 cost: 0.12391334027051926\n",
      "epoch: 2900 cost: 0.12048745155334473\n",
      "epoch: 3000 cost: 0.11724034696817398\n",
      "epoch: 3100 cost: 0.11415877938270569\n",
      "epoch: 3200 cost: 0.11123072355985641\n",
      "epoch: 3300 cost: 0.10844486951828003\n",
      "epoch: 3400 cost: 0.10579172521829605\n",
      "epoch: 3500 cost: 0.10326192528009415\n",
      "epoch: 3600 cost: 0.10084722191095352\n",
      "epoch: 3700 cost: 0.09854000806808472\n",
      "epoch: 3800 cost: 0.09633366763591766\n",
      "epoch: 3900 cost: 0.09422149509191513\n",
      "epoch: 4000 cost: 0.09219781309366226\n",
      "epoch: 4100 cost: 0.09025732427835464\n",
      "epoch: 4200 cost: 0.08839484304189682\n",
      "epoch: 4300 cost: 0.08660610765218735\n",
      "epoch: 4400 cost: 0.08488684892654419\n",
      "epoch: 4500 cost: 0.08323303610086441\n",
      "epoch: 4600 cost: 0.08164102584123611\n",
      "epoch: 4700 cost: 0.08010748028755188\n",
      "epoch: 4800 cost: 0.07862938940525055\n",
      "epoch: 4900 cost: 0.07720369100570679\n",
      "epoch: 5000 cost: 0.07582788914442062\n",
      "epoch: 5100 cost: 0.07449928671121597\n",
      "epoch: 5200 cost: 0.07321549206972122\n",
      "epoch: 5300 cost: 0.07197430729866028\n",
      "epoch: 5400 cost: 0.07077387720346451\n",
      "epoch: 5500 cost: 0.06961195915937424\n",
      "epoch: 5600 cost: 0.0684870034456253\n",
      "epoch: 5700 cost: 0.06739715486764908\n",
      "epoch: 5800 cost: 0.0663408413529396\n",
      "epoch: 5900 cost: 0.0653165727853775\n",
      "epoch: 6000 cost: 0.06432292610406876\n",
      "epoch: 6100 cost: 0.06335850059986115\n",
      "epoch: 6200 cost: 0.06242213770747185\n",
      "epoch: 6300 cost: 0.061512578278779984\n",
      "epoch: 6400 cost: 0.060628730803728104\n",
      "epoch: 6500 cost: 0.059769466519355774\n",
      "epoch: 6600 cost: 0.05893383547663689\n",
      "epoch: 6700 cost: 0.05812102556228638\n",
      "epoch: 6800 cost: 0.05732985958456993\n",
      "epoch: 6900 cost: 0.05655966326594353\n",
      "epoch: 7000 cost: 0.05580947920680046\n",
      "epoch: 7100 cost: 0.05507877841591835\n",
      "epoch: 7200 cost: 0.05436654016375542\n",
      "epoch: 7300 cost: 0.053672417998313904\n",
      "epoch: 7400 cost: 0.05299534276127815\n",
      "epoch: 7500 cost: 0.052335064858198166\n",
      "epoch: 7600 cost: 0.051690682768821716\n",
      "epoch: 7700 cost: 0.05106173828244209\n",
      "epoch: 7800 cost: 0.05044780671596527\n",
      "epoch: 7900 cost: 0.04984816536307335\n",
      "epoch: 8000 cost: 0.04926251992583275\n",
      "epoch: 8100 cost: 0.048690199851989746\n",
      "epoch: 8200 cost: 0.04813084006309509\n",
      "epoch: 8300 cost: 0.047584112733602524\n",
      "epoch: 8400 cost: 0.04704945534467697\n",
      "epoch: 8500 cost: 0.046526599675416946\n",
      "epoch: 8600 cost: 0.046014949679374695\n",
      "epoch: 8700 cost: 0.045514386147260666\n",
      "epoch: 8800 cost: 0.045024432241916656\n",
      "epoch: 8900 cost: 0.04454474523663521\n",
      "epoch: 9000 cost: 0.044075168669223785\n",
      "epoch: 9100 cost: 0.0436151921749115\n",
      "epoch: 9200 cost: 0.043164655566215515\n",
      "epoch: 9300 cost: 0.04272312670946121\n",
      "epoch: 9400 cost: 0.04229043796658516\n",
      "epoch: 9500 cost: 0.041866473853588104\n",
      "epoch: 9600 cost: 0.04145070165395737\n",
      "epoch: 9700 cost: 0.04104295372962952\n",
      "epoch: 9800 cost: 0.04064316675066948\n",
      "epoch: 9900 cost: 0.04025104641914368\n",
      "epoch: 10000 cost: 0.03986620903015137\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    y_hat=model(x_train)\n",
    "    cost=F.cross_entropy(y_hat, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%100 == 0:\n",
    "        print('epoch:',epoch, 'cost:',cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-11.4190,  -0.1089,  11.8240],\n",
      "        [ -4.3004,   0.4548,   4.3716],\n",
      "        [-18.3870,   8.3334,  11.4634],\n",
      "        [-12.6072,   8.7538,   5.5110],\n",
      "        [  0.9640,   3.5059,  -2.2739],\n",
      "        [  4.2154,   7.4301,  -9.0254],\n",
      "        [  7.0721,   4.7320,  -9.1733],\n",
      "        [ 10.5025,   5.6715, -13.0728]], grad_fn=<AddmmBackward0>)\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "prediction=model(x_train)\n",
    "print(prediction)\n",
    "for pred in prediction:\n",
    "    print(pred.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(4,3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 cost: 2.637636423110962\n",
      "epoch: 100 cost: 0.6479030251502991\n",
      "epoch: 200 cost: 0.5646426677703857\n",
      "epoch: 300 cost: 0.5110434293746948\n",
      "epoch: 400 cost: 0.4672488868236542\n",
      "epoch: 500 cost: 0.4282805621623993\n",
      "epoch: 600 cost: 0.391924113035202\n",
      "epoch: 700 cost: 0.35674208402633667\n",
      "epoch: 800 cost: 0.32157716155052185\n",
      "epoch: 900 cost: 0.28561723232269287\n",
      "epoch: 1000 cost: 0.2508176863193512\n",
      "epoch: 1100 cost: 0.23210185766220093\n",
      "epoch: 1200 cost: 0.22086557745933533\n",
      "epoch: 1300 cost: 0.21063703298568726\n",
      "epoch: 1400 cost: 0.20127873122692108\n",
      "epoch: 1500 cost: 0.19268494844436646\n",
      "epoch: 1600 cost: 0.18476678431034088\n",
      "epoch: 1700 cost: 0.17744912207126617\n",
      "epoch: 1800 cost: 0.17066752910614014\n",
      "epoch: 1900 cost: 0.16436627507209778\n",
      "epoch: 2000 cost: 0.1584969311952591\n",
      "epoch: 2100 cost: 0.1530178040266037\n",
      "epoch: 2200 cost: 0.14789187908172607\n",
      "epoch: 2300 cost: 0.14308682084083557\n",
      "epoch: 2400 cost: 0.13857412338256836\n",
      "epoch: 2500 cost: 0.13432839512825012\n",
      "epoch: 2600 cost: 0.130327045917511\n",
      "epoch: 2700 cost: 0.12655004858970642\n",
      "epoch: 2800 cost: 0.122979536652565\n",
      "epoch: 2900 cost: 0.11959897726774216\n",
      "epoch: 3000 cost: 0.11639437079429626\n",
      "epoch: 3100 cost: 0.11335216462612152\n",
      "epoch: 3200 cost: 0.11046060919761658\n",
      "epoch: 3300 cost: 0.10770916938781738\n",
      "epoch: 3400 cost: 0.10508791357278824\n",
      "epoch: 3500 cost: 0.10258817672729492\n",
      "epoch: 3600 cost: 0.10020141303539276\n",
      "epoch: 3700 cost: 0.09792064875364304\n",
      "epoch: 3800 cost: 0.09573902189731598\n",
      "epoch: 3900 cost: 0.09365029633045197\n",
      "epoch: 4000 cost: 0.09164856374263763\n",
      "epoch: 4100 cost: 0.08972857892513275\n",
      "epoch: 4200 cost: 0.0878857672214508\n",
      "epoch: 4300 cost: 0.08611556887626648\n",
      "epoch: 4400 cost: 0.08441359549760818\n",
      "epoch: 4500 cost: 0.08277644962072372\n",
      "epoch: 4600 cost: 0.08120007067918777\n",
      "epoch: 4700 cost: 0.07968148589134216\n",
      "epoch: 4800 cost: 0.07821754366159439\n",
      "epoch: 4900 cost: 0.07680539786815643\n",
      "epoch: 5000 cost: 0.07544229179620743\n",
      "epoch: 5100 cost: 0.07412579655647278\n",
      "epoch: 5200 cost: 0.072853684425354\n",
      "epoch: 5300 cost: 0.07162366062402725\n",
      "epoch: 5400 cost: 0.0704335868358612\n",
      "epoch: 5500 cost: 0.06928189843893051\n",
      "epoch: 5600 cost: 0.06816653907299042\n",
      "epoch: 5700 cost: 0.06708591431379318\n",
      "epoch: 5800 cost: 0.06603838503360748\n",
      "epoch: 5900 cost: 0.06502257287502289\n",
      "epoch: 6000 cost: 0.06403695791959763\n",
      "epoch: 6100 cost: 0.06308039277791977\n",
      "epoch: 6200 cost: 0.062151458114385605\n",
      "epoch: 6300 cost: 0.06124911457300186\n",
      "epoch: 6400 cost: 0.06037202477455139\n",
      "epoch: 6500 cost: 0.05951935425400734\n",
      "epoch: 6600 cost: 0.058690063655376434\n",
      "epoch: 6700 cost: 0.05788328871130943\n",
      "epoch: 6800 cost: 0.05709792301058769\n",
      "epoch: 6900 cost: 0.056333426386117935\n",
      "epoch: 7000 cost: 0.0555887445807457\n",
      "epoch: 7100 cost: 0.054863136261701584\n",
      "epoch: 7200 cost: 0.05415606498718262\n",
      "epoch: 7300 cost: 0.053466714918613434\n",
      "epoch: 7400 cost: 0.052794475108385086\n",
      "epoch: 7500 cost: 0.052138619124889374\n",
      "epoch: 7600 cost: 0.05149870738387108\n",
      "epoch: 7700 cost: 0.050874013453722\n",
      "epoch: 7800 cost: 0.05026412755250931\n",
      "epoch: 7900 cost: 0.04966845363378525\n",
      "epoch: 8000 cost: 0.049086619168519974\n",
      "epoch: 8100 cost: 0.0485181026160717\n",
      "epoch: 8200 cost: 0.04796237498521805\n",
      "epoch: 8300 cost: 0.047419045120477676\n",
      "epoch: 8400 cost: 0.04688774794340134\n",
      "epoch: 8500 cost: 0.04636809974908829\n",
      "epoch: 8600 cost: 0.04585971310734749\n",
      "epoch: 8700 cost: 0.04536217078566551\n",
      "epoch: 8800 cost: 0.04487523064017296\n",
      "epoch: 8900 cost: 0.04439845308661461\n",
      "epoch: 9000 cost: 0.04393162578344345\n",
      "epoch: 9100 cost: 0.04347435384988785\n",
      "epoch: 9200 cost: 0.043026480823755264\n",
      "epoch: 9300 cost: 0.04258757829666138\n",
      "epoch: 9400 cost: 0.04215735197067261\n",
      "epoch: 9500 cost: 0.041735757142305374\n",
      "epoch: 9600 cost: 0.04132235050201416\n",
      "epoch: 9700 cost: 0.040917038917541504\n",
      "epoch: 9800 cost: 0.04051932692527771\n",
      "epoch: 9900 cost: 0.04012938216328621\n",
      "epoch: 10000 cost: 0.03974665701389313\n"
     ]
    }
   ],
   "source": [
    "model=SoftmaxModel()\n",
    "optimizer=optim.SGD(model.parameters(), lr=0.1)\n",
    "epochs=10001\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_hat=model(x_train)\n",
    "    cost=F.cross_entropy(y_hat, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%100 == 0:\n",
    "        print('epoch:',epoch, 'cost:',cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-11.5040,  -0.2332,  11.5482],\n",
      "        [ -4.5121,   0.3314,   4.2518],\n",
      "        [-18.6585,   8.3969,  11.5301],\n",
      "        [-13.0540,   8.7773,   5.5311],\n",
      "        [  0.2068,   2.7515,  -3.0321],\n",
      "        [  3.6675,   6.8847,  -8.6049],\n",
      "        [  6.2559,   3.9120,  -9.5965],\n",
      "        [  9.5304,   4.7042, -13.5660]], grad_fn=<AddmmBackward0>)\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "prediction=model(x_train)\n",
    "print(prediction)\n",
    "for pred in prediction:\n",
    "    print(pred.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "iris=datasets.load_iris()\n",
    "# iris\n",
    "# iris.data\n",
    "iris.target\n",
    "# iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 4])\n",
      "torch.Size([150])\n"
     ]
    }
   ],
   "source": [
    "x_train=torch.FloatTensor(iris.data)\n",
    "y_train=torch.LongTensor(iris.target)\n",
    "print(x_train.size())\n",
    "print(y_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(4,3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SoftmaxModel()\n",
    "optimizer=optim.SGD(model.parameters(), lr=0.1)\n",
    "epochs=10001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 cost: 2.214918851852417\n",
      "epoch: 100 cost: 0.44505080580711365\n",
      "epoch: 200 cost: 0.2598172426223755\n",
      "epoch: 300 cost: 0.2164602130651474\n",
      "epoch: 400 cost: 0.1892022341489792\n",
      "epoch: 500 cost: 0.1703321486711502\n",
      "epoch: 600 cost: 0.15643833577632904\n",
      "epoch: 700 cost: 0.14574384689331055\n",
      "epoch: 800 cost: 0.13723178207874298\n",
      "epoch: 900 cost: 0.13027790188789368\n",
      "epoch: 1000 cost: 0.124477319419384\n",
      "epoch: 1100 cost: 0.11955566704273224\n",
      "epoch: 1200 cost: 0.11532022058963776\n",
      "epoch: 1300 cost: 0.11163146048784256\n",
      "epoch: 1400 cost: 0.10838580876588821\n",
      "epoch: 1500 cost: 0.10550463199615479\n",
      "epoch: 1600 cost: 0.10292721539735794\n",
      "epoch: 1700 cost: 0.10060573369264603\n",
      "epoch: 1800 cost: 0.09850217401981354\n",
      "epoch: 1900 cost: 0.09658568352460861\n",
      "epoch: 2000 cost: 0.094831183552742\n",
      "epoch: 2100 cost: 0.09321792423725128\n",
      "epoch: 2200 cost: 0.09172862768173218\n",
      "epoch: 2300 cost: 0.09034872055053711\n",
      "epoch: 2400 cost: 0.08906595408916473\n",
      "epoch: 2500 cost: 0.08786977827548981\n",
      "epoch: 2600 cost: 0.08675126731395721\n",
      "epoch: 2700 cost: 0.08570260554552078\n",
      "epoch: 2800 cost: 0.0847170427441597\n",
      "epoch: 2900 cost: 0.0837886780500412\n",
      "epoch: 3000 cost: 0.0829124003648758\n",
      "epoch: 3100 cost: 0.08208358287811279\n",
      "epoch: 3200 cost: 0.08129824697971344\n",
      "epoch: 3300 cost: 0.08055281639099121\n",
      "epoch: 3400 cost: 0.07984410971403122\n",
      "epoch: 3500 cost: 0.07916927337646484\n",
      "epoch: 3600 cost: 0.07852578163146973\n",
      "epoch: 3700 cost: 0.07791129499673843\n",
      "epoch: 3800 cost: 0.07732374221086502\n",
      "epoch: 3900 cost: 0.07676129043102264\n",
      "epoch: 4000 cost: 0.07622219622135162\n",
      "epoch: 4100 cost: 0.0757049098610878\n",
      "epoch: 4200 cost: 0.07520806789398193\n",
      "epoch: 4300 cost: 0.07473032921552658\n",
      "epoch: 4400 cost: 0.07427055388689041\n",
      "epoch: 4500 cost: 0.07382762432098389\n",
      "epoch: 4600 cost: 0.07340056449174881\n",
      "epoch: 4700 cost: 0.07298844307661057\n",
      "epoch: 4800 cost: 0.07259044051170349\n",
      "epoch: 4900 cost: 0.07220577448606491\n",
      "epoch: 5000 cost: 0.07183366268873215\n",
      "epoch: 5100 cost: 0.07147353142499924\n",
      "epoch: 5200 cost: 0.07112466543912888\n",
      "epoch: 5300 cost: 0.07078655809164047\n",
      "epoch: 5400 cost: 0.07045862078666687\n",
      "epoch: 5500 cost: 0.07014038413763046\n",
      "epoch: 5600 cost: 0.06983134895563126\n",
      "epoch: 5700 cost: 0.06953109800815582\n",
      "epoch: 5800 cost: 0.06923922896385193\n",
      "epoch: 5900 cost: 0.06895535439252853\n",
      "epoch: 6000 cost: 0.06867910176515579\n",
      "epoch: 6100 cost: 0.06841010600328445\n",
      "epoch: 6200 cost: 0.06814811378717422\n",
      "epoch: 6300 cost: 0.06789278984069824\n",
      "epoch: 6400 cost: 0.06764385849237442\n",
      "epoch: 6500 cost: 0.06740104407072067\n",
      "epoch: 6600 cost: 0.06716407835483551\n",
      "epoch: 6700 cost: 0.0669327899813652\n",
      "epoch: 6800 cost: 0.06670688837766647\n",
      "epoch: 6900 cost: 0.06648620963096619\n",
      "epoch: 7000 cost: 0.06627052277326584\n",
      "epoch: 7100 cost: 0.0660596564412117\n",
      "epoch: 7200 cost: 0.06585342437028885\n",
      "epoch: 7300 cost: 0.06565164774656296\n",
      "epoch: 7400 cost: 0.0654541552066803\n",
      "epoch: 7500 cost: 0.06526082754135132\n",
      "epoch: 7600 cost: 0.06507150083780289\n",
      "epoch: 7700 cost: 0.06488602608442307\n",
      "epoch: 7800 cost: 0.0647042766213417\n",
      "epoch: 7900 cost: 0.06452614068984985\n",
      "epoch: 8000 cost: 0.06435147672891617\n",
      "epoch: 8100 cost: 0.06418018043041229\n",
      "epoch: 8200 cost: 0.06401212513446808\n",
      "epoch: 8300 cost: 0.06384723633527756\n",
      "epoch: 8400 cost: 0.06368540227413177\n",
      "epoch: 8500 cost: 0.06352651119232178\n",
      "epoch: 8600 cost: 0.0633704885840416\n",
      "epoch: 8700 cost: 0.06321724504232407\n",
      "epoch: 8800 cost: 0.06306666880846024\n",
      "epoch: 8900 cost: 0.06291873753070831\n",
      "epoch: 9000 cost: 0.06277331709861755\n",
      "epoch: 9100 cost: 0.06263037025928497\n",
      "epoch: 9200 cost: 0.06248979642987251\n",
      "epoch: 9300 cost: 0.062351569533348083\n",
      "epoch: 9400 cost: 0.062215570360422134\n",
      "epoch: 9500 cost: 0.06208176165819168\n",
      "epoch: 9600 cost: 0.06195009872317314\n",
      "epoch: 9700 cost: 0.061820514500141144\n",
      "epoch: 9800 cost: 0.06169292330741882\n",
      "epoch: 9900 cost: 0.06156733259558678\n",
      "epoch: 10000 cost: 0.06144362688064575\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    y_hat=model(x_train)\n",
    "    cost=F.cross_entropy(y_hat, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%100 == 0:\n",
    "        print('epoch:',epoch, 'cost:',cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 tensor(147.)\n",
      "tensor(0.9800)\n"
     ]
    }
   ],
   "source": [
    "prediction=model(x_train)\n",
    "# print(prediction)\n",
    "\n",
    "accuracys=[]\n",
    "for i in range(len(prediction)):\n",
    "    accuracys.append(y_train[i]==prediction[i].argmax())\n",
    "\n",
    "print(len(accuracys), torch.FloatTensor(accuracys).sum())\n",
    "print(torch.FloatTensor(accuracys).sum()/len(accuracys))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
