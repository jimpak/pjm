{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2763787bf10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=torch.FloatTensor([[1],[2],[3],[4],[5]])\n",
    "t_data=torch.FloatTensor([[3],[5],[7],[9],[11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w=torch.zeros(1, requires_grad=True)\n",
    "b=torch.zeros(1, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=x_data*w+b\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(57., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost=torch.mean((t_data-y)**2)\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer=optim.SGD([w,b],lr=0.01)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 w: tensor([0.5000], requires_grad=True) b: tensor([0.1400], requires_grad=True) cost: tensor(57., grad_fn=<MeanBackward0>)\n",
      "epoch: 100 w: tensor([2.0815], requires_grad=True) b: tensor([0.7058], requires_grad=True) cost: tensor(0.0159, grad_fn=<MeanBackward0>)\n",
      "epoch: 200 w: tensor([2.0581], requires_grad=True) b: tensor([0.7903], requires_grad=True) cost: tensor(0.0081, grad_fn=<MeanBackward0>)\n",
      "epoch: 300 w: tensor([2.0414], requires_grad=True) b: tensor([0.8505], requires_grad=True) cost: tensor(0.0041, grad_fn=<MeanBackward0>)\n",
      "epoch: 400 w: tensor([2.0295], requires_grad=True) b: tensor([0.8935], requires_grad=True) cost: tensor(0.0021, grad_fn=<MeanBackward0>)\n",
      "epoch: 500 w: tensor([2.0210], requires_grad=True) b: tensor([0.9241], requires_grad=True) cost: tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "epoch: 600 w: tensor([2.0150], requires_grad=True) b: tensor([0.9459], requires_grad=True) cost: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "epoch: 700 w: tensor([2.0107], requires_grad=True) b: tensor([0.9614], requires_grad=True) cost: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "epoch: 800 w: tensor([2.0076], requires_grad=True) b: tensor([0.9725], requires_grad=True) cost: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "epoch: 900 w: tensor([2.0054], requires_grad=True) b: tensor([0.9804], requires_grad=True) cost: tensor(7.0334e-05, grad_fn=<MeanBackward0>)\n",
      "epoch: 1000 w: tensor([2.0039], requires_grad=True) b: tensor([0.9860], requires_grad=True) cost: tensor(3.5728e-05, grad_fn=<MeanBackward0>)\n",
      "epoch: 1100 w: tensor([2.0028], requires_grad=True) b: tensor([0.9900], requires_grad=True) cost: tensor(1.8150e-05, grad_fn=<MeanBackward0>)\n",
      "epoch: 1200 w: tensor([2.0020], requires_grad=True) b: tensor([0.9929], requires_grad=True) cost: tensor(9.2212e-06, grad_fn=<MeanBackward0>)\n",
      "epoch: 1300 w: tensor([2.0014], requires_grad=True) b: tensor([0.9949], requires_grad=True) cost: tensor(4.6847e-06, grad_fn=<MeanBackward0>)\n",
      "epoch: 1400 w: tensor([2.0010], requires_grad=True) b: tensor([0.9964], requires_grad=True) cost: tensor(2.3802e-06, grad_fn=<MeanBackward0>)\n",
      "epoch: 1500 w: tensor([2.0007], requires_grad=True) b: tensor([0.9974], requires_grad=True) cost: tensor(1.2102e-06, grad_fn=<MeanBackward0>)\n",
      "epoch: 1600 w: tensor([2.0005], requires_grad=True) b: tensor([0.9982], requires_grad=True) cost: tensor(6.1523e-07, grad_fn=<MeanBackward0>)\n",
      "epoch: 1700 w: tensor([2.0004], requires_grad=True) b: tensor([0.9987], requires_grad=True) cost: tensor(3.1271e-07, grad_fn=<MeanBackward0>)\n",
      "epoch: 1800 w: tensor([2.0003], requires_grad=True) b: tensor([0.9991], requires_grad=True) cost: tensor(1.5886e-07, grad_fn=<MeanBackward0>)\n",
      "epoch: 1900 w: tensor([2.0002], requires_grad=True) b: tensor([0.9993], requires_grad=True) cost: tensor(8.0881e-08, grad_fn=<MeanBackward0>)\n",
      "epoch: 2000 w: tensor([2.0001], requires_grad=True) b: tensor([0.9995], requires_grad=True) cost: tensor(4.1230e-08, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs=2001\n",
    "for epoch in range(epochs):\n",
    "    y=x_data*w+b  #가설\n",
    "    cost=torch.mean((t_data-y)**2)  #  비용함수 구하기\n",
    "    optimizer.zero_grad()  # 최적화 값 초기화\n",
    "    cost.backward()  # \n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100==0:\n",
    "        print('epoch:', epoch, 'w:',w, 'b:',b, 'cost:',cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [2 3]\n",
      " [3 4]\n",
      " [4 5]\n",
      " [5 6]]\n",
      "[[ 3]\n",
      " [ 5]\n",
      " [ 7]\n",
      " [ 9]\n",
      " [11]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_data1=np.array([[1,2],[2,3],[3,4],[4,5],[5,6]]).reshape(5,2)\n",
    "t_data1=np.array([3,5,7,9,11]).reshape(5,1)\n",
    "print(x_data1)\n",
    "print(t_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [2., 3.],\n",
      "        [3., 4.],\n",
      "        [4., 5.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 3.],\n",
      "        [ 5.],\n",
      "        [ 7.],\n",
      "        [ 9.],\n",
      "        [11.]])\n"
     ]
    }
   ],
   "source": [
    "x_data2=torch.from_numpy(x_data1).float()\n",
    "t_data2=torch.from_numpy(t_data1).float()\n",
    "print(x_data2)\n",
    "print(t_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.]], requires_grad=True)\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w=torch.zeros((2,1), requires_grad=True)\n",
    "b=torch.zeros(1, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 y: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>) cost: 57.0 w: tensor([[5.0000e-05],\n",
      "        [6.4000e-05]], requires_grad=True) b: tensor([1.4000e-05], requires_grad=True)\n",
      "Epoch: 400 y: tensor([[0.0759],\n",
      "        [0.1210],\n",
      "        [0.1660],\n",
      "        [0.2111],\n",
      "        [0.2561]], grad_fn=<AddBackward0>) cost: 54.34687423706055 w: tensor([[0.0198],\n",
      "        [0.0254]], requires_grad=True) b: tensor([0.0055], requires_grad=True)\n",
      "Epoch: 800 y: tensor([[0.1500],\n",
      "        [0.2391],\n",
      "        [0.3281],\n",
      "        [0.4172],\n",
      "        [0.5063]], grad_fn=<AddBackward0>) cost: 51.8172721862793 w: tensor([[0.0391],\n",
      "        [0.0501]], requires_grad=True) b: tensor([0.0109], requires_grad=True)\n",
      "Epoch: 1200 y: tensor([[0.2224],\n",
      "        [0.3544],\n",
      "        [0.4864],\n",
      "        [0.6184],\n",
      "        [0.7505]], grad_fn=<AddBackward0>) cost: 49.405452728271484 w: tensor([[0.0580],\n",
      "        [0.0742]], requires_grad=True) b: tensor([0.0162], requires_grad=True)\n",
      "Epoch: 1600 y: tensor([[0.2930],\n",
      "        [0.4670],\n",
      "        [0.6410],\n",
      "        [0.8150],\n",
      "        [0.9889]], grad_fn=<AddBackward0>) cost: 47.105934143066406 w: tensor([[0.0764],\n",
      "        [0.0977]], requires_grad=True) b: tensor([0.0214], requires_grad=True)\n",
      "Epoch: 2000 y: tensor([[0.3620],\n",
      "        [0.5769],\n",
      "        [0.7919],\n",
      "        [1.0068],\n",
      "        [1.2218]], grad_fn=<AddBackward0>) cost: 44.913475036621094 w: tensor([[0.0943],\n",
      "        [0.1207]], requires_grad=True) b: tensor([0.0264], requires_grad=True)\n",
      "Epoch: 2400 y: tensor([[0.4294],\n",
      "        [0.6843],\n",
      "        [0.9393],\n",
      "        [1.1942],\n",
      "        [1.4491]], grad_fn=<AddBackward0>) cost: 42.82310104370117 w: tensor([[0.1119],\n",
      "        [0.1432]], requires_grad=True) b: tensor([0.0313], requires_grad=True)\n",
      "Epoch: 2800 y: tensor([[0.4951],\n",
      "        [0.7891],\n",
      "        [1.0831],\n",
      "        [1.3771],\n",
      "        [1.6712]], grad_fn=<AddBackward0>) cost: 40.830055236816406 w: tensor([[0.1290],\n",
      "        [0.1651]], requires_grad=True) b: tensor([0.0361], requires_grad=True)\n",
      "Epoch: 3200 y: tensor([[0.5594],\n",
      "        [0.8915],\n",
      "        [1.2236],\n",
      "        [1.5558],\n",
      "        [1.8879]], grad_fn=<AddBackward0>) cost: 38.92980194091797 w: tensor([[0.1457],\n",
      "        [0.1865]], requires_grad=True) b: tensor([0.0408], requires_grad=True)\n",
      "Epoch: 3600 y: tensor([[0.6221],\n",
      "        [0.9914],\n",
      "        [1.3608],\n",
      "        [1.7302],\n",
      "        [2.0996]], grad_fn=<AddBackward0>) cost: 37.11802673339844 w: tensor([[0.1621],\n",
      "        [0.2074]], requires_grad=True) b: tensor([0.0453], requires_grad=True)\n",
      "Epoch: 4000 y: tensor([[0.6833],\n",
      "        [1.0890],\n",
      "        [1.4948],\n",
      "        [1.9005],\n",
      "        [2.3063]], grad_fn=<AddBackward0>) cost: 35.3906135559082 w: tensor([[0.1780],\n",
      "        [0.2278]], requires_grad=True) b: tensor([0.0498], requires_grad=True)\n",
      "Epoch: 4400 y: tensor([[0.7431],\n",
      "        [1.1843],\n",
      "        [1.6256],\n",
      "        [2.0668],\n",
      "        [2.5081]], grad_fn=<AddBackward0>) cost: 33.743629455566406 w: tensor([[0.1936],\n",
      "        [0.2477]], requires_grad=True) b: tensor([0.0541], requires_grad=True)\n",
      "Epoch: 4800 y: tensor([[0.8015],\n",
      "        [1.2774],\n",
      "        [1.7533],\n",
      "        [2.2292],\n",
      "        [2.7052]], grad_fn=<AddBackward0>) cost: 32.1733283996582 w: tensor([[0.2088],\n",
      "        [0.2672]], requires_grad=True) b: tensor([0.0584], requires_grad=True)\n",
      "Epoch: 5200 y: tensor([[0.8585],\n",
      "        [1.3682],\n",
      "        [1.8780],\n",
      "        [2.3878],\n",
      "        [2.8976]], grad_fn=<AddBackward0>) cost: 30.676132202148438 w: tensor([[0.2237],\n",
      "        [0.2862]], requires_grad=True) b: tensor([0.0625], requires_grad=True)\n",
      "Epoch: 5600 y: tensor([[0.9141],\n",
      "        [1.4570],\n",
      "        [1.9998],\n",
      "        [2.5426],\n",
      "        [3.0855]], grad_fn=<AddBackward0>) cost: 29.2486515045166 w: tensor([[0.2382],\n",
      "        [0.3048]], requires_grad=True) b: tensor([0.0666], requires_grad=True)\n",
      "Epoch: 6000 y: tensor([[0.9685],\n",
      "        [1.5436],\n",
      "        [2.1187],\n",
      "        [2.6938],\n",
      "        [3.2689]], grad_fn=<AddBackward0>) cost: 27.88763999938965 w: tensor([[0.2523],\n",
      "        [0.3229]], requires_grad=True) b: tensor([0.0705], requires_grad=True)\n",
      "Epoch: 6400 y: tensor([[1.0215],\n",
      "        [1.6282],\n",
      "        [2.2348],\n",
      "        [2.8414],\n",
      "        [3.4481]], grad_fn=<AddBackward0>) cost: 26.589990615844727 w: tensor([[0.2662],\n",
      "        [0.3406]], requires_grad=True) b: tensor([0.0744], requires_grad=True)\n",
      "Epoch: 6800 y: tensor([[1.0734],\n",
      "        [1.7108],\n",
      "        [2.3482],\n",
      "        [2.9856],\n",
      "        [3.6230]], grad_fn=<AddBackward0>) cost: 25.35276222229004 w: tensor([[0.2797],\n",
      "        [0.3578]], requires_grad=True) b: tensor([0.0782], requires_grad=True)\n",
      "Epoch: 7200 y: tensor([[1.1239],\n",
      "        [1.7914],\n",
      "        [2.4589],\n",
      "        [3.1263],\n",
      "        [3.7938]], grad_fn=<AddBackward0>) cost: 24.173137664794922 w: tensor([[0.2928],\n",
      "        [0.3747]], requires_grad=True) b: tensor([0.0818], requires_grad=True)\n",
      "Epoch: 7600 y: tensor([[1.1733],\n",
      "        [1.8702],\n",
      "        [2.5670],\n",
      "        [3.2638],\n",
      "        [3.9606]], grad_fn=<AddBackward0>) cost: 23.04843521118164 w: tensor([[0.3057],\n",
      "        [0.3912]], requires_grad=True) b: tensor([0.0854], requires_grad=True)\n",
      "Epoch: 8000 y: tensor([[1.2216],\n",
      "        [1.9470],\n",
      "        [2.6725],\n",
      "        [3.3980],\n",
      "        [4.1234]], grad_fn=<AddBackward0>) cost: 21.976104736328125 w: tensor([[0.3183],\n",
      "        [0.4072]], requires_grad=True) b: tensor([0.0889], requires_grad=True)\n",
      "Epoch: 8400 y: tensor([[1.2687],\n",
      "        [2.0221],\n",
      "        [2.7756],\n",
      "        [3.5290],\n",
      "        [4.2824]], grad_fn=<AddBackward0>) cost: 20.953697204589844 w: tensor([[0.3306],\n",
      "        [0.4229]], requires_grad=True) b: tensor([0.0924], requires_grad=True)\n",
      "Epoch: 8800 y: tensor([[1.3147],\n",
      "        [2.0954],\n",
      "        [2.8762],\n",
      "        [3.6569],\n",
      "        [4.4377]], grad_fn=<AddBackward0>) cost: 19.978900909423828 w: tensor([[0.3426],\n",
      "        [0.4383]], requires_grad=True) b: tensor([0.0957], requires_grad=True)\n",
      "Epoch: 9200 y: tensor([[1.3596],\n",
      "        [2.1670],\n",
      "        [2.9744],\n",
      "        [3.7819],\n",
      "        [4.5893]], grad_fn=<AddBackward0>) cost: 19.049480438232422 w: tensor([[0.3543],\n",
      "        [0.4532]], requires_grad=True) b: tensor([0.0990], requires_grad=True)\n",
      "Epoch: 9600 y: tensor([[1.4034],\n",
      "        [2.2369],\n",
      "        [3.0704],\n",
      "        [3.9039],\n",
      "        [4.7374]], grad_fn=<AddBackward0>) cost: 18.163339614868164 w: tensor([[0.3657],\n",
      "        [0.4678]], requires_grad=True) b: tensor([0.1021], requires_grad=True)\n",
      "Epoch: 10000 y: tensor([[1.4462],\n",
      "        [2.3052],\n",
      "        [3.1641],\n",
      "        [4.0230],\n",
      "        [4.8819]], grad_fn=<AddBackward0>) cost: 17.31846046447754 w: tensor([[0.3769],\n",
      "        [0.4821]], requires_grad=True) b: tensor([0.1052], requires_grad=True)\n",
      "Epoch: 10400 y: tensor([[1.4880],\n",
      "        [2.3718],\n",
      "        [3.2555],\n",
      "        [4.1393],\n",
      "        [5.0231]], grad_fn=<AddBackward0>) cost: 16.512914657592773 w: tensor([[0.3878],\n",
      "        [0.4960]], requires_grad=True) b: tensor([0.1083], requires_grad=True)\n",
      "Epoch: 10800 y: tensor([[1.5289],\n",
      "        [2.4369],\n",
      "        [3.3449],\n",
      "        [4.2529],\n",
      "        [5.1609]], grad_fn=<AddBackward0>) cost: 15.744885444641113 w: tensor([[0.3984],\n",
      "        [0.5097]], requires_grad=True) b: tensor([0.1112], requires_grad=True)\n",
      "Epoch: 11200 y: tensor([[1.5687],\n",
      "        [2.5004],\n",
      "        [3.4321],\n",
      "        [4.3638],\n",
      "        [5.2955]], grad_fn=<AddBackward0>) cost: 15.012600898742676 w: tensor([[0.4088],\n",
      "        [0.5229]], requires_grad=True) b: tensor([0.1141], requires_grad=True)\n",
      "Epoch: 11600 y: tensor([[1.6076],\n",
      "        [2.5624],\n",
      "        [3.5172],\n",
      "        [4.4721],\n",
      "        [5.4269]], grad_fn=<AddBackward0>) cost: 14.314416885375977 w: tensor([[0.4190],\n",
      "        [0.5359]], requires_grad=True) b: tensor([0.1169], requires_grad=True)\n",
      "Epoch: 12000 y: tensor([[1.6456],\n",
      "        [2.6230],\n",
      "        [3.6004],\n",
      "        [4.5778],\n",
      "        [5.5552]], grad_fn=<AddBackward0>) cost: 13.648747444152832 w: tensor([[0.4289],\n",
      "        [0.5486]], requires_grad=True) b: tensor([0.1197], requires_grad=True)\n",
      "Epoch: 12400 y: tensor([[1.6827],\n",
      "        [2.6822],\n",
      "        [3.6816],\n",
      "        [4.6810],\n",
      "        [5.6805]], grad_fn=<AddBackward0>) cost: 13.014055252075195 w: tensor([[0.4386],\n",
      "        [0.5609]], requires_grad=True) b: tensor([0.1224], requires_grad=True)\n",
      "Epoch: 12800 y: tensor([[1.7189],\n",
      "        [2.7399],\n",
      "        [3.7609],\n",
      "        [4.7818],\n",
      "        [5.8028]], grad_fn=<AddBackward0>) cost: 12.408926010131836 w: tensor([[0.4480],\n",
      "        [0.5730]], requires_grad=True) b: tensor([0.1250], requires_grad=True)\n",
      "Epoch: 13200 y: tensor([[1.7543],\n",
      "        [2.7963],\n",
      "        [3.8383],\n",
      "        [4.8803],\n",
      "        [5.9223]], grad_fn=<AddBackward0>) cost: 11.831972122192383 w: tensor([[0.4572],\n",
      "        [0.5848]], requires_grad=True) b: tensor([0.1276], requires_grad=True)\n",
      "Epoch: 13600 y: tensor([[1.7889],\n",
      "        [2.8514],\n",
      "        [3.9139],\n",
      "        [4.9764],\n",
      "        [6.0389]], grad_fn=<AddBackward0>) cost: 11.28188419342041 w: tensor([[0.4662],\n",
      "        [0.5963]], requires_grad=True) b: tensor([0.1301], requires_grad=True)\n",
      "Epoch: 14000 y: tensor([[1.8226],\n",
      "        [2.9051],\n",
      "        [3.9877],\n",
      "        [5.0702],\n",
      "        [6.1528]], grad_fn=<AddBackward0>) cost: 10.757402420043945 w: tensor([[0.4750],\n",
      "        [0.6076]], requires_grad=True) b: tensor([0.1325], requires_grad=True)\n",
      "Epoch: 14400 y: tensor([[1.8555],\n",
      "        [2.9576],\n",
      "        [4.0598],\n",
      "        [5.1619],\n",
      "        [6.2640]], grad_fn=<AddBackward0>) cost: 10.257339477539062 w: tensor([[0.4836],\n",
      "        [0.6185]], requires_grad=True) b: tensor([0.1349], requires_grad=True)\n",
      "Epoch: 14800 y: tensor([[1.8877],\n",
      "        [3.0089],\n",
      "        [4.1301],\n",
      "        [5.2514],\n",
      "        [6.3726]], grad_fn=<AddBackward0>) cost: 9.780560493469238 w: tensor([[0.4920],\n",
      "        [0.6292]], requires_grad=True) b: tensor([0.1372], requires_grad=True)\n",
      "Epoch: 15200 y: tensor([[1.9191],\n",
      "        [3.0590],\n",
      "        [4.1989],\n",
      "        [5.3387],\n",
      "        [6.4786]], grad_fn=<AddBackward0>) cost: 9.325979232788086 w: tensor([[0.5002],\n",
      "        [0.6397]], requires_grad=True) b: tensor([0.1395], requires_grad=True)\n",
      "Epoch: 15600 y: tensor([[1.9497],\n",
      "        [3.1078],\n",
      "        [4.2659],\n",
      "        [5.4241],\n",
      "        [6.5822]], grad_fn=<AddBackward0>) cost: 8.892561912536621 w: tensor([[0.5082],\n",
      "        [0.6499]], requires_grad=True) b: tensor([0.1417], requires_grad=True)\n",
      "Epoch: 16000 y: tensor([[1.9796],\n",
      "        [3.1556],\n",
      "        [4.3315],\n",
      "        [5.5074],\n",
      "        [6.6833]], grad_fn=<AddBackward0>) cost: 8.479330062866211 w: tensor([[0.5161],\n",
      "        [0.6599]], requires_grad=True) b: tensor([0.1439], requires_grad=True)\n",
      "Epoch: 16400 y: tensor([[2.0089],\n",
      "        [3.2021],\n",
      "        [4.3954],\n",
      "        [5.5887],\n",
      "        [6.7820]], grad_fn=<AddBackward0>) cost: 8.085336685180664 w: tensor([[0.5237],\n",
      "        [0.6696]], requires_grad=True) b: tensor([0.1460], requires_grad=True)\n",
      "Epoch: 16800 y: tensor([[2.0374],\n",
      "        [3.2476],\n",
      "        [4.4579],\n",
      "        [5.6681],\n",
      "        [6.8784]], grad_fn=<AddBackward0>) cost: 7.709689140319824 w: tensor([[0.5311],\n",
      "        [0.6792]], requires_grad=True) b: tensor([0.1480], requires_grad=True)\n",
      "Epoch: 17200 y: tensor([[2.0653],\n",
      "        [3.2921],\n",
      "        [4.5189],\n",
      "        [5.7457],\n",
      "        [6.9725]], grad_fn=<AddBackward0>) cost: 7.35152530670166 w: tensor([[0.5384],\n",
      "        [0.6884]], requires_grad=True) b: tensor([0.1500], requires_grad=True)\n",
      "Epoch: 17600 y: tensor([[2.0925],\n",
      "        [3.3355],\n",
      "        [4.5784],\n",
      "        [5.8214],\n",
      "        [7.0644]], grad_fn=<AddBackward0>) cost: 7.010040283203125 w: tensor([[0.5455],\n",
      "        [0.6975]], requires_grad=True) b: tensor([0.1520], requires_grad=True)\n",
      "Epoch: 18000 y: tensor([[2.1190],\n",
      "        [3.3778],\n",
      "        [4.6366],\n",
      "        [5.8954],\n",
      "        [7.1542]], grad_fn=<AddBackward0>) cost: 6.684456825256348 w: tensor([[0.5525],\n",
      "        [0.7064]], requires_grad=True) b: tensor([0.1539], requires_grad=True)\n",
      "Epoch: 18400 y: tensor([[2.1450],\n",
      "        [3.4192],\n",
      "        [4.6934],\n",
      "        [5.9676],\n",
      "        [7.2418]], grad_fn=<AddBackward0>) cost: 6.374032497406006 w: tensor([[0.5592],\n",
      "        [0.7150]], requires_grad=True) b: tensor([0.1558], requires_grad=True)\n",
      "Epoch: 18800 y: tensor([[2.1703],\n",
      "        [3.4596],\n",
      "        [4.7488],\n",
      "        [6.0381],\n",
      "        [7.3274]], grad_fn=<AddBackward0>) cost: 6.078057765960693 w: tensor([[0.5659],\n",
      "        [0.7235]], requires_grad=True) b: tensor([0.1576], requires_grad=True)\n",
      "Epoch: 19200 y: tensor([[2.1950],\n",
      "        [3.4990],\n",
      "        [4.8030],\n",
      "        [6.1069],\n",
      "        [7.4109]], grad_fn=<AddBackward0>) cost: 5.795865535736084 w: tensor([[0.5723],\n",
      "        [0.7317]], requires_grad=True) b: tensor([0.1594], requires_grad=True)\n",
      "Epoch: 19600 y: tensor([[2.2192],\n",
      "        [3.5375],\n",
      "        [4.8558],\n",
      "        [6.1742],\n",
      "        [7.4925]], grad_fn=<AddBackward0>) cost: 5.526805400848389 w: tensor([[0.5786],\n",
      "        [0.7397]], requires_grad=True) b: tensor([0.1611], requires_grad=True)\n",
      "Epoch: 20000 y: tensor([[2.2427],\n",
      "        [3.5751],\n",
      "        [4.9074],\n",
      "        [6.2398],\n",
      "        [7.5722]], grad_fn=<AddBackward0>) cost: 5.270282745361328 w: tensor([[0.5848],\n",
      "        [0.7476]], requires_grad=True) b: tensor([0.1628], requires_grad=True)\n",
      "Epoch: 20400 y: tensor([[2.2658],\n",
      "        [3.6118],\n",
      "        [4.9578],\n",
      "        [6.3039],\n",
      "        [7.6499]], grad_fn=<AddBackward0>) cost: 5.025702953338623 w: tensor([[0.5908],\n",
      "        [0.7553]], requires_grad=True) b: tensor([0.1645], requires_grad=True)\n",
      "Epoch: 20800 y: tensor([[2.2882],\n",
      "        [3.6476],\n",
      "        [5.0071],\n",
      "        [6.3665],\n",
      "        [7.7259]], grad_fn=<AddBackward0>) cost: 4.792501926422119 w: tensor([[0.5967],\n",
      "        [0.7628]], requires_grad=True) b: tensor([0.1661], requires_grad=True)\n",
      "Epoch: 21200 y: tensor([[2.3102],\n",
      "        [3.6826],\n",
      "        [5.0551],\n",
      "        [6.4276],\n",
      "        [7.8001]], grad_fn=<AddBackward0>) cost: 4.570175647735596 w: tensor([[0.6024],\n",
      "        [0.7701]], requires_grad=True) b: tensor([0.1676], requires_grad=True)\n",
      "Epoch: 21600 y: tensor([[2.3316],\n",
      "        [3.7168],\n",
      "        [5.1020],\n",
      "        [6.4873],\n",
      "        [7.8725]], grad_fn=<AddBackward0>) cost: 4.3581862449646 w: tensor([[0.6080],\n",
      "        [0.7772]], requires_grad=True) b: tensor([0.1692], requires_grad=True)\n",
      "Epoch: 22000 y: tensor([[2.3525],\n",
      "        [3.7502],\n",
      "        [5.1479],\n",
      "        [6.5455],\n",
      "        [7.9432]], grad_fn=<AddBackward0>) cost: 4.156071662902832 w: tensor([[0.6135],\n",
      "        [0.7842]], requires_grad=True) b: tensor([0.1707], requires_grad=True)\n",
      "Epoch: 22400 y: tensor([[2.3729],\n",
      "        [3.7828],\n",
      "        [5.1926],\n",
      "        [6.6024],\n",
      "        [8.0122]], grad_fn=<AddBackward0>) cost: 3.963362455368042 w: tensor([[0.6189],\n",
      "        [0.7910]], requires_grad=True) b: tensor([0.1722], requires_grad=True)\n",
      "Epoch: 22800 y: tensor([[2.3929],\n",
      "        [3.8146],\n",
      "        [5.2363],\n",
      "        [6.6580],\n",
      "        [8.0796]], grad_fn=<AddBackward0>) cost: 3.7796273231506348 w: tensor([[0.6241],\n",
      "        [0.7976]], requires_grad=True) b: tensor([0.1736], requires_grad=True)\n",
      "Epoch: 23200 y: tensor([[2.4124],\n",
      "        [3.8456],\n",
      "        [5.2789],\n",
      "        [6.7122],\n",
      "        [8.1455]], grad_fn=<AddBackward0>) cost: 3.6044559478759766 w: tensor([[0.6292],\n",
      "        [0.8041]], requires_grad=True) b: tensor([0.1750], requires_grad=True)\n",
      "Epoch: 23600 y: tensor([[2.4314],\n",
      "        [3.8760],\n",
      "        [5.3206],\n",
      "        [6.7652],\n",
      "        [8.2098]], grad_fn=<AddBackward0>) cost: 3.4374282360076904 w: tensor([[0.6341],\n",
      "        [0.8105]], requires_grad=True) b: tensor([0.1763], requires_grad=True)\n",
      "Epoch: 24000 y: tensor([[2.4500],\n",
      "        [3.9056],\n",
      "        [5.3612],\n",
      "        [6.8169],\n",
      "        [8.2725]], grad_fn=<AddBackward0>) cost: 3.278174877166748 w: tensor([[0.6390],\n",
      "        [0.8167]], requires_grad=True) b: tensor([0.1777], requires_grad=True)\n",
      "Epoch: 24400 y: tensor([[2.4681],\n",
      "        [3.9345],\n",
      "        [5.4009],\n",
      "        [6.8674],\n",
      "        [8.3338]], grad_fn=<AddBackward0>) cost: 3.1263508796691895 w: tensor([[0.6438],\n",
      "        [0.8227]], requires_grad=True) b: tensor([0.1790], requires_grad=True)\n",
      "Epoch: 24800 y: tensor([[2.4858],\n",
      "        [3.9628],\n",
      "        [5.4397],\n",
      "        [6.9167],\n",
      "        [8.3937]], grad_fn=<AddBackward0>) cost: 2.981588363647461 w: tensor([[0.6484],\n",
      "        [0.8286]], requires_grad=True) b: tensor([0.1802], requires_grad=True)\n",
      "Epoch: 25200 y: tensor([[2.5031],\n",
      "        [3.9903],\n",
      "        [5.4776],\n",
      "        [6.9648],\n",
      "        [8.4521]], grad_fn=<AddBackward0>) cost: 2.843567371368408 w: tensor([[0.6529],\n",
      "        [0.8344]], requires_grad=True) b: tensor([0.1815], requires_grad=True)\n",
      "Epoch: 25600 y: tensor([[2.5199],\n",
      "        [4.0172],\n",
      "        [5.5145],\n",
      "        [7.0119],\n",
      "        [8.5092]], grad_fn=<AddBackward0>) cost: 2.7119715213775635 w: tensor([[0.6573],\n",
      "        [0.8400]], requires_grad=True) b: tensor([0.1827], requires_grad=True)\n",
      "Epoch: 26000 y: tensor([[2.5364],\n",
      "        [4.0435],\n",
      "        [5.5506],\n",
      "        [7.0578],\n",
      "        [8.5649]], grad_fn=<AddBackward0>) cost: 2.5864996910095215 w: tensor([[0.6617],\n",
      "        [0.8455]], requires_grad=True) b: tensor([0.1838], requires_grad=True)\n",
      "Epoch: 26400 y: tensor([[2.5525],\n",
      "        [4.0692],\n",
      "        [5.5859],\n",
      "        [7.1026],\n",
      "        [8.6193]], grad_fn=<AddBackward0>) cost: 2.466874599456787 w: tensor([[0.6659],\n",
      "        [0.8508]], requires_grad=True) b: tensor([0.1850], requires_grad=True)\n",
      "Epoch: 26800 y: tensor([[2.5682],\n",
      "        [4.0943],\n",
      "        [5.6203],\n",
      "        [7.1464],\n",
      "        [8.6724]], grad_fn=<AddBackward0>) cost: 2.3528151512145996 w: tensor([[0.6700],\n",
      "        [0.8561]], requires_grad=True) b: tensor([0.1861], requires_grad=True)\n",
      "Epoch: 27200 y: tensor([[2.5835],\n",
      "        [4.1187],\n",
      "        [5.6539],\n",
      "        [7.1891],\n",
      "        [8.7243]], grad_fn=<AddBackward0>) cost: 2.244065523147583 w: tensor([[0.6740],\n",
      "        [0.8612]], requires_grad=True) b: tensor([0.1872], requires_grad=True)\n",
      "Epoch: 27600 y: tensor([[2.5985],\n",
      "        [4.1426],\n",
      "        [5.6867],\n",
      "        [7.2308],\n",
      "        [8.7749]], grad_fn=<AddBackward0>) cost: 2.1403841972351074 w: tensor([[0.6779],\n",
      "        [0.8662]], requires_grad=True) b: tensor([0.1882], requires_grad=True)\n",
      "Epoch: 28000 y: tensor([[2.6131],\n",
      "        [4.1659],\n",
      "        [5.7188],\n",
      "        [7.2716],\n",
      "        [8.8244]], grad_fn=<AddBackward0>) cost: 2.041527509689331 w: tensor([[0.6818],\n",
      "        [0.8711]], requires_grad=True) b: tensor([0.1893], requires_grad=True)\n",
      "Epoch: 28400 y: tensor([[2.6274],\n",
      "        [4.1887],\n",
      "        [5.7500],\n",
      "        [7.3114],\n",
      "        [8.8727]], grad_fn=<AddBackward0>) cost: 1.9472672939300537 w: tensor([[0.6855],\n",
      "        [0.8758]], requires_grad=True) b: tensor([0.1903], requires_grad=True)\n",
      "Epoch: 28800 y: tensor([[2.6414],\n",
      "        [4.2110],\n",
      "        [5.7806],\n",
      "        [7.3502],\n",
      "        [8.9198]], grad_fn=<AddBackward0>) cost: 1.8573932647705078 w: tensor([[0.6892],\n",
      "        [0.8805]], requires_grad=True) b: tensor([0.1913], requires_grad=True)\n",
      "Epoch: 29200 y: tensor([[2.6550],\n",
      "        [4.2327],\n",
      "        [5.8104],\n",
      "        [7.3882],\n",
      "        [8.9659]], grad_fn=<AddBackward0>) cost: 1.7717201709747314 w: tensor([[0.6928],\n",
      "        [0.8850]], requires_grad=True) b: tensor([0.1922], requires_grad=True)\n",
      "Epoch: 29600 y: tensor([[2.6682],\n",
      "        [4.2539],\n",
      "        [5.8395],\n",
      "        [7.4252],\n",
      "        [9.0108]], grad_fn=<AddBackward0>) cost: 1.690016508102417 w: tensor([[0.6962],\n",
      "        [0.8894]], requires_grad=True) b: tensor([0.1932], requires_grad=True)\n",
      "Epoch: 30000 y: tensor([[2.6812],\n",
      "        [4.2746],\n",
      "        [5.8680],\n",
      "        [7.4614],\n",
      "        [9.0547]], grad_fn=<AddBackward0>) cost: 1.6121337413787842 w: tensor([[0.6996],\n",
      "        [0.8938]], requires_grad=True) b: tensor([0.1941], requires_grad=True)\n",
      "Epoch: 30400 y: tensor([[2.6939],\n",
      "        [4.2948],\n",
      "        [5.8958],\n",
      "        [7.4967],\n",
      "        [9.0976]], grad_fn=<AddBackward0>) cost: 1.5378727912902832 w: tensor([[0.7030],\n",
      "        [0.8980]], requires_grad=True) b: tensor([0.1950], requires_grad=True)\n",
      "Epoch: 30800 y: tensor([[2.7063],\n",
      "        [4.3146],\n",
      "        [5.9229],\n",
      "        [7.5312],\n",
      "        [9.1395]], grad_fn=<AddBackward0>) cost: 1.4670631885528564 w: tensor([[0.7062],\n",
      "        [0.9021]], requires_grad=True) b: tensor([0.1959], requires_grad=True)\n",
      "Epoch: 31200 y: tensor([[2.7183],\n",
      "        [4.3338],\n",
      "        [5.9493],\n",
      "        [7.5648],\n",
      "        [9.1804]], grad_fn=<AddBackward0>) cost: 1.3995500802993774 w: tensor([[0.7094],\n",
      "        [0.9061]], requires_grad=True) b: tensor([0.1967], requires_grad=True)\n",
      "Epoch: 31600 y: tensor([[2.7301],\n",
      "        [4.3527],\n",
      "        [5.9752],\n",
      "        [7.5977],\n",
      "        [9.2203]], grad_fn=<AddBackward0>) cost: 1.3351812362670898 w: tensor([[0.7125],\n",
      "        [0.9101]], requires_grad=True) b: tensor([0.1976], requires_grad=True)\n",
      "Epoch: 32000 y: tensor([[2.7416],\n",
      "        [4.3710],\n",
      "        [6.0004],\n",
      "        [7.6298],\n",
      "        [9.2592]], grad_fn=<AddBackward0>) cost: 1.2738111019134521 w: tensor([[0.7155],\n",
      "        [0.9139]], requires_grad=True) b: tensor([0.1984], requires_grad=True)\n",
      "Epoch: 32400 y: tensor([[2.7529],\n",
      "        [4.3890],\n",
      "        [6.0251],\n",
      "        [7.6612],\n",
      "        [9.2973]], grad_fn=<AddBackward0>) cost: 1.2152975797653198 w: tensor([[0.7185],\n",
      "        [0.9176]], requires_grad=True) b: tensor([0.1992], requires_grad=True)\n",
      "Epoch: 32800 y: tensor([[2.7639],\n",
      "        [4.4065],\n",
      "        [6.0492],\n",
      "        [7.6918],\n",
      "        [9.3345]], grad_fn=<AddBackward0>) cost: 1.1595096588134766 w: tensor([[0.7214],\n",
      "        [0.9213]], requires_grad=True) b: tensor([0.1999], requires_grad=True)\n",
      "Epoch: 33200 y: tensor([[2.7746],\n",
      "        [4.4236],\n",
      "        [6.0726],\n",
      "        [7.7217],\n",
      "        [9.3707]], grad_fn=<AddBackward0>) cost: 1.106324553489685 w: tensor([[0.7242],\n",
      "        [0.9249]], requires_grad=True) b: tensor([0.2007], requires_grad=True)\n",
      "Epoch: 33600 y: tensor([[2.7850],\n",
      "        [4.4403],\n",
      "        [6.0956],\n",
      "        [7.7509],\n",
      "        [9.4062]], grad_fn=<AddBackward0>) cost: 1.0556013584136963 w: tensor([[0.7269],\n",
      "        [0.9284]], requires_grad=True) b: tensor([0.2014], requires_grad=True)\n",
      "Epoch: 34000 y: tensor([[2.7952],\n",
      "        [4.4566],\n",
      "        [6.1180],\n",
      "        [7.7794],\n",
      "        [9.4408]], grad_fn=<AddBackward0>) cost: 1.0072479248046875 w: tensor([[0.7296],\n",
      "        [0.9318]], requires_grad=True) b: tensor([0.2021], requires_grad=True)\n",
      "Epoch: 34400 y: tensor([[2.8052],\n",
      "        [4.4725],\n",
      "        [6.1399],\n",
      "        [7.8072],\n",
      "        [9.4745]], grad_fn=<AddBackward0>) cost: 0.9611492156982422 w: tensor([[0.7323],\n",
      "        [0.9351]], requires_grad=True) b: tensor([0.2028], requires_grad=True)\n",
      "Epoch: 34800 y: tensor([[2.8150],\n",
      "        [4.4881],\n",
      "        [6.1612],\n",
      "        [7.8344],\n",
      "        [9.5075]], grad_fn=<AddBackward0>) cost: 0.9171836972236633 w: tensor([[0.7348],\n",
      "        [0.9383]], requires_grad=True) b: tensor([0.2035], requires_grad=True)\n",
      "Epoch: 35200 y: tensor([[2.8245],\n",
      "        [4.5033],\n",
      "        [6.1821],\n",
      "        [7.8609],\n",
      "        [9.5397]], grad_fn=<AddBackward0>) cost: 0.8752811551094055 w: tensor([[0.7373],\n",
      "        [0.9415]], requires_grad=True) b: tensor([0.2042], requires_grad=True)\n",
      "Epoch: 35600 y: tensor([[2.8337],\n",
      "        [4.5181],\n",
      "        [6.2025],\n",
      "        [7.8868],\n",
      "        [9.5712]], grad_fn=<AddBackward0>) cost: 0.8353169560432434 w: tensor([[0.7398],\n",
      "        [0.9446]], requires_grad=True) b: tensor([0.2048], requires_grad=True)\n",
      "Epoch: 36000 y: tensor([[2.8428],\n",
      "        [4.5326],\n",
      "        [6.2223],\n",
      "        [7.9121],\n",
      "        [9.6019]], grad_fn=<AddBackward0>) cost: 0.7972249984741211 w: tensor([[0.7422],\n",
      "        [0.9476]], requires_grad=True) b: tensor([0.2054], requires_grad=True)\n",
      "Epoch: 36400 y: tensor([[2.8517],\n",
      "        [4.5467],\n",
      "        [6.2418],\n",
      "        [7.9368],\n",
      "        [9.6319]], grad_fn=<AddBackward0>) cost: 0.7608977556228638 w: tensor([[0.7445],\n",
      "        [0.9506]], requires_grad=True) b: tensor([0.2060], requires_grad=True)\n",
      "Epoch: 36800 y: tensor([[2.8603],\n",
      "        [4.5605],\n",
      "        [6.2607],\n",
      "        [7.9609],\n",
      "        [9.6612]], grad_fn=<AddBackward0>) cost: 0.7262572050094604 w: tensor([[0.7468],\n",
      "        [0.9534]], requires_grad=True) b: tensor([0.2066], requires_grad=True)\n",
      "Epoch: 37200 y: tensor([[2.8687],\n",
      "        [4.5740],\n",
      "        [6.2792],\n",
      "        [7.9845],\n",
      "        [9.6898]], grad_fn=<AddBackward0>) cost: 0.6932355165481567 w: tensor([[0.7490],\n",
      "        [0.9563]], requires_grad=True) b: tensor([0.2072], requires_grad=True)\n",
      "Epoch: 37600 y: tensor([[2.8770],\n",
      "        [4.5871],\n",
      "        [6.2973],\n",
      "        [8.0075],\n",
      "        [9.7177]], grad_fn=<AddBackward0>) cost: 0.6617584228515625 w: tensor([[0.7512],\n",
      "        [0.9590]], requires_grad=True) b: tensor([0.2078], requires_grad=True)\n",
      "Epoch: 38000 y: tensor([[2.8850],\n",
      "        [4.6000],\n",
      "        [6.3150],\n",
      "        [8.0299],\n",
      "        [9.7449]], grad_fn=<AddBackward0>) cost: 0.631741464138031 w: tensor([[0.7533],\n",
      "        [0.9617]], requires_grad=True) b: tensor([0.2084], requires_grad=True)\n",
      "Epoch: 38400 y: tensor([[2.8929],\n",
      "        [4.6125],\n",
      "        [6.3322],\n",
      "        [8.0519],\n",
      "        [9.7716]], grad_fn=<AddBackward0>) cost: 0.6031134724617004 w: tensor([[0.7554],\n",
      "        [0.9643]], requires_grad=True) b: tensor([0.2089], requires_grad=True)\n",
      "Epoch: 38800 y: tensor([[2.9005],\n",
      "        [4.6248],\n",
      "        [6.3490],\n",
      "        [8.0733],\n",
      "        [9.7975]], grad_fn=<AddBackward0>) cost: 0.5758307576179504 w: tensor([[0.7574],\n",
      "        [0.9668]], requires_grad=True) b: tensor([0.2094], requires_grad=True)\n",
      "Epoch: 39200 y: tensor([[2.9080],\n",
      "        [4.6367],\n",
      "        [6.3655],\n",
      "        [8.0942],\n",
      "        [9.8229]], grad_fn=<AddBackward0>) cost: 0.5498083233833313 w: tensor([[0.7594],\n",
      "        [0.9693]], requires_grad=True) b: tensor([0.2099], requires_grad=True)\n",
      "Epoch: 39600 y: tensor([[2.9153],\n",
      "        [4.6484],\n",
      "        [6.3815],\n",
      "        [8.1146],\n",
      "        [9.8477]], grad_fn=<AddBackward0>) cost: 0.5250040888786316 w: tensor([[0.7613],\n",
      "        [0.9718]], requires_grad=True) b: tensor([0.2104], requires_grad=True)\n",
      "Epoch: 40000 y: tensor([[2.9224],\n",
      "        [4.6598],\n",
      "        [6.3972],\n",
      "        [8.1345],\n",
      "        [9.8719]], grad_fn=<AddBackward0>) cost: 0.5013427734375 w: tensor([[0.7632],\n",
      "        [0.9742]], requires_grad=True) b: tensor([0.2109], requires_grad=True)\n",
      "Epoch: 40400 y: tensor([[2.9294],\n",
      "        [4.6709],\n",
      "        [6.4125],\n",
      "        [8.1540],\n",
      "        [9.8955]], grad_fn=<AddBackward0>) cost: 0.4787912964820862 w: tensor([[0.7651],\n",
      "        [0.9765]], requires_grad=True) b: tensor([0.2114], requires_grad=True)\n",
      "Epoch: 40800 y: tensor([[2.9362],\n",
      "        [4.6818],\n",
      "        [6.4274],\n",
      "        [8.1730],\n",
      "        [9.9186]], grad_fn=<AddBackward0>) cost: 0.45729532837867737 w: tensor([[0.7669],\n",
      "        [0.9787]], requires_grad=True) b: tensor([0.2119], requires_grad=True)\n",
      "Epoch: 41200 y: tensor([[2.9428],\n",
      "        [4.6924],\n",
      "        [6.4420],\n",
      "        [8.1916],\n",
      "        [9.9411]], grad_fn=<AddBackward0>) cost: 0.4367939531803131 w: tensor([[0.7686],\n",
      "        [0.9810]], requires_grad=True) b: tensor([0.2123], requires_grad=True)\n",
      "Epoch: 41600 y: tensor([[2.9493],\n",
      "        [4.7028],\n",
      "        [6.4562],\n",
      "        [8.2097],\n",
      "        [9.9632]], grad_fn=<AddBackward0>) cost: 0.41724085807800293 w: tensor([[0.7704],\n",
      "        [0.9831]], requires_grad=True) b: tensor([0.2128], requires_grad=True)\n",
      "Epoch: 42000 y: tensor([[2.9557],\n",
      "        [4.7129],\n",
      "        [6.4701],\n",
      "        [8.2274],\n",
      "        [9.9846]], grad_fn=<AddBackward0>) cost: 0.3986034095287323 w: tensor([[0.7720],\n",
      "        [0.9852]], requires_grad=True) b: tensor([0.2132], requires_grad=True)\n",
      "Epoch: 42400 y: tensor([[ 2.9618],\n",
      "        [ 4.7228],\n",
      "        [ 6.4837],\n",
      "        [ 8.2447],\n",
      "        [10.0056]], grad_fn=<AddBackward0>) cost: 0.3808394968509674 w: tensor([[0.7737],\n",
      "        [0.9873]], requires_grad=True) b: tensor([0.2136], requires_grad=True)\n",
      "Epoch: 42800 y: tensor([[ 2.9679],\n",
      "        [ 4.7324],\n",
      "        [ 6.4970],\n",
      "        [ 8.2615],\n",
      "        [10.0261]], grad_fn=<AddBackward0>) cost: 0.3638918995857239 w: tensor([[0.7753],\n",
      "        [0.9893]], requires_grad=True) b: tensor([0.2140], requires_grad=True)\n",
      "Epoch: 43200 y: tensor([[ 2.9737],\n",
      "        [ 4.7418],\n",
      "        [ 6.5099],\n",
      "        [ 8.2780],\n",
      "        [10.0461]], grad_fn=<AddBackward0>) cost: 0.34774312376976013 w: tensor([[0.7768],\n",
      "        [0.9913]], requires_grad=True) b: tensor([0.2144], requires_grad=True)\n",
      "Epoch: 43600 y: tensor([[ 2.9795],\n",
      "        [ 4.7510],\n",
      "        [ 6.5226],\n",
      "        [ 8.2941],\n",
      "        [10.0656]], grad_fn=<AddBackward0>) cost: 0.33233577013015747 w: tensor([[0.7784],\n",
      "        [0.9932]], requires_grad=True) b: tensor([0.2148], requires_grad=True)\n",
      "Epoch: 44000 y: tensor([[ 2.9851],\n",
      "        [ 4.7600],\n",
      "        [ 6.5349],\n",
      "        [ 8.3098],\n",
      "        [10.0847]], grad_fn=<AddBackward0>) cost: 0.3176537752151489 w: tensor([[0.7799],\n",
      "        [0.9950]], requires_grad=True) b: tensor([0.2152], requires_grad=True)\n",
      "Epoch: 44400 y: tensor([[ 2.9906],\n",
      "        [ 4.7688],\n",
      "        [ 6.5470],\n",
      "        [ 8.3251],\n",
      "        [10.1033]], grad_fn=<AddBackward0>) cost: 0.3036487102508545 w: tensor([[0.7813],\n",
      "        [0.9969]], requires_grad=True) b: tensor([0.2155], requires_grad=True)\n",
      "Epoch: 44800 y: tensor([[ 2.9959],\n",
      "        [ 4.7773],\n",
      "        [ 6.5587],\n",
      "        [ 8.3401],\n",
      "        [10.1215]], grad_fn=<AddBackward0>) cost: 0.2903086245059967 w: tensor([[0.7827],\n",
      "        [0.9987]], requires_grad=True) b: tensor([0.2159], requires_grad=True)\n",
      "Epoch: 45200 y: tensor([[ 3.0012],\n",
      "        [ 4.7857],\n",
      "        [ 6.5702],\n",
      "        [ 8.3547],\n",
      "        [10.1393]], grad_fn=<AddBackward0>) cost: 0.27757948637008667 w: tensor([[0.7841],\n",
      "        [1.0004]], requires_grad=True) b: tensor([0.2163], requires_grad=True)\n",
      "Epoch: 45600 y: tensor([[ 3.0063],\n",
      "        [ 4.7938],\n",
      "        [ 6.5814],\n",
      "        [ 8.3690],\n",
      "        [10.1566]], grad_fn=<AddBackward0>) cost: 0.26543718576431274 w: tensor([[0.7855],\n",
      "        [1.0021]], requires_grad=True) b: tensor([0.2166], requires_grad=True)\n",
      "Epoch: 46000 y: tensor([[ 3.0112],\n",
      "        [ 4.8018],\n",
      "        [ 6.5924],\n",
      "        [ 8.3830],\n",
      "        [10.1735]], grad_fn=<AddBackward0>) cost: 0.25385865569114685 w: tensor([[0.7868],\n",
      "        [1.0038]], requires_grad=True) b: tensor([0.2169], requires_grad=True)\n",
      "Epoch: 46400 y: tensor([[ 3.0161],\n",
      "        [ 4.8096],\n",
      "        [ 6.6031],\n",
      "        [ 8.3966],\n",
      "        [10.1901]], grad_fn=<AddBackward0>) cost: 0.24282050132751465 w: tensor([[0.7881],\n",
      "        [1.0054]], requires_grad=True) b: tensor([0.2172], requires_grad=True)\n",
      "Epoch: 46800 y: tensor([[ 3.0208],\n",
      "        [ 4.8172],\n",
      "        [ 6.6135],\n",
      "        [ 8.4099],\n",
      "        [10.2062]], grad_fn=<AddBackward0>) cost: 0.23231306672096252 w: tensor([[0.7894],\n",
      "        [1.0070]], requires_grad=True) b: tensor([0.2176], requires_grad=True)\n",
      "Epoch: 47200 y: tensor([[ 3.0255],\n",
      "        [ 4.8246],\n",
      "        [ 6.6237],\n",
      "        [ 8.4228],\n",
      "        [10.2220]], grad_fn=<AddBackward0>) cost: 0.2222912311553955 w: tensor([[0.7906],\n",
      "        [1.0085]], requires_grad=True) b: tensor([0.2179], requires_grad=True)\n",
      "Epoch: 47600 y: tensor([[ 3.0300],\n",
      "        [ 4.8318],\n",
      "        [ 6.6337],\n",
      "        [ 8.4355],\n",
      "        [10.2374]], grad_fn=<AddBackward0>) cost: 0.21272635459899902 w: tensor([[0.7918],\n",
      "        [1.0100]], requires_grad=True) b: tensor([0.2182], requires_grad=True)\n",
      "Epoch: 48000 y: tensor([[ 3.0344],\n",
      "        [ 4.8389],\n",
      "        [ 6.6434],\n",
      "        [ 8.4479],\n",
      "        [10.2524]], grad_fn=<AddBackward0>) cost: 0.2035870999097824 w: tensor([[0.7930],\n",
      "        [1.0115]], requires_grad=True) b: tensor([0.2184], requires_grad=True)\n",
      "Epoch: 48400 y: tensor([[ 3.0387],\n",
      "        [ 4.8458],\n",
      "        [ 6.6529],\n",
      "        [ 8.4600],\n",
      "        [10.2671]], grad_fn=<AddBackward0>) cost: 0.19491450488567352 w: tensor([[0.7942],\n",
      "        [1.0129]], requires_grad=True) b: tensor([0.2187], requires_grad=True)\n",
      "Epoch: 48800 y: tensor([[ 3.0429],\n",
      "        [ 4.8525],\n",
      "        [ 6.6622],\n",
      "        [ 8.4718],\n",
      "        [10.2814]], grad_fn=<AddBackward0>) cost: 0.1866310089826584 w: tensor([[0.7953],\n",
      "        [1.0143]], requires_grad=True) b: tensor([0.2190], requires_grad=True)\n",
      "Epoch: 49200 y: tensor([[ 3.0470],\n",
      "        [ 4.8591],\n",
      "        [ 6.6712],\n",
      "        [ 8.4833],\n",
      "        [10.2954]], grad_fn=<AddBackward0>) cost: 0.17871105670928955 w: tensor([[0.7964],\n",
      "        [1.0157]], requires_grad=True) b: tensor([0.2193], requires_grad=True)\n",
      "Epoch: 49600 y: tensor([[ 3.0510],\n",
      "        [ 4.8656],\n",
      "        [ 6.6801],\n",
      "        [ 8.4946],\n",
      "        [10.3091]], grad_fn=<AddBackward0>) cost: 0.17117930948734283 w: tensor([[0.7975],\n",
      "        [1.0170]], requires_grad=True) b: tensor([0.2195], requires_grad=True)\n",
      "Epoch: 50000 y: tensor([[ 3.0550],\n",
      "        [ 4.8718],\n",
      "        [ 6.6887],\n",
      "        [ 8.5055],\n",
      "        [10.3224]], grad_fn=<AddBackward0>) cost: 0.16400496661663055 w: tensor([[0.7985],\n",
      "        [1.0183]], requires_grad=True) b: tensor([0.2198], requires_grad=True)\n",
      "Epoch: 50400 y: tensor([[ 3.0588],\n",
      "        [ 4.8780],\n",
      "        [ 6.6971],\n",
      "        [ 8.5163],\n",
      "        [10.3355]], grad_fn=<AddBackward0>) cost: 0.1571359634399414 w: tensor([[0.7996],\n",
      "        [1.0196]], requires_grad=True) b: tensor([0.2200], requires_grad=True)\n",
      "Epoch: 50800 y: tensor([[ 3.0625],\n",
      "        [ 4.8839],\n",
      "        [ 6.7053],\n",
      "        [ 8.5267],\n",
      "        [10.3482]], grad_fn=<AddBackward0>) cost: 0.1506158709526062 w: tensor([[0.8006],\n",
      "        [1.0208]], requires_grad=True) b: tensor([0.2203], requires_grad=True)\n",
      "Epoch: 51200 y: tensor([[ 3.0662],\n",
      "        [ 4.8898],\n",
      "        [ 6.7134],\n",
      "        [ 8.5370],\n",
      "        [10.3606]], grad_fn=<AddBackward0>) cost: 0.14439275860786438 w: tensor([[0.8016],\n",
      "        [1.0221]], requires_grad=True) b: tensor([0.2205], requires_grad=True)\n",
      "Epoch: 51600 y: tensor([[ 3.0697],\n",
      "        [ 4.8955],\n",
      "        [ 6.7212],\n",
      "        [ 8.5470],\n",
      "        [10.3727]], grad_fn=<AddBackward0>) cost: 0.1384345293045044 w: tensor([[0.8025],\n",
      "        [1.0232]], requires_grad=True) b: tensor([0.2207], requires_grad=True)\n",
      "Epoch: 52000 y: tensor([[ 3.0732],\n",
      "        [ 4.9010],\n",
      "        [ 6.7289],\n",
      "        [ 8.5567],\n",
      "        [10.3845]], grad_fn=<AddBackward0>) cost: 0.13279704749584198 w: tensor([[0.8035],\n",
      "        [1.0244]], requires_grad=True) b: tensor([0.2209], requires_grad=True)\n",
      "Epoch: 52400 y: tensor([[ 3.0766],\n",
      "        [ 4.9065],\n",
      "        [ 6.7364],\n",
      "        [ 8.5663],\n",
      "        [10.3961]], grad_fn=<AddBackward0>) cost: 0.12738007307052612 w: tensor([[0.8044],\n",
      "        [1.0255]], requires_grad=True) b: tensor([0.2212], requires_grad=True)\n",
      "Epoch: 52800 y: tensor([[ 3.0799],\n",
      "        [ 4.9118],\n",
      "        [ 6.7436],\n",
      "        [ 8.5755],\n",
      "        [10.4074]], grad_fn=<AddBackward0>) cost: 0.12224797904491425 w: tensor([[0.8053],\n",
      "        [1.0266]], requires_grad=True) b: tensor([0.2214], requires_grad=True)\n",
      "Epoch: 53200 y: tensor([[ 3.0831],\n",
      "        [ 4.9169],\n",
      "        [ 6.7508],\n",
      "        [ 8.5846],\n",
      "        [10.4185]], grad_fn=<AddBackward0>) cost: 0.1173311248421669 w: tensor([[0.8061],\n",
      "        [1.0277]], requires_grad=True) b: tensor([0.2216], requires_grad=True)\n",
      "Epoch: 53600 y: tensor([[ 3.0863],\n",
      "        [ 4.9220],\n",
      "        [ 6.7577],\n",
      "        [ 8.5935],\n",
      "        [10.4292]], grad_fn=<AddBackward0>) cost: 0.11265168339014053 w: tensor([[0.8070],\n",
      "        [1.0288]], requires_grad=True) b: tensor([0.2218], requires_grad=True)\n",
      "Epoch: 54000 y: tensor([[ 3.0893],\n",
      "        [ 4.9269],\n",
      "        [ 6.7645],\n",
      "        [ 8.6021],\n",
      "        [10.4397]], grad_fn=<AddBackward0>) cost: 0.10818883031606674 w: tensor([[0.8078],\n",
      "        [1.0298]], requires_grad=True) b: tensor([0.2220], requires_grad=True)\n",
      "Epoch: 54400 y: tensor([[ 3.0923],\n",
      "        [ 4.9318],\n",
      "        [ 6.7712],\n",
      "        [ 8.6106],\n",
      "        [10.4500]], grad_fn=<AddBackward0>) cost: 0.10393716394901276 w: tensor([[0.8086],\n",
      "        [1.0308]], requires_grad=True) b: tensor([0.2221], requires_grad=True)\n",
      "Epoch: 54800 y: tensor([[ 3.0953],\n",
      "        [ 4.9365],\n",
      "        [ 6.7776],\n",
      "        [ 8.6188],\n",
      "        [10.4600]], grad_fn=<AddBackward0>) cost: 0.09988222271203995 w: tensor([[0.8094],\n",
      "        [1.0318]], requires_grad=True) b: tensor([0.2223], requires_grad=True)\n",
      "Epoch: 55200 y: tensor([[ 3.0981],\n",
      "        [ 4.9411],\n",
      "        [ 6.7840],\n",
      "        [ 8.6269],\n",
      "        [10.4698]], grad_fn=<AddBackward0>) cost: 0.09601185470819473 w: tensor([[0.8102],\n",
      "        [1.0327]], requires_grad=True) b: tensor([0.2225], requires_grad=True)\n",
      "Epoch: 55600 y: tensor([[ 3.1009],\n",
      "        [ 4.9455],\n",
      "        [ 6.7902],\n",
      "        [ 8.6348],\n",
      "        [10.4794]], grad_fn=<AddBackward0>) cost: 0.09231643378734589 w: tensor([[0.8110],\n",
      "        [1.0336]], requires_grad=True) b: tensor([0.2227], requires_grad=True)\n",
      "Epoch: 56000 y: tensor([[ 3.1036],\n",
      "        [ 4.9499],\n",
      "        [ 6.7962],\n",
      "        [ 8.6424],\n",
      "        [10.4887]], grad_fn=<AddBackward0>) cost: 0.08881130069494247 w: tensor([[0.8117],\n",
      "        [1.0345]], requires_grad=True) b: tensor([0.2228], requires_grad=True)\n",
      "Epoch: 56400 y: tensor([[ 3.1063],\n",
      "        [ 4.9542],\n",
      "        [ 6.8021],\n",
      "        [ 8.6500],\n",
      "        [10.4979]], grad_fn=<AddBackward0>) cost: 0.08544424176216125 w: tensor([[0.8124],\n",
      "        [1.0354]], requires_grad=True) b: tensor([0.2230], requires_grad=True)\n",
      "Epoch: 56800 y: tensor([[ 3.1089],\n",
      "        [ 4.9584],\n",
      "        [ 6.8078],\n",
      "        [ 8.6573],\n",
      "        [10.5067]], grad_fn=<AddBackward0>) cost: 0.08225803077220917 w: tensor([[0.8132],\n",
      "        [1.0363]], requires_grad=True) b: tensor([0.2231], requires_grad=True)\n",
      "Epoch: 57200 y: tensor([[ 3.1115],\n",
      "        [ 4.9625],\n",
      "        [ 6.8135],\n",
      "        [ 8.6645],\n",
      "        [10.5155]], grad_fn=<AddBackward0>) cost: 0.07918659597635269 w: tensor([[0.8139],\n",
      "        [1.0372]], requires_grad=True) b: tensor([0.2233], requires_grad=True)\n",
      "Epoch: 57600 y: tensor([[ 3.1139],\n",
      "        [ 4.9664],\n",
      "        [ 6.8189],\n",
      "        [ 8.6714],\n",
      "        [10.5239]], grad_fn=<AddBackward0>) cost: 0.07630688697099686 w: tensor([[0.8145],\n",
      "        [1.0380]], requires_grad=True) b: tensor([0.2234], requires_grad=True)\n",
      "Epoch: 58000 y: tensor([[ 3.1163],\n",
      "        [ 4.9703],\n",
      "        [ 6.8243],\n",
      "        [ 8.6783],\n",
      "        [10.5322]], grad_fn=<AddBackward0>) cost: 0.0735173299908638 w: tensor([[0.8152],\n",
      "        [1.0388]], requires_grad=True) b: tensor([0.2236], requires_grad=True)\n",
      "Epoch: 58400 y: tensor([[ 3.1187],\n",
      "        [ 4.9741],\n",
      "        [ 6.8295],\n",
      "        [ 8.6849],\n",
      "        [10.5403]], grad_fn=<AddBackward0>) cost: 0.0708826333284378 w: tensor([[0.8158],\n",
      "        [1.0396]], requires_grad=True) b: tensor([0.2237], requires_grad=True)\n",
      "Epoch: 58800 y: tensor([[ 3.1210],\n",
      "        [ 4.9778],\n",
      "        [ 6.8346],\n",
      "        [ 8.6914],\n",
      "        [10.5482]], grad_fn=<AddBackward0>) cost: 0.06836899369955063 w: tensor([[0.8165],\n",
      "        [1.0403]], requires_grad=True) b: tensor([0.2239], requires_grad=True)\n",
      "Epoch: 59200 y: tensor([[ 3.1233],\n",
      "        [ 4.9815],\n",
      "        [ 6.8396],\n",
      "        [ 8.6978],\n",
      "        [10.5560]], grad_fn=<AddBackward0>) cost: 0.06593821942806244 w: tensor([[0.8171],\n",
      "        [1.0411]], requires_grad=True) b: tensor([0.2240], requires_grad=True)\n",
      "Epoch: 59600 y: tensor([[ 3.1254],\n",
      "        [ 4.9849],\n",
      "        [ 6.8444],\n",
      "        [ 8.7039],\n",
      "        [10.5635]], grad_fn=<AddBackward0>) cost: 0.06367512047290802 w: tensor([[0.8177],\n",
      "        [1.0418]], requires_grad=True) b: tensor([0.2241], requires_grad=True)\n",
      "Epoch: 60000 y: tensor([[ 3.1276],\n",
      "        [ 4.9884],\n",
      "        [ 6.8492],\n",
      "        [ 8.7100],\n",
      "        [10.5708]], grad_fn=<AddBackward0>) cost: 0.061479829251766205 w: tensor([[0.8183],\n",
      "        [1.0425]], requires_grad=True) b: tensor([0.2242], requires_grad=True)\n",
      "Epoch: 60400 y: tensor([[ 3.1297],\n",
      "        [ 4.9918],\n",
      "        [ 6.8539],\n",
      "        [ 8.7160],\n",
      "        [10.5781]], grad_fn=<AddBackward0>) cost: 0.059386663138866425 w: tensor([[0.8189],\n",
      "        [1.0432]], requires_grad=True) b: tensor([0.2244], requires_grad=True)\n",
      "Epoch: 60800 y: tensor([[ 3.1317],\n",
      "        [ 4.9950],\n",
      "        [ 6.8584],\n",
      "        [ 8.7217],\n",
      "        [10.5850]], grad_fn=<AddBackward0>) cost: 0.05741506814956665 w: tensor([[0.8194],\n",
      "        [1.0439]], requires_grad=True) b: tensor([0.2245], requires_grad=True)\n",
      "Epoch: 61200 y: tensor([[ 3.1337],\n",
      "        [ 4.9983],\n",
      "        [ 6.8628],\n",
      "        [ 8.7273],\n",
      "        [10.5919]], grad_fn=<AddBackward0>) cost: 0.05551880598068237 w: tensor([[0.8200],\n",
      "        [1.0446]], requires_grad=True) b: tensor([0.2246], requires_grad=True)\n",
      "Epoch: 61600 y: tensor([[ 3.1357],\n",
      "        [ 5.0014],\n",
      "        [ 6.8672],\n",
      "        [ 8.7329],\n",
      "        [10.5986]], grad_fn=<AddBackward0>) cost: 0.053695302456617355 w: tensor([[0.8205],\n",
      "        [1.0452]], requires_grad=True) b: tensor([0.2247], requires_grad=True)\n",
      "Epoch: 62000 y: tensor([[ 3.1375],\n",
      "        [ 5.0044],\n",
      "        [ 6.8713],\n",
      "        [ 8.7382],\n",
      "        [10.6051]], grad_fn=<AddBackward0>) cost: 0.051995910704135895 w: tensor([[0.8211],\n",
      "        [1.0458]], requires_grad=True) b: tensor([0.2248], requires_grad=True)\n",
      "Epoch: 62400 y: tensor([[ 3.1394],\n",
      "        [ 5.0074],\n",
      "        [ 6.8755],\n",
      "        [ 8.7435],\n",
      "        [10.6115]], grad_fn=<AddBackward0>) cost: 0.05034387856721878 w: tensor([[0.8216],\n",
      "        [1.0465]], requires_grad=True) b: tensor([0.2249], requires_grad=True)\n",
      "Epoch: 62800 y: tensor([[ 3.1412],\n",
      "        [ 5.0104],\n",
      "        [ 6.8795],\n",
      "        [ 8.7487],\n",
      "        [10.6178]], grad_fn=<AddBackward0>) cost: 0.048761337995529175 w: tensor([[0.8221],\n",
      "        [1.0471]], requires_grad=True) b: tensor([0.2250], requires_grad=True)\n",
      "Epoch: 63200 y: tensor([[ 3.1430],\n",
      "        [ 5.0132],\n",
      "        [ 6.8834],\n",
      "        [ 8.7536],\n",
      "        [10.6238]], grad_fn=<AddBackward0>) cost: 0.04728385806083679 w: tensor([[0.8226],\n",
      "        [1.0477]], requires_grad=True) b: tensor([0.2251], requires_grad=True)\n",
      "Epoch: 63600 y: tensor([[ 3.1447],\n",
      "        [ 5.0159],\n",
      "        [ 6.8872],\n",
      "        [ 8.7585],\n",
      "        [10.6297]], grad_fn=<AddBackward0>) cost: 0.045867227017879486 w: tensor([[0.8230],\n",
      "        [1.0482]], requires_grad=True) b: tensor([0.2252], requires_grad=True)\n",
      "Epoch: 64000 y: tensor([[ 3.1464],\n",
      "        [ 5.0187],\n",
      "        [ 6.8910],\n",
      "        [ 8.7633],\n",
      "        [10.6356]], grad_fn=<AddBackward0>) cost: 0.044484496116638184 w: tensor([[0.8235],\n",
      "        [1.0488]], requires_grad=True) b: tensor([0.2253], requires_grad=True)\n",
      "Epoch: 64400 y: tensor([[ 3.1480],\n",
      "        [ 5.0213],\n",
      "        [ 6.8946],\n",
      "        [ 8.7679],\n",
      "        [10.6413]], grad_fn=<AddBackward0>) cost: 0.04320327192544937 w: tensor([[0.8240],\n",
      "        [1.0493]], requires_grad=True) b: tensor([0.2254], requires_grad=True)\n",
      "Epoch: 64800 y: tensor([[ 3.1496],\n",
      "        [ 5.0239],\n",
      "        [ 6.8982],\n",
      "        [ 8.7725],\n",
      "        [10.6467]], grad_fn=<AddBackward0>) cost: 0.0419761948287487 w: tensor([[0.8244],\n",
      "        [1.0499]], requires_grad=True) b: tensor([0.2254], requires_grad=True)\n",
      "Epoch: 65200 y: tensor([[ 3.1512],\n",
      "        [ 5.0264],\n",
      "        [ 6.9017],\n",
      "        [ 8.7769],\n",
      "        [10.6522]], grad_fn=<AddBackward0>) cost: 0.04079306870698929 w: tensor([[0.8249],\n",
      "        [1.0504]], requires_grad=True) b: tensor([0.2255], requires_grad=True)\n",
      "Epoch: 65600 y: tensor([[ 3.1527],\n",
      "        [ 5.0289],\n",
      "        [ 6.9051],\n",
      "        [ 8.7813],\n",
      "        [10.6575]], grad_fn=<AddBackward0>) cost: 0.03965000435709953 w: tensor([[0.8253],\n",
      "        [1.0509]], requires_grad=True) b: tensor([0.2256], requires_grad=True)\n",
      "Epoch: 66000 y: tensor([[ 3.1542],\n",
      "        [ 5.0313],\n",
      "        [ 6.9084],\n",
      "        [ 8.7855],\n",
      "        [10.6626]], grad_fn=<AddBackward0>) cost: 0.03859109431505203 w: tensor([[0.8257],\n",
      "        [1.0514]], requires_grad=True) b: tensor([0.2257], requires_grad=True)\n",
      "Epoch: 66400 y: tensor([[ 3.1556],\n",
      "        [ 5.0336],\n",
      "        [ 6.9116],\n",
      "        [ 8.7896],\n",
      "        [10.6676]], grad_fn=<AddBackward0>) cost: 0.03758413344621658 w: tensor([[0.8261],\n",
      "        [1.0519]], requires_grad=True) b: tensor([0.2257], requires_grad=True)\n",
      "Epoch: 66800 y: tensor([[ 3.1570],\n",
      "        [ 5.0359],\n",
      "        [ 6.9148],\n",
      "        [ 8.7937],\n",
      "        [10.6726]], grad_fn=<AddBackward0>) cost: 0.03660060837864876 w: tensor([[0.8265],\n",
      "        [1.0523]], requires_grad=True) b: tensor([0.2258], requires_grad=True)\n",
      "Epoch: 67200 y: tensor([[ 3.1585],\n",
      "        [ 5.0382],\n",
      "        [ 6.9180],\n",
      "        [ 8.7977],\n",
      "        [10.6775]], grad_fn=<AddBackward0>) cost: 0.035652197897434235 w: tensor([[0.8269],\n",
      "        [1.0528]], requires_grad=True) b: tensor([0.2259], requires_grad=True)\n",
      "Epoch: 67600 y: tensor([[ 3.1598],\n",
      "        [ 5.0403],\n",
      "        [ 6.9209],\n",
      "        [ 8.8015],\n",
      "        [10.6820]], grad_fn=<AddBackward0>) cost: 0.03478272259235382 w: tensor([[0.8273],\n",
      "        [1.0533]], requires_grad=True) b: tensor([0.2259], requires_grad=True)\n",
      "Epoch: 68000 y: tensor([[ 3.1611],\n",
      "        [ 5.0425],\n",
      "        [ 6.9238],\n",
      "        [ 8.8052],\n",
      "        [10.6866]], grad_fn=<AddBackward0>) cost: 0.03394314646720886 w: tensor([[0.8277],\n",
      "        [1.0537]], requires_grad=True) b: tensor([0.2260], requires_grad=True)\n",
      "Epoch: 68400 y: tensor([[ 3.1624],\n",
      "        [ 5.0445],\n",
      "        [ 6.9267],\n",
      "        [ 8.8089],\n",
      "        [10.6911]], grad_fn=<AddBackward0>) cost: 0.03313704952597618 w: tensor([[0.8281],\n",
      "        [1.0541]], requires_grad=True) b: tensor([0.2261], requires_grad=True)\n",
      "Epoch: 68800 y: tensor([[ 3.1636],\n",
      "        [ 5.0466],\n",
      "        [ 6.9296],\n",
      "        [ 8.8125],\n",
      "        [10.6955]], grad_fn=<AddBackward0>) cost: 0.032358210533857346 w: tensor([[0.8284],\n",
      "        [1.0545]], requires_grad=True) b: tensor([0.2261], requires_grad=True)\n",
      "Epoch: 69200 y: tensor([[ 3.1649],\n",
      "        [ 5.0486],\n",
      "        [ 6.9323],\n",
      "        [ 8.8161],\n",
      "        [10.6998]], grad_fn=<AddBackward0>) cost: 0.031612295657396317 w: tensor([[0.8288],\n",
      "        [1.0550]], requires_grad=True) b: tensor([0.2262], requires_grad=True)\n",
      "Epoch: 69600 y: tensor([[ 3.1660],\n",
      "        [ 5.0505],\n",
      "        [ 6.9350],\n",
      "        [ 8.8194],\n",
      "        [10.7039]], grad_fn=<AddBackward0>) cost: 0.03093084692955017 w: tensor([[0.8291],\n",
      "        [1.0553]], requires_grad=True) b: tensor([0.2262], requires_grad=True)\n",
      "Epoch: 70000 y: tensor([[ 3.1672],\n",
      "        [ 5.0524],\n",
      "        [ 6.9375],\n",
      "        [ 8.8227],\n",
      "        [10.7079]], grad_fn=<AddBackward0>) cost: 0.030272487550973892 w: tensor([[0.8295],\n",
      "        [1.0557]], requires_grad=True) b: tensor([0.2263], requires_grad=True)\n",
      "Epoch: 70400 y: tensor([[ 3.1683],\n",
      "        [ 5.0542],\n",
      "        [ 6.9401],\n",
      "        [ 8.8260],\n",
      "        [10.7119]], grad_fn=<AddBackward0>) cost: 0.029629919677972794 w: tensor([[0.8298],\n",
      "        [1.0561]], requires_grad=True) b: tensor([0.2263], requires_grad=True)\n",
      "Epoch: 70800 y: tensor([[ 3.1695],\n",
      "        [ 5.0561],\n",
      "        [ 6.9427],\n",
      "        [ 8.8292],\n",
      "        [10.7158]], grad_fn=<AddBackward0>) cost: 0.029010092839598656 w: tensor([[0.8301],\n",
      "        [1.0565]], requires_grad=True) b: tensor([0.2264], requires_grad=True)\n",
      "Epoch: 71200 y: tensor([[ 3.1706],\n",
      "        [ 5.0578],\n",
      "        [ 6.9451],\n",
      "        [ 8.8324],\n",
      "        [10.7197]], grad_fn=<AddBackward0>) cost: 0.028425240889191628 w: tensor([[0.8304],\n",
      "        [1.0569]], requires_grad=True) b: tensor([0.2264], requires_grad=True)\n",
      "Epoch: 71600 y: tensor([[ 3.1716],\n",
      "        [ 5.0595],\n",
      "        [ 6.9474],\n",
      "        [ 8.8353],\n",
      "        [10.7233]], grad_fn=<AddBackward0>) cost: 0.027887895703315735 w: tensor([[0.8307],\n",
      "        [1.0572]], requires_grad=True) b: tensor([0.2265], requires_grad=True)\n",
      "Epoch: 72000 y: tensor([[ 3.1726],\n",
      "        [ 5.0612],\n",
      "        [ 6.9497],\n",
      "        [ 8.8383],\n",
      "        [10.7269]], grad_fn=<AddBackward0>) cost: 0.02736285701394081 w: tensor([[0.8310],\n",
      "        [1.0575]], requires_grad=True) b: tensor([0.2265], requires_grad=True)\n",
      "Epoch: 72400 y: tensor([[ 3.1736],\n",
      "        [ 5.0628],\n",
      "        [ 6.9520],\n",
      "        [ 8.8412],\n",
      "        [10.7304]], grad_fn=<AddBackward0>) cost: 0.026865079998970032 w: tensor([[0.8313],\n",
      "        [1.0579]], requires_grad=True) b: tensor([0.2266], requires_grad=True)\n",
      "Epoch: 72800 y: tensor([[ 3.1746],\n",
      "        [ 5.0644],\n",
      "        [ 6.9542],\n",
      "        [ 8.8440],\n",
      "        [10.7338]], grad_fn=<AddBackward0>) cost: 0.026382017880678177 w: tensor([[0.8316],\n",
      "        [1.0582]], requires_grad=True) b: tensor([0.2266], requires_grad=True)\n",
      "Epoch: 73200 y: tensor([[ 3.1756],\n",
      "        [ 5.0660],\n",
      "        [ 6.9564],\n",
      "        [ 8.8469],\n",
      "        [10.7373]], grad_fn=<AddBackward0>) cost: 0.02591026946902275 w: tensor([[0.8319],\n",
      "        [1.0585]], requires_grad=True) b: tensor([0.2266], requires_grad=True)\n",
      "Epoch: 73600 y: tensor([[ 3.1765],\n",
      "        [ 5.0676],\n",
      "        [ 6.9586],\n",
      "        [ 8.8496],\n",
      "        [10.7406]], grad_fn=<AddBackward0>) cost: 0.02546634152531624 w: tensor([[0.8322],\n",
      "        [1.0588]], requires_grad=True) b: tensor([0.2267], requires_grad=True)\n",
      "Epoch: 74000 y: tensor([[ 3.1774],\n",
      "        [ 5.0690],\n",
      "        [ 6.9605],\n",
      "        [ 8.8521],\n",
      "        [10.7437]], grad_fn=<AddBackward0>) cost: 0.02506915107369423 w: tensor([[0.8324],\n",
      "        [1.0591]], requires_grad=True) b: tensor([0.2267], requires_grad=True)\n",
      "Epoch: 74400 y: tensor([[ 3.1783],\n",
      "        [ 5.0704],\n",
      "        [ 6.9625],\n",
      "        [ 8.8546],\n",
      "        [10.7467]], grad_fn=<AddBackward0>) cost: 0.024681057780981064 w: tensor([[0.8327],\n",
      "        [1.0594]], requires_grad=True) b: tensor([0.2267], requires_grad=True)\n",
      "Epoch: 74800 y: tensor([[ 3.1791],\n",
      "        [ 5.0718],\n",
      "        [ 6.9645],\n",
      "        [ 8.8571],\n",
      "        [10.7498]], grad_fn=<AddBackward0>) cost: 0.02430185116827488 w: tensor([[0.8330],\n",
      "        [1.0597]], requires_grad=True) b: tensor([0.2268], requires_grad=True)\n",
      "Epoch: 75200 y: tensor([[ 3.1800],\n",
      "        [ 5.0732],\n",
      "        [ 6.9664],\n",
      "        [ 8.8596],\n",
      "        [10.7529]], grad_fn=<AddBackward0>) cost: 0.02393154427409172 w: tensor([[0.8332],\n",
      "        [1.0600]], requires_grad=True) b: tensor([0.2268], requires_grad=True)\n",
      "Epoch: 75600 y: tensor([[ 3.1808],\n",
      "        [ 5.0746],\n",
      "        [ 6.9683],\n",
      "        [ 8.8621],\n",
      "        [10.7558]], grad_fn=<AddBackward0>) cost: 0.023582156747579575 w: tensor([[0.8335],\n",
      "        [1.0603]], requires_grad=True) b: tensor([0.2268], requires_grad=True)\n",
      "Epoch: 76000 y: tensor([[ 3.1817],\n",
      "        [ 5.0759],\n",
      "        [ 6.9702],\n",
      "        [ 8.8645],\n",
      "        [10.7588]], grad_fn=<AddBackward0>) cost: 0.02324400097131729 w: tensor([[0.8337],\n",
      "        [1.0606]], requires_grad=True) b: tensor([0.2268], requires_grad=True)\n",
      "Epoch: 76400 y: tensor([[ 3.1824],\n",
      "        [ 5.0772],\n",
      "        [ 6.9720],\n",
      "        [ 8.8667],\n",
      "        [10.7615]], grad_fn=<AddBackward0>) cost: 0.022934701293706894 w: tensor([[0.8340],\n",
      "        [1.0608]], requires_grad=True) b: tensor([0.2269], requires_grad=True)\n",
      "Epoch: 76800 y: tensor([[ 3.1832],\n",
      "        [ 5.0784],\n",
      "        [ 6.9737],\n",
      "        [ 8.8689],\n",
      "        [10.7641]], grad_fn=<AddBackward0>) cost: 0.022642377763986588 w: tensor([[0.8342],\n",
      "        [1.0611]], requires_grad=True) b: tensor([0.2269], requires_grad=True)\n",
      "Epoch: 77200 y: tensor([[ 3.1839],\n",
      "        [ 5.0796],\n",
      "        [ 6.9753],\n",
      "        [ 8.8711],\n",
      "        [10.7668]], grad_fn=<AddBackward0>) cost: 0.022358296439051628 w: tensor([[0.8344],\n",
      "        [1.0613]], requires_grad=True) b: tensor([0.2269], requires_grad=True)\n",
      "Epoch: 77600 y: tensor([[ 3.1846],\n",
      "        [ 5.0808],\n",
      "        [ 6.9770],\n",
      "        [ 8.8731],\n",
      "        [10.7693]], grad_fn=<AddBackward0>) cost: 0.022092636674642563 w: tensor([[0.8346],\n",
      "        [1.0615]], requires_grad=True) b: tensor([0.2269], requires_grad=True)\n",
      "Epoch: 78000 y: tensor([[ 3.1853],\n",
      "        [ 5.0819],\n",
      "        [ 6.9786],\n",
      "        [ 8.8752],\n",
      "        [10.7718]], grad_fn=<AddBackward0>) cost: 0.0218330267816782 w: tensor([[0.8349],\n",
      "        [1.0618]], requires_grad=True) b: tensor([0.2269], requires_grad=True)\n",
      "Epoch: 78400 y: tensor([[ 3.1860],\n",
      "        [ 5.0831],\n",
      "        [ 6.9802],\n",
      "        [ 8.8773],\n",
      "        [10.7743]], grad_fn=<AddBackward0>) cost: 0.0215794425457716 w: tensor([[0.8351],\n",
      "        [1.0620]], requires_grad=True) b: tensor([0.2269], requires_grad=True)\n",
      "Epoch: 78800 y: tensor([[ 3.1867],\n",
      "        [ 5.0843],\n",
      "        [ 6.9818],\n",
      "        [ 8.8793],\n",
      "        [10.7769]], grad_fn=<AddBackward0>) cost: 0.021332014352083206 w: tensor([[0.8353],\n",
      "        [1.0622]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 79200 y: tensor([[ 3.1874],\n",
      "        [ 5.0854],\n",
      "        [ 6.9834],\n",
      "        [ 8.8814],\n",
      "        [10.7794]], grad_fn=<AddBackward0>) cost: 0.021090807393193245 w: tensor([[0.8355],\n",
      "        [1.0625]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 79600 y: tensor([[ 3.1881],\n",
      "        [ 5.0864],\n",
      "        [ 6.9848],\n",
      "        [ 8.8832],\n",
      "        [10.7816]], grad_fn=<AddBackward0>) cost: 0.020883653312921524 w: tensor([[0.8357],\n",
      "        [1.0627]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 80000 y: tensor([[ 3.1886],\n",
      "        [ 5.0874],\n",
      "        [ 6.9862],\n",
      "        [ 8.8849],\n",
      "        [10.7837]], grad_fn=<AddBackward0>) cost: 0.020689858123660088 w: tensor([[0.8359],\n",
      "        [1.0629]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 80400 y: tensor([[ 3.1892],\n",
      "        [ 5.0884],\n",
      "        [ 6.9875],\n",
      "        [ 8.8867],\n",
      "        [10.7858]], grad_fn=<AddBackward0>) cost: 0.020500145852565765 w: tensor([[0.8361],\n",
      "        [1.0631]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 80800 y: tensor([[ 3.1898],\n",
      "        [ 5.0893],\n",
      "        [ 6.9889],\n",
      "        [ 8.8884],\n",
      "        [10.7879]], grad_fn=<AddBackward0>) cost: 0.020314736291766167 w: tensor([[0.8363],\n",
      "        [1.0633]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 81200 y: tensor([[ 3.1904],\n",
      "        [ 5.0903],\n",
      "        [ 6.9902],\n",
      "        [ 8.8901],\n",
      "        [10.7900]], grad_fn=<AddBackward0>) cost: 0.020133662968873978 w: tensor([[0.8365],\n",
      "        [1.0635]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 81600 y: tensor([[ 3.1910],\n",
      "        [ 5.0913],\n",
      "        [ 6.9915],\n",
      "        [ 8.8918],\n",
      "        [10.7921]], grad_fn=<AddBackward0>) cost: 0.01995663531124592 w: tensor([[0.8366],\n",
      "        [1.0636]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 82000 y: tensor([[ 3.1915],\n",
      "        [ 5.0922],\n",
      "        [ 6.9928],\n",
      "        [ 8.8935],\n",
      "        [10.7941]], grad_fn=<AddBackward0>) cost: 0.019791502505540848 w: tensor([[0.8368],\n",
      "        [1.0638]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 82400 y: tensor([[ 3.1921],\n",
      "        [ 5.0931],\n",
      "        [ 6.9941],\n",
      "        [ 8.8951],\n",
      "        [10.7961]], grad_fn=<AddBackward0>) cost: 0.019633065909147263 w: tensor([[0.8370],\n",
      "        [1.0640]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 82800 y: tensor([[ 3.1926],\n",
      "        [ 5.0940],\n",
      "        [ 6.9954],\n",
      "        [ 8.8967],\n",
      "        [10.7981]], grad_fn=<AddBackward0>) cost: 0.01947837881743908 w: tensor([[0.8372],\n",
      "        [1.0642]], requires_grad=True) b: tensor([0.2271], requires_grad=True)\n",
      "Epoch: 83200 y: tensor([[ 3.1932],\n",
      "        [ 5.0949],\n",
      "        [ 6.9966],\n",
      "        [ 8.8984],\n",
      "        [10.8001]], grad_fn=<AddBackward0>) cost: 0.01932734064757824 w: tensor([[0.8373],\n",
      "        [1.0644]], requires_grad=True) b: tensor([0.2271], requires_grad=True)\n",
      "Epoch: 83600 y: tensor([[ 3.1937],\n",
      "        [ 5.0957],\n",
      "        [ 6.9978],\n",
      "        [ 8.8998],\n",
      "        [10.8018]], grad_fn=<AddBackward0>) cost: 0.019194914028048515 w: tensor([[0.8375],\n",
      "        [1.0646]], requires_grad=True) b: tensor([0.2271], requires_grad=True)\n",
      "Epoch: 84000 y: tensor([[ 3.1941],\n",
      "        [ 5.0965],\n",
      "        [ 6.9988],\n",
      "        [ 8.9012],\n",
      "        [10.8035]], grad_fn=<AddBackward0>) cost: 0.01907007396221161 w: tensor([[0.8377],\n",
      "        [1.0647]], requires_grad=True) b: tensor([0.2271], requires_grad=True)\n",
      "Epoch: 84400 y: tensor([[ 3.1946],\n",
      "        [ 5.0972],\n",
      "        [ 6.9999],\n",
      "        [ 8.9026],\n",
      "        [10.8052]], grad_fn=<AddBackward0>) cost: 0.018947770819067955 w: tensor([[0.8378],\n",
      "        [1.0648]], requires_grad=True) b: tensor([0.2271], requires_grad=True)\n",
      "Epoch: 84800 y: tensor([[ 3.1950],\n",
      "        [ 5.0980],\n",
      "        [ 7.0009],\n",
      "        [ 8.9039],\n",
      "        [10.8068]], grad_fn=<AddBackward0>) cost: 0.018834391608834267 w: tensor([[0.8380],\n",
      "        [1.0650]], requires_grad=True) b: tensor([0.2271], requires_grad=True)\n",
      "Epoch: 85200 y: tensor([[ 3.1954],\n",
      "        [ 5.0987],\n",
      "        [ 7.0019],\n",
      "        [ 8.9052],\n",
      "        [10.8084]], grad_fn=<AddBackward0>) cost: 0.01872636005282402 w: tensor([[0.8381],\n",
      "        [1.0651]], requires_grad=True) b: tensor([0.2271], requires_grad=True)\n",
      "Epoch: 85600 y: tensor([[ 3.1959],\n",
      "        [ 5.0994],\n",
      "        [ 7.0029],\n",
      "        [ 8.9065],\n",
      "        [10.8100]], grad_fn=<AddBackward0>) cost: 0.018620656803250313 w: tensor([[0.8383],\n",
      "        [1.0653]], requires_grad=True) b: tensor([0.2271], requires_grad=True)\n",
      "Epoch: 86000 y: tensor([[ 3.1963],\n",
      "        [ 5.1001],\n",
      "        [ 7.0039],\n",
      "        [ 8.9077],\n",
      "        [10.8116]], grad_fn=<AddBackward0>) cost: 0.01851724274456501 w: tensor([[0.8384],\n",
      "        [1.0654]], requires_grad=True) b: tensor([0.2271], requires_grad=True)\n",
      "Epoch: 86400 y: tensor([[ 3.1967],\n",
      "        [ 5.1008],\n",
      "        [ 7.0049],\n",
      "        [ 8.9090],\n",
      "        [10.8131]], grad_fn=<AddBackward0>) cost: 0.018416237086057663 w: tensor([[0.8385],\n",
      "        [1.0656]], requires_grad=True) b: tensor([0.2271], requires_grad=True)\n",
      "Epoch: 86800 y: tensor([[ 3.1971],\n",
      "        [ 5.1015],\n",
      "        [ 7.0059],\n",
      "        [ 8.9103],\n",
      "        [10.8147]], grad_fn=<AddBackward0>) cost: 0.018317410722374916 w: tensor([[0.8387],\n",
      "        [1.0657]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 87200 y: tensor([[ 3.1976],\n",
      "        [ 5.1022],\n",
      "        [ 7.0069],\n",
      "        [ 8.9116],\n",
      "        [10.8163]], grad_fn=<AddBackward0>) cost: 0.018220916390419006 w: tensor([[0.8388],\n",
      "        [1.0658]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 87600 y: tensor([[ 3.1980],\n",
      "        [ 5.1029],\n",
      "        [ 7.0079],\n",
      "        [ 8.9129],\n",
      "        [10.8178]], grad_fn=<AddBackward0>) cost: 0.0181267112493515 w: tensor([[0.8390],\n",
      "        [1.0660]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 88000 y: tensor([[ 3.1984],\n",
      "        [ 5.1036],\n",
      "        [ 7.0089],\n",
      "        [ 8.9141],\n",
      "        [10.8194]], grad_fn=<AddBackward0>) cost: 0.01803739368915558 w: tensor([[0.8391],\n",
      "        [1.0661]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 88400 y: tensor([[ 3.1988],\n",
      "        [ 5.1043],\n",
      "        [ 7.0098],\n",
      "        [ 8.9153],\n",
      "        [10.8208]], grad_fn=<AddBackward0>) cost: 0.017955357208848 w: tensor([[0.8392],\n",
      "        [1.0663]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 88800 y: tensor([[ 3.1991],\n",
      "        [ 5.1048],\n",
      "        [ 7.0106],\n",
      "        [ 8.9163],\n",
      "        [10.8220]], grad_fn=<AddBackward0>) cost: 0.017886731773614883 w: tensor([[0.8393],\n",
      "        [1.0664]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 89200 y: tensor([[ 3.1994],\n",
      "        [ 5.1054],\n",
      "        [ 7.0113],\n",
      "        [ 8.9172],\n",
      "        [10.8232]], grad_fn=<AddBackward0>) cost: 0.017821991816163063 w: tensor([[0.8395],\n",
      "        [1.0665]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 89600 y: tensor([[ 3.1997],\n",
      "        [ 5.1059],\n",
      "        [ 7.0120],\n",
      "        [ 8.9182],\n",
      "        [10.8243]], grad_fn=<AddBackward0>) cost: 0.01775827445089817 w: tensor([[0.8396],\n",
      "        [1.0666]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 90000 y: tensor([[ 3.2000],\n",
      "        [ 5.1064],\n",
      "        [ 7.0128],\n",
      "        [ 8.9191],\n",
      "        [10.8255]], grad_fn=<AddBackward0>) cost: 0.017695898190140724 w: tensor([[0.8397],\n",
      "        [1.0667]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 90400 y: tensor([[ 3.2003],\n",
      "        [ 5.1069],\n",
      "        [ 7.0135],\n",
      "        [ 8.9201],\n",
      "        [10.8267]], grad_fn=<AddBackward0>) cost: 0.017634663730859756 w: tensor([[0.8398],\n",
      "        [1.0668]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 90800 y: tensor([[ 3.2006],\n",
      "        [ 5.1074],\n",
      "        [ 7.0142],\n",
      "        [ 8.9210],\n",
      "        [10.8278]], grad_fn=<AddBackward0>) cost: 0.017574770376086235 w: tensor([[0.8399],\n",
      "        [1.0669]], requires_grad=True) b: tensor([0.2270], requires_grad=True)\n",
      "Epoch: 91200 y: tensor([[ 3.2009],\n",
      "        [ 5.1079],\n",
      "        [ 7.0149],\n",
      "        [ 8.9220],\n",
      "        [10.8290]], grad_fn=<AddBackward0>) cost: 0.01751602254807949 w: tensor([[0.8401],\n",
      "        [1.0670]], requires_grad=True) b: tensor([0.2269], requires_grad=True)\n",
      "Epoch: 91600 y: tensor([[ 3.2012],\n",
      "        [ 5.1084],\n",
      "        [ 7.0157],\n",
      "        [ 8.9229],\n",
      "        [10.8301]], grad_fn=<AddBackward0>) cost: 0.017458610236644745 w: tensor([[0.8402],\n",
      "        [1.0670]], requires_grad=True) b: tensor([0.2269], requires_grad=True)\n",
      "Epoch: 92000 y: tensor([[ 3.2015],\n",
      "        [ 5.1090],\n",
      "        [ 7.0164],\n",
      "        [ 8.9238],\n",
      "        [10.8313]], grad_fn=<AddBackward0>) cost: 0.017402347177267075 w: tensor([[0.8403],\n",
      "        [1.0671]], requires_grad=True) b: tensor([0.2269], requires_grad=True)\n",
      "Epoch: 92400 y: tensor([[ 3.2018],\n",
      "        [ 5.1095],\n",
      "        [ 7.0171],\n",
      "        [ 8.9248],\n",
      "        [10.8324]], grad_fn=<AddBackward0>) cost: 0.01734931394457817 w: tensor([[0.8404],\n",
      "        [1.0672]], requires_grad=True) b: tensor([0.2269], requires_grad=True)\n",
      "Epoch: 92800 y: tensor([[ 3.2021],\n",
      "        [ 5.1099],\n",
      "        [ 7.0178],\n",
      "        [ 8.9256],\n",
      "        [10.8334]], grad_fn=<AddBackward0>) cost: 0.017301736399531364 w: tensor([[0.8405],\n",
      "        [1.0673]], requires_grad=True) b: tensor([0.2269], requires_grad=True)\n",
      "Epoch: 93200 y: tensor([[ 3.2023],\n",
      "        [ 5.1104],\n",
      "        [ 7.0184],\n",
      "        [ 8.9264],\n",
      "        [10.8345]], grad_fn=<AddBackward0>) cost: 0.017255261540412903 w: tensor([[0.8406],\n",
      "        [1.0674]], requires_grad=True) b: tensor([0.2269], requires_grad=True)\n",
      "Epoch: 93600 y: tensor([[ 3.2026],\n",
      "        [ 5.1108],\n",
      "        [ 7.0191],\n",
      "        [ 8.9273],\n",
      "        [10.8355]], grad_fn=<AddBackward0>) cost: 0.017209533601999283 w: tensor([[0.8407],\n",
      "        [1.0675]], requires_grad=True) b: tensor([0.2269], requires_grad=True)\n",
      "Epoch: 94000 y: tensor([[ 3.2029],\n",
      "        [ 5.1113],\n",
      "        [ 7.0197],\n",
      "        [ 8.9281],\n",
      "        [10.8365]], grad_fn=<AddBackward0>) cost: 0.017164787277579308 w: tensor([[0.8408],\n",
      "        [1.0676]], requires_grad=True) b: tensor([0.2269], requires_grad=True)\n",
      "Epoch: 94400 y: tensor([[ 3.2032],\n",
      "        [ 5.1118],\n",
      "        [ 7.0204],\n",
      "        [ 8.9290],\n",
      "        [10.8376]], grad_fn=<AddBackward0>) cost: 0.01712103560566902 w: tensor([[0.8409],\n",
      "        [1.0677]], requires_grad=True) b: tensor([0.2268], requires_grad=True)\n",
      "Epoch: 94800 y: tensor([[ 3.2034],\n",
      "        [ 5.1122],\n",
      "        [ 7.0210],\n",
      "        [ 8.9298],\n",
      "        [10.8386]], grad_fn=<AddBackward0>) cost: 0.017078205943107605 w: tensor([[0.8410],\n",
      "        [1.0678]], requires_grad=True) b: tensor([0.2268], requires_grad=True)\n",
      "Epoch: 95200 y: tensor([[ 3.2037],\n",
      "        [ 5.1127],\n",
      "        [ 7.0217],\n",
      "        [ 8.9306],\n",
      "        [10.8396]], grad_fn=<AddBackward0>) cost: 0.017036456614732742 w: tensor([[0.8411],\n",
      "        [1.0679]], requires_grad=True) b: tensor([0.2268], requires_grad=True)\n",
      "Epoch: 95600 y: tensor([[ 3.2040],\n",
      "        [ 5.1131],\n",
      "        [ 7.0223],\n",
      "        [ 8.9315],\n",
      "        [10.8407]], grad_fn=<AddBackward0>) cost: 0.01699567213654518 w: tensor([[0.8412],\n",
      "        [1.0680]], requires_grad=True) b: tensor([0.2268], requires_grad=True)\n",
      "Epoch: 96000 y: tensor([[ 3.2042],\n",
      "        [ 5.1136],\n",
      "        [ 7.0230],\n",
      "        [ 8.9323],\n",
      "        [10.8417]], grad_fn=<AddBackward0>) cost: 0.016955874860286713 w: tensor([[0.8413],\n",
      "        [1.0681]], requires_grad=True) b: tensor([0.2268], requires_grad=True)\n",
      "Epoch: 96400 y: tensor([[ 3.2044],\n",
      "        [ 5.1139],\n",
      "        [ 7.0234],\n",
      "        [ 8.9329],\n",
      "        [10.8424]], grad_fn=<AddBackward0>) cost: 0.016925346106290817 w: tensor([[0.8414],\n",
      "        [1.0681]], requires_grad=True) b: tensor([0.2267], requires_grad=True)\n",
      "Epoch: 96800 y: tensor([[ 3.2046],\n",
      "        [ 5.1142],\n",
      "        [ 7.0239],\n",
      "        [ 8.9335],\n",
      "        [10.8432]], grad_fn=<AddBackward0>) cost: 0.01689526066184044 w: tensor([[0.8415],\n",
      "        [1.0682]], requires_grad=True) b: tensor([0.2267], requires_grad=True)\n",
      "Epoch: 97200 y: tensor([[ 3.2047],\n",
      "        [ 5.1145],\n",
      "        [ 7.0243],\n",
      "        [ 8.9341],\n",
      "        [10.8439]], grad_fn=<AddBackward0>) cost: 0.016865750774741173 w: tensor([[0.8416],\n",
      "        [1.0682]], requires_grad=True) b: tensor([0.2267], requires_grad=True)\n",
      "Epoch: 97600 y: tensor([[ 3.2049],\n",
      "        [ 5.1149],\n",
      "        [ 7.0248],\n",
      "        [ 8.9347],\n",
      "        [10.8447]], grad_fn=<AddBackward0>) cost: 0.0168367438018322 w: tensor([[0.8417],\n",
      "        [1.0683]], requires_grad=True) b: tensor([0.2267], requires_grad=True)\n",
      "Epoch: 98000 y: tensor([[ 3.2051],\n",
      "        [ 5.1152],\n",
      "        [ 7.0252],\n",
      "        [ 8.9353],\n",
      "        [10.8454]], grad_fn=<AddBackward0>) cost: 0.016808968037366867 w: tensor([[0.8417],\n",
      "        [1.0683]], requires_grad=True) b: tensor([0.2267], requires_grad=True)\n",
      "Epoch: 98400 y: tensor([[ 3.2052],\n",
      "        [ 5.1154],\n",
      "        [ 7.0256],\n",
      "        [ 8.9358],\n",
      "        [10.8460]], grad_fn=<AddBackward0>) cost: 0.01678578183054924 w: tensor([[0.8418],\n",
      "        [1.0684]], requires_grad=True) b: tensor([0.2267], requires_grad=True)\n",
      "Epoch: 98800 y: tensor([[ 3.2054],\n",
      "        [ 5.1157],\n",
      "        [ 7.0260],\n",
      "        [ 8.9363],\n",
      "        [10.8467]], grad_fn=<AddBackward0>) cost: 0.01676303707063198 w: tensor([[0.8419],\n",
      "        [1.0684]], requires_grad=True) b: tensor([0.2266], requires_grad=True)\n",
      "Epoch: 99200 y: tensor([[ 3.2055],\n",
      "        [ 5.1160],\n",
      "        [ 7.0264],\n",
      "        [ 8.9368],\n",
      "        [10.8473]], grad_fn=<AddBackward0>) cost: 0.016740350052714348 w: tensor([[0.8420],\n",
      "        [1.0685]], requires_grad=True) b: tensor([0.2266], requires_grad=True)\n",
      "Epoch: 99600 y: tensor([[ 3.2057],\n",
      "        [ 5.1162],\n",
      "        [ 7.0268],\n",
      "        [ 8.9373],\n",
      "        [10.8479]], grad_fn=<AddBackward0>) cost: 0.01671796292066574 w: tensor([[0.8420],\n",
      "        [1.0685]], requires_grad=True) b: tensor([0.2266], requires_grad=True)\n",
      "Epoch: 100000 y: tensor([[ 3.2058],\n",
      "        [ 5.1165],\n",
      "        [ 7.0272],\n",
      "        [ 8.9378],\n",
      "        [10.8485]], grad_fn=<AddBackward0>) cost: 0.01669592410326004 w: tensor([[0.8421],\n",
      "        [1.0686]], requires_grad=True) b: tensor([0.2266], requires_grad=True)\n",
      "Epoch: 100400 y: tensor([[ 3.2060],\n",
      "        [ 5.1168],\n",
      "        [ 7.0275],\n",
      "        [ 8.9383],\n",
      "        [10.8491]], grad_fn=<AddBackward0>) cost: 0.016674231737852097 w: tensor([[0.8422],\n",
      "        [1.0686]], requires_grad=True) b: tensor([0.2265], requires_grad=True)\n",
      "Epoch: 100800 y: tensor([[ 3.2061],\n",
      "        [ 5.1170],\n",
      "        [ 7.0279],\n",
      "        [ 8.9388],\n",
      "        [10.8498]], grad_fn=<AddBackward0>) cost: 0.01665288768708706 w: tensor([[0.8422],\n",
      "        [1.0687]], requires_grad=True) b: tensor([0.2265], requires_grad=True)\n",
      "Epoch: 101200 y: tensor([[ 3.2062],\n",
      "        [ 5.1173],\n",
      "        [ 7.0283],\n",
      "        [ 8.9393],\n",
      "        [10.8504]], grad_fn=<AddBackward0>) cost: 0.01663189008831978 w: tensor([[0.8423],\n",
      "        [1.0687]], requires_grad=True) b: tensor([0.2265], requires_grad=True)\n",
      "Epoch: 101600 y: tensor([[ 3.2064],\n",
      "        [ 5.1175],\n",
      "        [ 7.0287],\n",
      "        [ 8.9398],\n",
      "        [10.8510]], grad_fn=<AddBackward0>) cost: 0.016611242666840553 w: tensor([[0.8424],\n",
      "        [1.0688]], requires_grad=True) b: tensor([0.2265], requires_grad=True)\n",
      "Epoch: 102000 y: tensor([[ 3.2065],\n",
      "        [ 5.1178],\n",
      "        [ 7.0291],\n",
      "        [ 8.9403],\n",
      "        [10.8516]], grad_fn=<AddBackward0>) cost: 0.016590941697359085 w: tensor([[0.8425],\n",
      "        [1.0688]], requires_grad=True) b: tensor([0.2265], requires_grad=True)\n",
      "Epoch: 102400 y: tensor([[ 3.2067],\n",
      "        [ 5.1181],\n",
      "        [ 7.0295],\n",
      "        [ 8.9408],\n",
      "        [10.8522]], grad_fn=<AddBackward0>) cost: 0.016570989042520523 w: tensor([[0.8425],\n",
      "        [1.0689]], requires_grad=True) b: tensor([0.2264], requires_grad=True)\n",
      "Epoch: 102800 y: tensor([[ 3.2068],\n",
      "        [ 5.1183],\n",
      "        [ 7.0298],\n",
      "        [ 8.9413],\n",
      "        [10.8529]], grad_fn=<AddBackward0>) cost: 0.016551386564970016 w: tensor([[0.8426],\n",
      "        [1.0689]], requires_grad=True) b: tensor([0.2264], requires_grad=True)\n",
      "Epoch: 103200 y: tensor([[ 3.2070],\n",
      "        [ 5.1186],\n",
      "        [ 7.0302],\n",
      "        [ 8.9418],\n",
      "        [10.8535]], grad_fn=<AddBackward0>) cost: 0.01653212681412697 w: tensor([[0.8427],\n",
      "        [1.0690]], requires_grad=True) b: tensor([0.2264], requires_grad=True)\n",
      "Epoch: 103600 y: tensor([[ 3.2071],\n",
      "        [ 5.1189],\n",
      "        [ 7.0306],\n",
      "        [ 8.9423],\n",
      "        [10.8541]], grad_fn=<AddBackward0>) cost: 0.016513219103217125 w: tensor([[0.8427],\n",
      "        [1.0690]], requires_grad=True) b: tensor([0.2264], requires_grad=True)\n",
      "Epoch: 104000 y: tensor([[ 3.2072],\n",
      "        [ 5.1191],\n",
      "        [ 7.0310],\n",
      "        [ 8.9429],\n",
      "        [10.8547]], grad_fn=<AddBackward0>) cost: 0.01649465784430504 w: tensor([[0.8428],\n",
      "        [1.0690]], requires_grad=True) b: tensor([0.2263], requires_grad=True)\n",
      "Epoch: 104400 y: tensor([[ 3.2074],\n",
      "        [ 5.1194],\n",
      "        [ 7.0314],\n",
      "        [ 8.9434],\n",
      "        [10.8553]], grad_fn=<AddBackward0>) cost: 0.016476446762681007 w: tensor([[0.8429],\n",
      "        [1.0691]], requires_grad=True) b: tensor([0.2263], requires_grad=True)\n",
      "Epoch: 104800 y: tensor([[ 3.2075],\n",
      "        [ 5.1196],\n",
      "        [ 7.0317],\n",
      "        [ 8.9439],\n",
      "        [10.8560]], grad_fn=<AddBackward0>) cost: 0.016458580270409584 w: tensor([[0.8430],\n",
      "        [1.0691]], requires_grad=True) b: tensor([0.2263], requires_grad=True)\n",
      "Epoch: 105200 y: tensor([[ 3.2077],\n",
      "        [ 5.1199],\n",
      "        [ 7.0321],\n",
      "        [ 8.9444],\n",
      "        [10.8566]], grad_fn=<AddBackward0>) cost: 0.016441062092781067 w: tensor([[0.8430],\n",
      "        [1.0692]], requires_grad=True) b: tensor([0.2263], requires_grad=True)\n",
      "Epoch: 105600 y: tensor([[ 3.2078],\n",
      "        [ 5.1202],\n",
      "        [ 7.0325],\n",
      "        [ 8.9449],\n",
      "        [10.8572]], grad_fn=<AddBackward0>) cost: 0.016423892229795456 w: tensor([[0.8431],\n",
      "        [1.0692]], requires_grad=True) b: tensor([0.2262], requires_grad=True)\n",
      "Epoch: 106000 y: tensor([[ 3.2080],\n",
      "        [ 5.1204],\n",
      "        [ 7.0329],\n",
      "        [ 8.9454],\n",
      "        [10.8578]], grad_fn=<AddBackward0>) cost: 0.01640707068145275 w: tensor([[0.8432],\n",
      "        [1.0693]], requires_grad=True) b: tensor([0.2262], requires_grad=True)\n",
      "Epoch: 106400 y: tensor([[ 3.2081],\n",
      "        [ 5.1207],\n",
      "        [ 7.0333],\n",
      "        [ 8.9459],\n",
      "        [10.8584]], grad_fn=<AddBackward0>) cost: 0.016390595585107803 w: tensor([[0.8432],\n",
      "        [1.0693]], requires_grad=True) b: tensor([0.2262], requires_grad=True)\n",
      "Epoch: 106800 y: tensor([[ 3.2082],\n",
      "        [ 5.1209],\n",
      "        [ 7.0336],\n",
      "        [ 8.9463],\n",
      "        [10.8590]], grad_fn=<AddBackward0>) cost: 0.01637662574648857 w: tensor([[0.8433],\n",
      "        [1.0694]], requires_grad=True) b: tensor([0.2262], requires_grad=True)\n",
      "Epoch: 107200 y: tensor([[ 3.2083],\n",
      "        [ 5.1211],\n",
      "        [ 7.0339],\n",
      "        [ 8.9467],\n",
      "        [10.8595]], grad_fn=<AddBackward0>) cost: 0.016363825649023056 w: tensor([[0.8434],\n",
      "        [1.0694]], requires_grad=True) b: tensor([0.2261], requires_grad=True)\n",
      "Epoch: 107600 y: tensor([[ 3.2085],\n",
      "        [ 5.1213],\n",
      "        [ 7.0342],\n",
      "        [ 8.9471],\n",
      "        [10.8600]], grad_fn=<AddBackward0>) cost: 0.016351278871297836 w: tensor([[0.8434],\n",
      "        [1.0695]], requires_grad=True) b: tensor([0.2261], requires_grad=True)\n",
      "Epoch: 108000 y: tensor([[ 3.2086],\n",
      "        [ 5.1215],\n",
      "        [ 7.0345],\n",
      "        [ 8.9475],\n",
      "        [10.8605]], grad_fn=<AddBackward0>) cost: 0.016338922083377838 w: tensor([[0.8434],\n",
      "        [1.0695]], requires_grad=True) b: tensor([0.2261], requires_grad=True)\n",
      "Epoch: 108400 y: tensor([[ 3.2087],\n",
      "        [ 5.1218],\n",
      "        [ 7.0348],\n",
      "        [ 8.9479],\n",
      "        [10.8610]], grad_fn=<AddBackward0>) cost: 0.016326891258358955 w: tensor([[0.8435],\n",
      "        [1.0696]], requires_grad=True) b: tensor([0.2260], requires_grad=True)\n",
      "Epoch: 108800 y: tensor([[ 3.2088],\n",
      "        [ 5.1220],\n",
      "        [ 7.0351],\n",
      "        [ 8.9483],\n",
      "        [10.8615]], grad_fn=<AddBackward0>) cost: 0.016314975917339325 w: tensor([[0.8435],\n",
      "        [1.0696]], requires_grad=True) b: tensor([0.2260], requires_grad=True)\n",
      "Epoch: 109200 y: tensor([[ 3.2089],\n",
      "        [ 5.1222],\n",
      "        [ 7.0354],\n",
      "        [ 8.9487],\n",
      "        [10.8619]], grad_fn=<AddBackward0>) cost: 0.01630331389605999 w: tensor([[0.8436],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2260], requires_grad=True)\n",
      "Epoch: 109600 y: tensor([[ 3.2090],\n",
      "        [ 5.1224],\n",
      "        [ 7.0357],\n",
      "        [ 8.9491],\n",
      "        [10.8624]], grad_fn=<AddBackward0>) cost: 0.016291843727231026 w: tensor([[0.8436],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2260], requires_grad=True)\n",
      "Epoch: 110000 y: tensor([[ 3.2091],\n",
      "        [ 5.1225],\n",
      "        [ 7.0359],\n",
      "        [ 8.9493],\n",
      "        [10.8628]], grad_fn=<AddBackward0>) cost: 0.0162823386490345 w: tensor([[0.8437],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2259], requires_grad=True)\n",
      "Epoch: 110400 y: tensor([[ 3.2091],\n",
      "        [ 5.1226],\n",
      "        [ 7.0360],\n",
      "        [ 8.9495],\n",
      "        [10.8630]], grad_fn=<AddBackward0>) cost: 0.016273943707346916 w: tensor([[0.8437],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2259], requires_grad=True)\n",
      "Epoch: 110800 y: tensor([[ 3.2091],\n",
      "        [ 5.1226],\n",
      "        [ 7.0361],\n",
      "        [ 8.9497],\n",
      "        [10.8632]], grad_fn=<AddBackward0>) cost: 0.016265617683529854 w: tensor([[0.8438],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2259], requires_grad=True)\n",
      "Epoch: 111200 y: tensor([[ 3.2091],\n",
      "        [ 5.1227],\n",
      "        [ 7.0363],\n",
      "        [ 8.9498],\n",
      "        [10.8634]], grad_fn=<AddBackward0>) cost: 0.01625729352235794 w: tensor([[0.8438],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2258], requires_grad=True)\n",
      "Epoch: 111600 y: tensor([[ 3.2092],\n",
      "        [ 5.1228],\n",
      "        [ 7.0364],\n",
      "        [ 8.9500],\n",
      "        [10.8636]], grad_fn=<AddBackward0>) cost: 0.01624910533428192 w: tensor([[0.8439],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2258], requires_grad=True)\n",
      "Epoch: 112000 y: tensor([[ 3.2092],\n",
      "        [ 5.1228],\n",
      "        [ 7.0365],\n",
      "        [ 8.9501],\n",
      "        [10.8638]], grad_fn=<AddBackward0>) cost: 0.01624085195362568 w: tensor([[0.8439],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2258], requires_grad=True)\n",
      "Epoch: 112400 y: tensor([[ 3.2092],\n",
      "        [ 5.1229],\n",
      "        [ 7.0366],\n",
      "        [ 8.9503],\n",
      "        [10.8640]], grad_fn=<AddBackward0>) cost: 0.01623266376554966 w: tensor([[0.8440],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2257], requires_grad=True)\n",
      "Epoch: 112800 y: tensor([[ 3.2092],\n",
      "        [ 5.1230],\n",
      "        [ 7.0367],\n",
      "        [ 8.9505],\n",
      "        [10.8642]], grad_fn=<AddBackward0>) cost: 0.01622447744011879 w: tensor([[0.8440],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2257], requires_grad=True)\n",
      "Epoch: 113200 y: tensor([[ 3.2092],\n",
      "        [ 5.1230],\n",
      "        [ 7.0368],\n",
      "        [ 8.9506],\n",
      "        [10.8644]], grad_fn=<AddBackward0>) cost: 0.01621643267571926 w: tensor([[0.8441],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2257], requires_grad=True)\n",
      "Epoch: 113600 y: tensor([[ 3.2092],\n",
      "        [ 5.1231],\n",
      "        [ 7.0369],\n",
      "        [ 8.9508],\n",
      "        [10.8646]], grad_fn=<AddBackward0>) cost: 0.016208317130804062 w: tensor([[0.8441],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2257], requires_grad=True)\n",
      "Epoch: 114000 y: tensor([[ 3.2093],\n",
      "        [ 5.1232],\n",
      "        [ 7.0371],\n",
      "        [ 8.9510],\n",
      "        [10.8649]], grad_fn=<AddBackward0>) cost: 0.016200268641114235 w: tensor([[0.8442],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2256], requires_grad=True)\n",
      "Epoch: 114400 y: tensor([[ 3.2093],\n",
      "        [ 5.1232],\n",
      "        [ 7.0372],\n",
      "        [ 8.9511],\n",
      "        [10.8651]], grad_fn=<AddBackward0>) cost: 0.016192220151424408 w: tensor([[0.8442],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2256], requires_grad=True)\n",
      "Epoch: 114800 y: tensor([[ 3.2093],\n",
      "        [ 5.1233],\n",
      "        [ 7.0373],\n",
      "        [ 8.9513],\n",
      "        [10.8653]], grad_fn=<AddBackward0>) cost: 0.016184311360120773 w: tensor([[0.8443],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2256], requires_grad=True)\n",
      "Epoch: 115200 y: tensor([[ 3.2093],\n",
      "        [ 5.1234],\n",
      "        [ 7.0374],\n",
      "        [ 8.9514],\n",
      "        [10.8655]], grad_fn=<AddBackward0>) cost: 0.016176337376236916 w: tensor([[0.8443],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2255], requires_grad=True)\n",
      "Epoch: 115600 y: tensor([[ 3.2093],\n",
      "        [ 5.1234],\n",
      "        [ 7.0375],\n",
      "        [ 8.9516],\n",
      "        [10.8657]], grad_fn=<AddBackward0>) cost: 0.01616842672228813 w: tensor([[0.8444],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2255], requires_grad=True)\n",
      "Epoch: 116000 y: tensor([[ 3.2093],\n",
      "        [ 5.1235],\n",
      "        [ 7.0376],\n",
      "        [ 8.9518],\n",
      "        [10.8659]], grad_fn=<AddBackward0>) cost: 0.016160521656274796 w: tensor([[0.8444],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2255], requires_grad=True)\n",
      "Epoch: 116400 y: tensor([[ 3.2094],\n",
      "        [ 5.1236],\n",
      "        [ 7.0377],\n",
      "        [ 8.9519],\n",
      "        [10.8661]], grad_fn=<AddBackward0>) cost: 0.016152748838067055 w: tensor([[0.8444],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2254], requires_grad=True)\n",
      "Epoch: 116800 y: tensor([[ 3.2094],\n",
      "        [ 5.1236],\n",
      "        [ 7.0378],\n",
      "        [ 8.9521],\n",
      "        [10.8663]], grad_fn=<AddBackward0>) cost: 0.01614491268992424 w: tensor([[0.8445],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2254], requires_grad=True)\n",
      "Epoch: 117200 y: tensor([[ 3.2094],\n",
      "        [ 5.1237],\n",
      "        [ 7.0380],\n",
      "        [ 8.9522],\n",
      "        [10.8665]], grad_fn=<AddBackward0>) cost: 0.01613714173436165 w: tensor([[0.8445],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2254], requires_grad=True)\n",
      "Epoch: 117600 y: tensor([[ 3.2094],\n",
      "        [ 5.1237],\n",
      "        [ 7.0381],\n",
      "        [ 8.9524],\n",
      "        [10.8667]], grad_fn=<AddBackward0>) cost: 0.016129374504089355 w: tensor([[0.8446],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2254], requires_grad=True)\n",
      "Epoch: 118000 y: tensor([[ 3.2094],\n",
      "        [ 5.1238],\n",
      "        [ 7.0382],\n",
      "        [ 8.9526],\n",
      "        [10.8669]], grad_fn=<AddBackward0>) cost: 0.016121741384267807 w: tensor([[0.8446],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2253], requires_grad=True)\n",
      "Epoch: 118400 y: tensor([[ 3.2095],\n",
      "        [ 5.1239],\n",
      "        [ 7.0383],\n",
      "        [ 8.9527],\n",
      "        [10.8671]], grad_fn=<AddBackward0>) cost: 0.016114044934511185 w: tensor([[0.8447],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2253], requires_grad=True)\n",
      "Epoch: 118800 y: tensor([[ 3.2095],\n",
      "        [ 5.1239],\n",
      "        [ 7.0384],\n",
      "        [ 8.9529],\n",
      "        [10.8674]], grad_fn=<AddBackward0>) cost: 0.016106413677334785 w: tensor([[0.8447],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2253], requires_grad=True)\n",
      "Epoch: 119200 y: tensor([[ 3.2095],\n",
      "        [ 5.1240],\n",
      "        [ 7.0385],\n",
      "        [ 8.9530],\n",
      "        [10.8676]], grad_fn=<AddBackward0>) cost: 0.016098784282803535 w: tensor([[0.8448],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2252], requires_grad=True)\n",
      "Epoch: 119600 y: tensor([[ 3.2095],\n",
      "        [ 5.1241],\n",
      "        [ 7.0386],\n",
      "        [ 8.9532],\n",
      "        [10.8678]], grad_fn=<AddBackward0>) cost: 0.01609129086136818 w: tensor([[0.8448],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2252], requires_grad=True)\n",
      "Epoch: 120000 y: tensor([[ 3.2095],\n",
      "        [ 5.1241],\n",
      "        [ 7.0388],\n",
      "        [ 8.9534],\n",
      "        [10.8680]], grad_fn=<AddBackward0>) cost: 0.0160837322473526 w: tensor([[0.8449],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2252], requires_grad=True)\n",
      "Epoch: 120400 y: tensor([[ 3.2095],\n",
      "        [ 5.1242],\n",
      "        [ 7.0389],\n",
      "        [ 8.9535],\n",
      "        [10.8682]], grad_fn=<AddBackward0>) cost: 0.016076240688562393 w: tensor([[0.8449],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2251], requires_grad=True)\n",
      "Epoch: 120800 y: tensor([[ 3.2096],\n",
      "        [ 5.1243],\n",
      "        [ 7.0390],\n",
      "        [ 8.9537],\n",
      "        [10.8684]], grad_fn=<AddBackward0>) cost: 0.016068750992417336 w: tensor([[0.8450],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2251], requires_grad=True)\n",
      "Epoch: 121200 y: tensor([[ 3.2096],\n",
      "        [ 5.1243],\n",
      "        [ 7.0391],\n",
      "        [ 8.9538],\n",
      "        [10.8686]], grad_fn=<AddBackward0>) cost: 0.016061395406723022 w: tensor([[0.8450],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2251], requires_grad=True)\n",
      "Epoch: 121600 y: tensor([[ 3.2096],\n",
      "        [ 5.1244],\n",
      "        [ 7.0392],\n",
      "        [ 8.9540],\n",
      "        [10.8688]], grad_fn=<AddBackward0>) cost: 0.016053976491093636 w: tensor([[0.8451],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2251], requires_grad=True)\n",
      "Epoch: 122000 y: tensor([[ 3.2096],\n",
      "        [ 5.1245],\n",
      "        [ 7.0393],\n",
      "        [ 8.9542],\n",
      "        [10.8690]], grad_fn=<AddBackward0>) cost: 0.016046622768044472 w: tensor([[0.8451],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2250], requires_grad=True)\n",
      "Epoch: 122400 y: tensor([[ 3.2096],\n",
      "        [ 5.1245],\n",
      "        [ 7.0394],\n",
      "        [ 8.9543],\n",
      "        [10.8692]], grad_fn=<AddBackward0>) cost: 0.016039270907640457 w: tensor([[0.8452],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2250], requires_grad=True)\n",
      "Epoch: 122800 y: tensor([[ 3.2097],\n",
      "        [ 5.1246],\n",
      "        [ 7.0395],\n",
      "        [ 8.9545],\n",
      "        [10.8694]], grad_fn=<AddBackward0>) cost: 0.016032056882977486 w: tensor([[0.8452],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2250], requires_grad=True)\n",
      "Epoch: 123200 y: tensor([[ 3.2097],\n",
      "        [ 5.1247],\n",
      "        [ 7.0397],\n",
      "        [ 8.9547],\n",
      "        [10.8696]], grad_fn=<AddBackward0>) cost: 0.016024775803089142 w: tensor([[0.8453],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2249], requires_grad=True)\n",
      "Epoch: 123600 y: tensor([[ 3.2097],\n",
      "        [ 5.1247],\n",
      "        [ 7.0398],\n",
      "        [ 8.9548],\n",
      "        [10.8699]], grad_fn=<AddBackward0>) cost: 0.01601755991578102 w: tensor([[0.8453],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2249], requires_grad=True)\n",
      "Epoch: 124000 y: tensor([[ 3.2097],\n",
      "        [ 5.1248],\n",
      "        [ 7.0399],\n",
      "        [ 8.9550],\n",
      "        [10.8701]], grad_fn=<AddBackward0>) cost: 0.016010349616408348 w: tensor([[0.8454],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2249], requires_grad=True)\n",
      "Epoch: 124400 y: tensor([[ 3.2097],\n",
      "        [ 5.1249],\n",
      "        [ 7.0400],\n",
      "        [ 8.9551],\n",
      "        [10.8703]], grad_fn=<AddBackward0>) cost: 0.01600326970219612 w: tensor([[0.8454],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2249], requires_grad=True)\n",
      "Epoch: 124800 y: tensor([[ 3.2097],\n",
      "        [ 5.1249],\n",
      "        [ 7.0401],\n",
      "        [ 8.9553],\n",
      "        [10.8705]], grad_fn=<AddBackward0>) cost: 0.01599613018333912 w: tensor([[0.8455],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2248], requires_grad=True)\n",
      "Epoch: 125200 y: tensor([[ 3.2098],\n",
      "        [ 5.1250],\n",
      "        [ 7.0402],\n",
      "        [ 8.9555],\n",
      "        [10.8707]], grad_fn=<AddBackward0>) cost: 0.01598905585706234 w: tensor([[0.8455],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2248], requires_grad=True)\n",
      "Epoch: 125600 y: tensor([[ 3.2098],\n",
      "        [ 5.1251],\n",
      "        [ 7.0403],\n",
      "        [ 8.9556],\n",
      "        [10.8709]], grad_fn=<AddBackward0>) cost: 0.01598198339343071 w: tensor([[0.8455],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2248], requires_grad=True)\n",
      "Epoch: 126000 y: tensor([[ 3.2098],\n",
      "        [ 5.1251],\n",
      "        [ 7.0405],\n",
      "        [ 8.9558],\n",
      "        [10.8711]], grad_fn=<AddBackward0>) cost: 0.015975045040249825 w: tensor([[0.8456],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2247], requires_grad=True)\n",
      "Epoch: 126400 y: tensor([[ 3.2098],\n",
      "        [ 5.1252],\n",
      "        [ 7.0406],\n",
      "        [ 8.9559],\n",
      "        [10.8713]], grad_fn=<AddBackward0>) cost: 0.015968041494488716 w: tensor([[0.8456],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2247], requires_grad=True)\n",
      "Epoch: 126800 y: tensor([[ 3.2098],\n",
      "        [ 5.1253],\n",
      "        [ 7.0407],\n",
      "        [ 8.9561],\n",
      "        [10.8715]], grad_fn=<AddBackward0>) cost: 0.01596110686659813 w: tensor([[0.8457],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2247], requires_grad=True)\n",
      "Epoch: 127200 y: tensor([[ 3.2098],\n",
      "        [ 5.1253],\n",
      "        [ 7.0408],\n",
      "        [ 8.9563],\n",
      "        [10.8717]], grad_fn=<AddBackward0>) cost: 0.01595417410135269 w: tensor([[0.8457],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2246], requires_grad=True)\n",
      "Epoch: 127600 y: tensor([[ 3.2099],\n",
      "        [ 5.1254],\n",
      "        [ 7.0409],\n",
      "        [ 8.9564],\n",
      "        [10.8719]], grad_fn=<AddBackward0>) cost: 0.0159473717212677 w: tensor([[0.8458],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2246], requires_grad=True)\n",
      "Epoch: 128000 y: tensor([[ 3.2099],\n",
      "        [ 5.1255],\n",
      "        [ 7.0410],\n",
      "        [ 8.9566],\n",
      "        [10.8722]], grad_fn=<AddBackward0>) cost: 0.015940332785248756 w: tensor([[0.8458],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2246], requires_grad=True)\n",
      "Epoch: 128400 y: tensor([[ 3.2099],\n",
      "        [ 5.1255],\n",
      "        [ 7.0411],\n",
      "        [ 8.9567],\n",
      "        [10.8724]], grad_fn=<AddBackward0>) cost: 0.015933077782392502 w: tensor([[0.8459],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2245], requires_grad=True)\n",
      "Epoch: 128800 y: tensor([[ 3.2099],\n",
      "        [ 5.1256],\n",
      "        [ 7.0412],\n",
      "        [ 8.9569],\n",
      "        [10.8726]], grad_fn=<AddBackward0>) cost: 0.01592579111456871 w: tensor([[0.8459],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2245], requires_grad=True)\n",
      "Epoch: 129200 y: tensor([[ 3.2099],\n",
      "        [ 5.1256],\n",
      "        [ 7.0413],\n",
      "        [ 8.9570],\n",
      "        [10.8727]], grad_fn=<AddBackward0>) cost: 0.015919286757707596 w: tensor([[0.8460],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2245], requires_grad=True)\n",
      "Epoch: 129600 y: tensor([[ 3.2099],\n",
      "        [ 5.1256],\n",
      "        [ 7.0414],\n",
      "        [ 8.9571],\n",
      "        [10.8728]], grad_fn=<AddBackward0>) cost: 0.015914220362901688 w: tensor([[0.8460],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2244], requires_grad=True)\n",
      "Epoch: 130000 y: tensor([[ 3.2099],\n",
      "        [ 5.1256],\n",
      "        [ 7.0414],\n",
      "        [ 8.9571],\n",
      "        [10.8729]], grad_fn=<AddBackward0>) cost: 0.01590912602841854 w: tensor([[0.8460],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2244], requires_grad=True)\n",
      "Epoch: 130400 y: tensor([[ 3.2099],\n",
      "        [ 5.1256],\n",
      "        [ 7.0414],\n",
      "        [ 8.9572],\n",
      "        [10.8730]], grad_fn=<AddBackward0>) cost: 0.015904070809483528 w: tensor([[0.8460],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2244], requires_grad=True)\n",
      "Epoch: 130800 y: tensor([[ 3.2099],\n",
      "        [ 5.1257],\n",
      "        [ 7.0415],\n",
      "        [ 8.9573],\n",
      "        [10.8731]], grad_fn=<AddBackward0>) cost: 0.015898987650871277 w: tensor([[0.8461],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2243], requires_grad=True)\n",
      "Epoch: 131200 y: tensor([[ 3.2099],\n",
      "        [ 5.1257],\n",
      "        [ 7.0415],\n",
      "        [ 8.9573],\n",
      "        [10.8731]], grad_fn=<AddBackward0>) cost: 0.01589393988251686 w: tensor([[0.8461],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2243], requires_grad=True)\n",
      "Epoch: 131600 y: tensor([[ 3.2098],\n",
      "        [ 5.1257],\n",
      "        [ 7.0415],\n",
      "        [ 8.9574],\n",
      "        [10.8732]], grad_fn=<AddBackward0>) cost: 0.015888867899775505 w: tensor([[0.8461],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2243], requires_grad=True)\n",
      "Epoch: 132000 y: tensor([[ 3.2098],\n",
      "        [ 5.1257],\n",
      "        [ 7.0416],\n",
      "        [ 8.9574],\n",
      "        [10.8733]], grad_fn=<AddBackward0>) cost: 0.015883831307291985 w: tensor([[0.8461],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2242], requires_grad=True)\n",
      "Epoch: 132400 y: tensor([[ 3.2098],\n",
      "        [ 5.1257],\n",
      "        [ 7.0416],\n",
      "        [ 8.9575],\n",
      "        [10.8734]], grad_fn=<AddBackward0>) cost: 0.015878768637776375 w: tensor([[0.8462],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2242], requires_grad=True)\n",
      "Epoch: 132800 y: tensor([[ 3.2098],\n",
      "        [ 5.1257],\n",
      "        [ 7.0416],\n",
      "        [ 8.9576],\n",
      "        [10.8735]], grad_fn=<AddBackward0>) cost: 0.0158737413585186 w: tensor([[0.8462],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2242], requires_grad=True)\n",
      "Epoch: 133200 y: tensor([[ 3.2098],\n",
      "        [ 5.1257],\n",
      "        [ 7.0417],\n",
      "        [ 8.9576],\n",
      "        [10.8736]], grad_fn=<AddBackward0>) cost: 0.01586868427693844 w: tensor([[0.8462],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2241], requires_grad=True)\n",
      "Epoch: 133600 y: tensor([[ 3.2098],\n",
      "        [ 5.1257],\n",
      "        [ 7.0417],\n",
      "        [ 8.9577],\n",
      "        [10.8736]], grad_fn=<AddBackward0>) cost: 0.01586366817355156 w: tensor([[0.8462],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2241], requires_grad=True)\n",
      "Epoch: 134000 y: tensor([[ 3.2098],\n",
      "        [ 5.1258],\n",
      "        [ 7.0417],\n",
      "        [ 8.9577],\n",
      "        [10.8737]], grad_fn=<AddBackward0>) cost: 0.015858624130487442 w: tensor([[0.8463],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2240], requires_grad=True)\n",
      "Epoch: 134400 y: tensor([[ 3.2098],\n",
      "        [ 5.1258],\n",
      "        [ 7.0418],\n",
      "        [ 8.9578],\n",
      "        [10.8738]], grad_fn=<AddBackward0>) cost: 0.01585361547768116 w: tensor([[0.8463],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2240], requires_grad=True)\n",
      "Epoch: 134800 y: tensor([[ 3.2097],\n",
      "        [ 5.1258],\n",
      "        [ 7.0418],\n",
      "        [ 8.9579],\n",
      "        [10.8739]], grad_fn=<AddBackward0>) cost: 0.01584858074784279 w: tensor([[0.8463],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2240], requires_grad=True)\n",
      "Epoch: 135200 y: tensor([[ 3.2097],\n",
      "        [ 5.1258],\n",
      "        [ 7.0419],\n",
      "        [ 8.9579],\n",
      "        [10.8740]], grad_fn=<AddBackward0>) cost: 0.015843583270907402 w: tensor([[0.8463],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2239], requires_grad=True)\n",
      "Epoch: 135600 y: tensor([[ 3.2097],\n",
      "        [ 5.1258],\n",
      "        [ 7.0419],\n",
      "        [ 8.9580],\n",
      "        [10.8741]], grad_fn=<AddBackward0>) cost: 0.015838557854294777 w: tensor([[0.8463],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2239], requires_grad=True)\n",
      "Epoch: 136000 y: tensor([[ 3.2097],\n",
      "        [ 5.1258],\n",
      "        [ 7.0419],\n",
      "        [ 8.9580],\n",
      "        [10.8741]], grad_fn=<AddBackward0>) cost: 0.015833567827939987 w: tensor([[0.8464],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2239], requires_grad=True)\n",
      "Epoch: 136400 y: tensor([[ 3.2097],\n",
      "        [ 5.1258],\n",
      "        [ 7.0420],\n",
      "        [ 8.9581],\n",
      "        [10.8742]], grad_fn=<AddBackward0>) cost: 0.015828553587198257 w: tensor([[0.8464],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2238], requires_grad=True)\n",
      "Epoch: 136800 y: tensor([[ 3.2097],\n",
      "        [ 5.1258],\n",
      "        [ 7.0420],\n",
      "        [ 8.9581],\n",
      "        [10.8743]], grad_fn=<AddBackward0>) cost: 0.015823574736714363 w: tensor([[0.8464],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2238], requires_grad=True)\n",
      "Epoch: 137200 y: tensor([[ 3.2097],\n",
      "        [ 5.1259],\n",
      "        [ 7.0420],\n",
      "        [ 8.9582],\n",
      "        [10.8744]], grad_fn=<AddBackward0>) cost: 0.01581856794655323 w: tensor([[0.8464],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2238], requires_grad=True)\n",
      "Epoch: 137600 y: tensor([[ 3.2097],\n",
      "        [ 5.1259],\n",
      "        [ 7.0421],\n",
      "        [ 8.9583],\n",
      "        [10.8745]], grad_fn=<AddBackward0>) cost: 0.01581360027194023 w: tensor([[0.8465],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2237], requires_grad=True)\n",
      "Epoch: 138000 y: tensor([[ 3.2096],\n",
      "        [ 5.1259],\n",
      "        [ 7.0421],\n",
      "        [ 8.9583],\n",
      "        [10.8746]], grad_fn=<AddBackward0>) cost: 0.015808602795004845 w: tensor([[0.8465],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2237], requires_grad=True)\n",
      "Epoch: 138400 y: tensor([[ 3.2096],\n",
      "        [ 5.1259],\n",
      "        [ 7.0421],\n",
      "        [ 8.9584],\n",
      "        [10.8746]], grad_fn=<AddBackward0>) cost: 0.015803644433617592 w: tensor([[0.8465],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2237], requires_grad=True)\n",
      "Epoch: 138800 y: tensor([[ 3.2096],\n",
      "        [ 5.1259],\n",
      "        [ 7.0422],\n",
      "        [ 8.9584],\n",
      "        [10.8747]], grad_fn=<AddBackward0>) cost: 0.01579865626990795 w: tensor([[0.8465],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2236], requires_grad=True)\n",
      "Epoch: 139200 y: tensor([[ 3.2096],\n",
      "        [ 5.1259],\n",
      "        [ 7.0422],\n",
      "        [ 8.9585],\n",
      "        [10.8748]], grad_fn=<AddBackward0>) cost: 0.015793709084391594 w: tensor([[0.8466],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2236], requires_grad=True)\n",
      "Epoch: 139600 y: tensor([[ 3.2096],\n",
      "        [ 5.1259],\n",
      "        [ 7.0422],\n",
      "        [ 8.9586],\n",
      "        [10.8749]], grad_fn=<AddBackward0>) cost: 0.0157887302339077 w: tensor([[0.8466],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2235], requires_grad=True)\n",
      "Epoch: 140000 y: tensor([[ 3.2096],\n",
      "        [ 5.1259],\n",
      "        [ 7.0423],\n",
      "        [ 8.9586],\n",
      "        [10.8750]], grad_fn=<AddBackward0>) cost: 0.01578379049897194 w: tensor([[0.8466],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2235], requires_grad=True)\n",
      "Epoch: 140400 y: tensor([[ 3.2096],\n",
      "        [ 5.1259],\n",
      "        [ 7.0423],\n",
      "        [ 8.9587],\n",
      "        [10.8751]], grad_fn=<AddBackward0>) cost: 0.01577882096171379 w: tensor([[0.8466],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2235], requires_grad=True)\n",
      "Epoch: 140800 y: tensor([[ 3.2096],\n",
      "        [ 5.1260],\n",
      "        [ 7.0424],\n",
      "        [ 8.9587],\n",
      "        [10.8751]], grad_fn=<AddBackward0>) cost: 0.015773894265294075 w: tensor([[0.8467],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2234], requires_grad=True)\n",
      "Epoch: 141200 y: tensor([[ 3.2096],\n",
      "        [ 5.1260],\n",
      "        [ 7.0424],\n",
      "        [ 8.9588],\n",
      "        [10.8752]], grad_fn=<AddBackward0>) cost: 0.015768934041261673 w: tensor([[0.8467],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2234], requires_grad=True)\n",
      "Epoch: 141600 y: tensor([[ 3.2095],\n",
      "        [ 5.1260],\n",
      "        [ 7.0424],\n",
      "        [ 8.9589],\n",
      "        [10.8753]], grad_fn=<AddBackward0>) cost: 0.015764012932777405 w: tensor([[0.8467],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2234], requires_grad=True)\n",
      "Epoch: 142000 y: tensor([[ 3.2095],\n",
      "        [ 5.1260],\n",
      "        [ 7.0425],\n",
      "        [ 8.9589],\n",
      "        [10.8754]], grad_fn=<AddBackward0>) cost: 0.015759065747261047 w: tensor([[0.8467],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2233], requires_grad=True)\n",
      "Epoch: 142400 y: tensor([[ 3.2095],\n",
      "        [ 5.1260],\n",
      "        [ 7.0425],\n",
      "        [ 8.9590],\n",
      "        [10.8755]], grad_fn=<AddBackward0>) cost: 0.015754155814647675 w: tensor([[0.8468],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2233], requires_grad=True)\n",
      "Epoch: 142800 y: tensor([[ 3.2095],\n",
      "        [ 5.1260],\n",
      "        [ 7.0425],\n",
      "        [ 8.9590],\n",
      "        [10.8756]], grad_fn=<AddBackward0>) cost: 0.015749216079711914 w: tensor([[0.8468],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2233], requires_grad=True)\n",
      "Epoch: 143200 y: tensor([[ 3.2095],\n",
      "        [ 5.1260],\n",
      "        [ 7.0426],\n",
      "        [ 8.9591],\n",
      "        [10.8756]], grad_fn=<AddBackward0>) cost: 0.015744313597679138 w: tensor([[0.8468],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2232], requires_grad=True)\n",
      "Epoch: 143600 y: tensor([[ 3.2095],\n",
      "        [ 5.1260],\n",
      "        [ 7.0426],\n",
      "        [ 8.9592],\n",
      "        [10.8757]], grad_fn=<AddBackward0>) cost: 0.015739385038614273 w: tensor([[0.8468],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2232], requires_grad=True)\n",
      "Epoch: 144000 y: tensor([[ 3.2095],\n",
      "        [ 5.1261],\n",
      "        [ 7.0426],\n",
      "        [ 8.9592],\n",
      "        [10.8758]], grad_fn=<AddBackward0>) cost: 0.015734493732452393 w: tensor([[0.8468],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2232], requires_grad=True)\n",
      "Epoch: 144400 y: tensor([[ 3.2095],\n",
      "        [ 5.1261],\n",
      "        [ 7.0427],\n",
      "        [ 8.9593],\n",
      "        [10.8759]], grad_fn=<AddBackward0>) cost: 0.015729574486613274 w: tensor([[0.8469],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2231], requires_grad=True)\n",
      "Epoch: 144800 y: tensor([[ 3.2094],\n",
      "        [ 5.1261],\n",
      "        [ 7.0427],\n",
      "        [ 8.9593],\n",
      "        [10.8760]], grad_fn=<AddBackward0>) cost: 0.01572469249367714 w: tensor([[0.8469],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2231], requires_grad=True)\n",
      "Epoch: 145200 y: tensor([[ 3.2094],\n",
      "        [ 5.1261],\n",
      "        [ 7.0427],\n",
      "        [ 8.9594],\n",
      "        [10.8761]], grad_fn=<AddBackward0>) cost: 0.015719782561063766 w: tensor([[0.8469],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2230], requires_grad=True)\n",
      "Epoch: 145600 y: tensor([[ 3.2094],\n",
      "        [ 5.1261],\n",
      "        [ 7.0428],\n",
      "        [ 8.9595],\n",
      "        [10.8761]], grad_fn=<AddBackward0>) cost: 0.01571490988135338 w: tensor([[0.8469],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2230], requires_grad=True)\n",
      "Epoch: 146000 y: tensor([[ 3.2094],\n",
      "        [ 5.1261],\n",
      "        [ 7.0428],\n",
      "        [ 8.9595],\n",
      "        [10.8762]], grad_fn=<AddBackward0>) cost: 0.0157100111246109 w: tensor([[0.8470],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2230], requires_grad=True)\n",
      "Epoch: 146400 y: tensor([[ 3.2094],\n",
      "        [ 5.1261],\n",
      "        [ 7.0429],\n",
      "        [ 8.9596],\n",
      "        [10.8763]], grad_fn=<AddBackward0>) cost: 0.01570514775812626 w: tensor([[0.8470],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2229], requires_grad=True)\n",
      "Epoch: 146800 y: tensor([[ 3.2094],\n",
      "        [ 5.1261],\n",
      "        [ 7.0429],\n",
      "        [ 8.9596],\n",
      "        [10.8764]], grad_fn=<AddBackward0>) cost: 0.015700258314609528 w: tensor([[0.8470],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2229], requires_grad=True)\n",
      "Epoch: 147200 y: tensor([[ 3.2094],\n",
      "        [ 5.1261],\n",
      "        [ 7.0429],\n",
      "        [ 8.9597],\n",
      "        [10.8765]], grad_fn=<AddBackward0>) cost: 0.01569540612399578 w: tensor([[0.8470],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2229], requires_grad=True)\n",
      "Epoch: 147600 y: tensor([[ 3.2094],\n",
      "        [ 5.1262],\n",
      "        [ 7.0430],\n",
      "        [ 8.9598],\n",
      "        [10.8766]], grad_fn=<AddBackward0>) cost: 0.015690524131059647 w: tensor([[0.8471],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2228], requires_grad=True)\n",
      "Epoch: 148000 y: tensor([[ 3.2094],\n",
      "        [ 5.1262],\n",
      "        [ 7.0430],\n",
      "        [ 8.9598],\n",
      "        [10.8766]], grad_fn=<AddBackward0>) cost: 0.015685681253671646 w: tensor([[0.8471],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2228], requires_grad=True)\n",
      "Epoch: 148400 y: tensor([[ 3.2093],\n",
      "        [ 5.1262],\n",
      "        [ 7.0430],\n",
      "        [ 8.9599],\n",
      "        [10.8767]], grad_fn=<AddBackward0>) cost: 0.015680810436606407 w: tensor([[0.8471],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2228], requires_grad=True)\n",
      "Epoch: 148800 y: tensor([[ 3.2093],\n",
      "        [ 5.1262],\n",
      "        [ 7.0431],\n",
      "        [ 8.9599],\n",
      "        [10.8768]], grad_fn=<AddBackward0>) cost: 0.015675976872444153 w: tensor([[0.8471],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2227], requires_grad=True)\n",
      "Epoch: 149200 y: tensor([[ 3.2093],\n",
      "        [ 5.1262],\n",
      "        [ 7.0431],\n",
      "        [ 8.9600],\n",
      "        [10.8769]], grad_fn=<AddBackward0>) cost: 0.01567111536860466 w: tensor([[0.8472],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2227], requires_grad=True)\n",
      "Epoch: 149600 y: tensor([[ 3.2093],\n",
      "        [ 5.1262],\n",
      "        [ 7.0431],\n",
      "        [ 8.9601],\n",
      "        [10.8770]], grad_fn=<AddBackward0>) cost: 0.015666291117668152 w: tensor([[0.8472],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2227], requires_grad=True)\n",
      "Epoch: 150000 y: tensor([[ 3.2093],\n",
      "        [ 5.1262],\n",
      "        [ 7.0432],\n",
      "        [ 8.9601],\n",
      "        [10.8771]], grad_fn=<AddBackward0>) cost: 0.015661438927054405 w: tensor([[0.8472],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2226], requires_grad=True)\n",
      "Epoch: 150400 y: tensor([[ 3.2093],\n",
      "        [ 5.1262],\n",
      "        [ 7.0432],\n",
      "        [ 8.9602],\n",
      "        [10.8771]], grad_fn=<AddBackward0>) cost: 0.015656623989343643 w: tensor([[0.8472],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2226], requires_grad=True)\n",
      "Epoch: 150800 y: tensor([[ 3.2093],\n",
      "        [ 5.1263],\n",
      "        [ 7.0432],\n",
      "        [ 8.9602],\n",
      "        [10.8772]], grad_fn=<AddBackward0>) cost: 0.015651782974600792 w: tensor([[0.8473],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2225], requires_grad=True)\n",
      "Epoch: 151200 y: tensor([[ 3.2093],\n",
      "        [ 5.1263],\n",
      "        [ 7.0433],\n",
      "        [ 8.9603],\n",
      "        [10.8773]], grad_fn=<AddBackward0>) cost: 0.015646979212760925 w: tensor([[0.8473],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2225], requires_grad=True)\n",
      "Epoch: 151600 y: tensor([[ 3.2092],\n",
      "        [ 5.1263],\n",
      "        [ 7.0433],\n",
      "        [ 8.9604],\n",
      "        [10.8774]], grad_fn=<AddBackward0>) cost: 0.01564214751124382 w: tensor([[0.8473],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2225], requires_grad=True)\n",
      "Epoch: 152000 y: tensor([[ 3.2092],\n",
      "        [ 5.1263],\n",
      "        [ 7.0434],\n",
      "        [ 8.9604],\n",
      "        [10.8775]], grad_fn=<AddBackward0>) cost: 0.01563735119998455 w: tensor([[0.8473],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2224], requires_grad=True)\n",
      "Epoch: 152400 y: tensor([[ 3.2092],\n",
      "        [ 5.1263],\n",
      "        [ 7.0434],\n",
      "        [ 8.9605],\n",
      "        [10.8776]], grad_fn=<AddBackward0>) cost: 0.01563253067433834 w: tensor([[0.8473],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2224], requires_grad=True)\n",
      "Epoch: 152800 y: tensor([[ 3.2092],\n",
      "        [ 5.1263],\n",
      "        [ 7.0434],\n",
      "        [ 8.9605],\n",
      "        [10.8776]], grad_fn=<AddBackward0>) cost: 0.015627743676304817 w: tensor([[0.8474],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2224], requires_grad=True)\n",
      "Epoch: 153200 y: tensor([[ 3.2092],\n",
      "        [ 5.1263],\n",
      "        [ 7.0435],\n",
      "        [ 8.9606],\n",
      "        [10.8777]], grad_fn=<AddBackward0>) cost: 0.015622931532561779 w: tensor([[0.8474],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2223], requires_grad=True)\n",
      "Epoch: 153600 y: tensor([[ 3.2092],\n",
      "        [ 5.1263],\n",
      "        [ 7.0435],\n",
      "        [ 8.9607],\n",
      "        [10.8778]], grad_fn=<AddBackward0>) cost: 0.015618154779076576 w: tensor([[0.8474],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2223], requires_grad=True)\n",
      "Epoch: 154000 y: tensor([[ 3.2092],\n",
      "        [ 5.1264],\n",
      "        [ 7.0435],\n",
      "        [ 8.9607],\n",
      "        [10.8779]], grad_fn=<AddBackward0>) cost: 0.015613351948559284 w: tensor([[0.8474],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2223], requires_grad=True)\n",
      "Epoch: 154400 y: tensor([[ 3.2092],\n",
      "        [ 5.1264],\n",
      "        [ 7.0436],\n",
      "        [ 8.9608],\n",
      "        [10.8780]], grad_fn=<AddBackward0>) cost: 0.015608586370944977 w: tensor([[0.8475],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2222], requires_grad=True)\n",
      "Epoch: 154800 y: tensor([[ 3.2091],\n",
      "        [ 5.1264],\n",
      "        [ 7.0436],\n",
      "        [ 8.9608],\n",
      "        [10.8781]], grad_fn=<AddBackward0>) cost: 0.015603792853653431 w: tensor([[0.8475],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2222], requires_grad=True)\n",
      "Epoch: 155200 y: tensor([[ 3.2091],\n",
      "        [ 5.1264],\n",
      "        [ 7.0436],\n",
      "        [ 8.9609],\n",
      "        [10.8781]], grad_fn=<AddBackward0>) cost: 0.01559903472661972 w: tensor([[0.8475],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2221], requires_grad=True)\n",
      "Epoch: 155600 y: tensor([[ 3.2091],\n",
      "        [ 5.1264],\n",
      "        [ 7.0437],\n",
      "        [ 8.9610],\n",
      "        [10.8782]], grad_fn=<AddBackward0>) cost: 0.015594251453876495 w: tensor([[0.8475],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2221], requires_grad=True)\n",
      "Epoch: 156000 y: tensor([[ 3.2091],\n",
      "        [ 5.1264],\n",
      "        [ 7.0437],\n",
      "        [ 8.9610],\n",
      "        [10.8783]], grad_fn=<AddBackward0>) cost: 0.015589505434036255 w: tensor([[0.8476],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2221], requires_grad=True)\n",
      "Epoch: 156400 y: tensor([[ 3.2091],\n",
      "        [ 5.1264],\n",
      "        [ 7.0437],\n",
      "        [ 8.9611],\n",
      "        [10.8784]], grad_fn=<AddBackward0>) cost: 0.015584729611873627 w: tensor([[0.8476],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2220], requires_grad=True)\n",
      "Epoch: 156800 y: tensor([[ 3.2091],\n",
      "        [ 5.1264],\n",
      "        [ 7.0438],\n",
      "        [ 8.9611],\n",
      "        [10.8785]], grad_fn=<AddBackward0>) cost: 0.015579992905259132 w: tensor([[0.8476],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2220], requires_grad=True)\n",
      "Epoch: 157200 y: tensor([[ 3.2091],\n",
      "        [ 5.1264],\n",
      "        [ 7.0438],\n",
      "        [ 8.9612],\n",
      "        [10.8786]], grad_fn=<AddBackward0>) cost: 0.015575230121612549 w: tensor([[0.8476],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2220], requires_grad=True)\n",
      "Epoch: 157600 y: tensor([[ 3.2091],\n",
      "        [ 5.1265],\n",
      "        [ 7.0439],\n",
      "        [ 8.9612],\n",
      "        [10.8786]], grad_fn=<AddBackward0>) cost: 0.015570501796901226 w: tensor([[0.8477],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2219], requires_grad=True)\n",
      "Epoch: 158000 y: tensor([[ 3.2091],\n",
      "        [ 5.1265],\n",
      "        [ 7.0439],\n",
      "        [ 8.9613],\n",
      "        [10.8787]], grad_fn=<AddBackward0>) cost: 0.015565747395157814 w: tensor([[0.8477],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2219], requires_grad=True)\n",
      "Epoch: 158400 y: tensor([[ 3.2090],\n",
      "        [ 5.1265],\n",
      "        [ 7.0439],\n",
      "        [ 8.9614],\n",
      "        [10.8788]], grad_fn=<AddBackward0>) cost: 0.015561027452349663 w: tensor([[0.8477],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2219], requires_grad=True)\n",
      "Epoch: 158800 y: tensor([[ 3.2090],\n",
      "        [ 5.1265],\n",
      "        [ 7.0440],\n",
      "        [ 8.9614],\n",
      "        [10.8789]], grad_fn=<AddBackward0>) cost: 0.015556283295154572 w: tensor([[0.8477],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2218], requires_grad=True)\n",
      "Epoch: 159200 y: tensor([[ 3.2090],\n",
      "        [ 5.1265],\n",
      "        [ 7.0440],\n",
      "        [ 8.9615],\n",
      "        [10.8790]], grad_fn=<AddBackward0>) cost: 0.015551576390862465 w: tensor([[0.8478],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2218], requires_grad=True)\n",
      "Epoch: 159600 y: tensor([[ 3.2090],\n",
      "        [ 5.1265],\n",
      "        [ 7.0440],\n",
      "        [ 8.9615],\n",
      "        [10.8791]], grad_fn=<AddBackward0>) cost: 0.015546840615570545 w: tensor([[0.8478],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2218], requires_grad=True)\n",
      "Epoch: 160000 y: tensor([[ 3.2090],\n",
      "        [ 5.1265],\n",
      "        [ 7.0441],\n",
      "        [ 8.9616],\n",
      "        [10.8791]], grad_fn=<AddBackward0>) cost: 0.01554214209318161 w: tensor([[0.8478],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2217], requires_grad=True)\n",
      "Epoch: 160400 y: tensor([[ 3.2090],\n",
      "        [ 5.1265],\n",
      "        [ 7.0441],\n",
      "        [ 8.9617],\n",
      "        [10.8792]], grad_fn=<AddBackward0>) cost: 0.015537415631115437 w: tensor([[0.8478],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2217], requires_grad=True)\n",
      "Epoch: 160800 y: tensor([[ 3.2090],\n",
      "        [ 5.1266],\n",
      "        [ 7.0441],\n",
      "        [ 8.9617],\n",
      "        [10.8793]], grad_fn=<AddBackward0>) cost: 0.015532727353274822 w: tensor([[0.8479],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2216], requires_grad=True)\n",
      "Epoch: 161200 y: tensor([[ 3.2090],\n",
      "        [ 5.1266],\n",
      "        [ 7.0442],\n",
      "        [ 8.9618],\n",
      "        [10.8794]], grad_fn=<AddBackward0>) cost: 0.01552801113575697 w: tensor([[0.8479],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2216], requires_grad=True)\n",
      "Epoch: 161600 y: tensor([[ 3.2089],\n",
      "        [ 5.1266],\n",
      "        [ 7.0442],\n",
      "        [ 8.9618],\n",
      "        [10.8795]], grad_fn=<AddBackward0>) cost: 0.015523331239819527 w: tensor([[0.8479],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2216], requires_grad=True)\n",
      "Epoch: 162000 y: tensor([[ 3.2089],\n",
      "        [ 5.1266],\n",
      "        [ 7.0442],\n",
      "        [ 8.9619],\n",
      "        [10.8796]], grad_fn=<AddBackward0>) cost: 0.01551862619817257 w: tensor([[0.8479],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2215], requires_grad=True)\n",
      "Epoch: 162400 y: tensor([[ 3.2089],\n",
      "        [ 5.1266],\n",
      "        [ 7.0443],\n",
      "        [ 8.9620],\n",
      "        [10.8796]], grad_fn=<AddBackward0>) cost: 0.015513954684138298 w: tensor([[0.8479],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2215], requires_grad=True)\n",
      "Epoch: 162800 y: tensor([[ 3.2089],\n",
      "        [ 5.1266],\n",
      "        [ 7.0443],\n",
      "        [ 8.9620],\n",
      "        [10.8797]], grad_fn=<AddBackward0>) cost: 0.015509258024394512 w: tensor([[0.8480],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2215], requires_grad=True)\n",
      "Epoch: 163200 y: tensor([[ 3.2089],\n",
      "        [ 5.1266],\n",
      "        [ 7.0444],\n",
      "        [ 8.9621],\n",
      "        [10.8798]], grad_fn=<AddBackward0>) cost: 0.015504596754908562 w: tensor([[0.8480],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2214], requires_grad=True)\n",
      "Epoch: 163600 y: tensor([[ 3.2089],\n",
      "        [ 5.1266],\n",
      "        [ 7.0444],\n",
      "        [ 8.9621],\n",
      "        [10.8799]], grad_fn=<AddBackward0>) cost: 0.015499910339713097 w: tensor([[0.8480],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2214], requires_grad=True)\n",
      "Epoch: 164000 y: tensor([[ 3.2089],\n",
      "        [ 5.1267],\n",
      "        [ 7.0444],\n",
      "        [ 8.9622],\n",
      "        [10.8800]], grad_fn=<AddBackward0>) cost: 0.015495261177420616 w: tensor([[0.8480],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2214], requires_grad=True)\n",
      "Epoch: 164400 y: tensor([[ 3.2089],\n",
      "        [ 5.1267],\n",
      "        [ 7.0445],\n",
      "        [ 8.9623],\n",
      "        [10.8801]], grad_fn=<AddBackward0>) cost: 0.015490584075450897 w: tensor([[0.8481],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2213], requires_grad=True)\n",
      "Epoch: 164800 y: tensor([[ 3.2089],\n",
      "        [ 5.1267],\n",
      "        [ 7.0445],\n",
      "        [ 8.9623],\n",
      "        [10.8801]], grad_fn=<AddBackward0>) cost: 0.015485942363739014 w: tensor([[0.8481],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2213], requires_grad=True)\n",
      "Epoch: 165200 y: tensor([[ 3.2088],\n",
      "        [ 5.1267],\n",
      "        [ 7.0445],\n",
      "        [ 8.9624],\n",
      "        [10.8802]], grad_fn=<AddBackward0>) cost: 0.01548127643764019 w: tensor([[0.8481],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2213], requires_grad=True)\n",
      "Epoch: 165600 y: tensor([[ 3.2088],\n",
      "        [ 5.1267],\n",
      "        [ 7.0446],\n",
      "        [ 8.9624],\n",
      "        [10.8803]], grad_fn=<AddBackward0>) cost: 0.015476644039154053 w: tensor([[0.8481],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2212], requires_grad=True)\n",
      "Epoch: 166000 y: tensor([[ 3.2088],\n",
      "        [ 5.1267],\n",
      "        [ 7.0446],\n",
      "        [ 8.9625],\n",
      "        [10.8804]], grad_fn=<AddBackward0>) cost: 0.015471987426280975 w: tensor([[0.8482],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2212], requires_grad=True)\n",
      "Epoch: 166400 y: tensor([[ 3.2088],\n",
      "        [ 5.1267],\n",
      "        [ 7.0446],\n",
      "        [ 8.9626],\n",
      "        [10.8805]], grad_fn=<AddBackward0>) cost: 0.015467366203665733 w: tensor([[0.8482],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2211], requires_grad=True)\n",
      "Epoch: 166800 y: tensor([[ 3.2088],\n",
      "        [ 5.1267],\n",
      "        [ 7.0447],\n",
      "        [ 8.9626],\n",
      "        [10.8806]], grad_fn=<AddBackward0>) cost: 0.015462718904018402 w: tensor([[0.8482],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2211], requires_grad=True)\n",
      "Epoch: 167200 y: tensor([[ 3.2088],\n",
      "        [ 5.1267],\n",
      "        [ 7.0447],\n",
      "        [ 8.9627],\n",
      "        [10.8806]], grad_fn=<AddBackward0>) cost: 0.015458105131983757 w: tensor([[0.8482],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2211], requires_grad=True)\n",
      "Epoch: 167600 y: tensor([[ 3.2088],\n",
      "        [ 5.1268],\n",
      "        [ 7.0447],\n",
      "        [ 8.9627],\n",
      "        [10.8807]], grad_fn=<AddBackward0>) cost: 0.015453468076884747 w: tensor([[0.8483],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2210], requires_grad=True)\n",
      "Epoch: 168000 y: tensor([[ 3.2088],\n",
      "        [ 5.1268],\n",
      "        [ 7.0448],\n",
      "        [ 8.9628],\n",
      "        [10.8808]], grad_fn=<AddBackward0>) cost: 0.015448863618075848 w: tensor([[0.8483],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2210], requires_grad=True)\n",
      "Epoch: 168400 y: tensor([[ 3.2087],\n",
      "        [ 5.1268],\n",
      "        [ 7.0448],\n",
      "        [ 8.9629],\n",
      "        [10.8809]], grad_fn=<AddBackward0>) cost: 0.015444235876202583 w: tensor([[0.8483],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2210], requires_grad=True)\n",
      "Epoch: 168800 y: tensor([[ 3.2087],\n",
      "        [ 5.1268],\n",
      "        [ 7.0449],\n",
      "        [ 8.9629],\n",
      "        [10.8810]], grad_fn=<AddBackward0>) cost: 0.01543964259326458 w: tensor([[0.8483],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2209], requires_grad=True)\n",
      "Epoch: 169200 y: tensor([[ 3.2087],\n",
      "        [ 5.1268],\n",
      "        [ 7.0449],\n",
      "        [ 8.9630],\n",
      "        [10.8811]], grad_fn=<AddBackward0>) cost: 0.015435023233294487 w: tensor([[0.8484],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2209], requires_grad=True)\n",
      "Epoch: 169600 y: tensor([[ 3.2087],\n",
      "        [ 5.1268],\n",
      "        [ 7.0449],\n",
      "        [ 8.9630],\n",
      "        [10.8811]], grad_fn=<AddBackward0>) cost: 0.015430440194904804 w: tensor([[0.8484],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2209], requires_grad=True)\n",
      "Epoch: 170000 y: tensor([[ 3.2087],\n",
      "        [ 5.1268],\n",
      "        [ 7.0450],\n",
      "        [ 8.9631],\n",
      "        [10.8812]], grad_fn=<AddBackward0>) cost: 0.015425832942128181 w: tensor([[0.8484],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2208], requires_grad=True)\n",
      "Epoch: 170400 y: tensor([[ 3.2087],\n",
      "        [ 5.1268],\n",
      "        [ 7.0450],\n",
      "        [ 8.9632],\n",
      "        [10.8813]], grad_fn=<AddBackward0>) cost: 0.015421259216964245 w: tensor([[0.8484],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2208], requires_grad=True)\n",
      "Epoch: 170800 y: tensor([[ 3.2087],\n",
      "        [ 5.1269],\n",
      "        [ 7.0450],\n",
      "        [ 8.9632],\n",
      "        [10.8814]], grad_fn=<AddBackward0>) cost: 0.015416659414768219 w: tensor([[0.8484],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2208], requires_grad=True)\n",
      "Epoch: 171200 y: tensor([[ 3.2087],\n",
      "        [ 5.1269],\n",
      "        [ 7.0451],\n",
      "        [ 8.9633],\n",
      "        [10.8815]], grad_fn=<AddBackward0>) cost: 0.015412095002830029 w: tensor([[0.8485],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2207], requires_grad=True)\n",
      "Epoch: 171600 y: tensor([[ 3.2086],\n",
      "        [ 5.1269],\n",
      "        [ 7.0451],\n",
      "        [ 8.9633],\n",
      "        [10.8816]], grad_fn=<AddBackward0>) cost: 0.015407504513859749 w: tensor([[0.8485],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2207], requires_grad=True)\n",
      "Epoch: 172000 y: tensor([[ 3.2086],\n",
      "        [ 5.1269],\n",
      "        [ 7.0451],\n",
      "        [ 8.9634],\n",
      "        [10.8816]], grad_fn=<AddBackward0>) cost: 0.01540295034646988 w: tensor([[0.8485],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2206], requires_grad=True)\n",
      "Epoch: 172400 y: tensor([[ 3.2086],\n",
      "        [ 5.1269],\n",
      "        [ 7.0452],\n",
      "        [ 8.9635],\n",
      "        [10.8817]], grad_fn=<AddBackward0>) cost: 0.01539837010204792 w: tensor([[0.8485],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2206], requires_grad=True)\n",
      "Epoch: 172800 y: tensor([[ 3.2086],\n",
      "        [ 5.1269],\n",
      "        [ 7.0452],\n",
      "        [ 8.9635],\n",
      "        [10.8818]], grad_fn=<AddBackward0>) cost: 0.015393826179206371 w: tensor([[0.8486],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2206], requires_grad=True)\n",
      "Epoch: 173200 y: tensor([[ 3.2086],\n",
      "        [ 5.1269],\n",
      "        [ 7.0452],\n",
      "        [ 8.9636],\n",
      "        [10.8819]], grad_fn=<AddBackward0>) cost: 0.015389256179332733 w: tensor([[0.8486],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2205], requires_grad=True)\n",
      "Epoch: 173600 y: tensor([[ 3.2086],\n",
      "        [ 5.1269],\n",
      "        [ 7.0453],\n",
      "        [ 8.9636],\n",
      "        [10.8820]], grad_fn=<AddBackward0>) cost: 0.015384720638394356 w: tensor([[0.8486],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2205], requires_grad=True)\n",
      "Epoch: 174000 y: tensor([[ 3.2086],\n",
      "        [ 5.1269],\n",
      "        [ 7.0453],\n",
      "        [ 8.9637],\n",
      "        [10.8821]], grad_fn=<AddBackward0>) cost: 0.01538015902042389 w: tensor([[0.8486],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2205], requires_grad=True)\n",
      "Epoch: 174400 y: tensor([[ 3.2086],\n",
      "        [ 5.1270],\n",
      "        [ 7.0454],\n",
      "        [ 8.9638],\n",
      "        [10.8821]], grad_fn=<AddBackward0>) cost: 0.015375634655356407 w: tensor([[0.8487],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2204], requires_grad=True)\n",
      "Epoch: 174800 y: tensor([[ 3.2086],\n",
      "        [ 5.1270],\n",
      "        [ 7.0454],\n",
      "        [ 8.9638],\n",
      "        [10.8822]], grad_fn=<AddBackward0>) cost: 0.015371082350611687 w: tensor([[0.8487],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2204], requires_grad=True)\n",
      "Epoch: 175200 y: tensor([[ 3.2085],\n",
      "        [ 5.1270],\n",
      "        [ 7.0454],\n",
      "        [ 8.9639],\n",
      "        [10.8823]], grad_fn=<AddBackward0>) cost: 0.01536656729876995 w: tensor([[0.8487],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2204], requires_grad=True)\n",
      "Epoch: 175600 y: tensor([[ 3.2085],\n",
      "        [ 5.1270],\n",
      "        [ 7.0455],\n",
      "        [ 8.9639],\n",
      "        [10.8824]], grad_fn=<AddBackward0>) cost: 0.015362026169896126 w: tensor([[0.8487],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2203], requires_grad=True)\n",
      "Epoch: 176000 y: tensor([[ 3.2085],\n",
      "        [ 5.1270],\n",
      "        [ 7.0455],\n",
      "        [ 8.9640],\n",
      "        [10.8825]], grad_fn=<AddBackward0>) cost: 0.015357519499957561 w: tensor([[0.8488],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2203], requires_grad=True)\n",
      "Epoch: 176400 y: tensor([[ 3.2085],\n",
      "        [ 5.1270],\n",
      "        [ 7.0455],\n",
      "        [ 8.9641],\n",
      "        [10.8826]], grad_fn=<AddBackward0>) cost: 0.015352988615632057 w: tensor([[0.8488],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2203], requires_grad=True)\n",
      "Epoch: 176800 y: tensor([[ 3.2085],\n",
      "        [ 5.1270],\n",
      "        [ 7.0456],\n",
      "        [ 8.9641],\n",
      "        [10.8826]], grad_fn=<AddBackward0>) cost: 0.01534848939627409 w: tensor([[0.8488],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2202], requires_grad=True)\n",
      "Epoch: 177200 y: tensor([[ 3.2085],\n",
      "        [ 5.1270],\n",
      "        [ 7.0456],\n",
      "        [ 8.9642],\n",
      "        [10.8827]], grad_fn=<AddBackward0>) cost: 0.015343969687819481 w: tensor([[0.8488],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2202], requires_grad=True)\n",
      "Epoch: 177600 y: tensor([[ 3.2085],\n",
      "        [ 5.1271],\n",
      "        [ 7.0456],\n",
      "        [ 8.9642],\n",
      "        [10.8828]], grad_fn=<AddBackward0>) cost: 0.015339483506977558 w: tensor([[0.8489],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2201], requires_grad=True)\n",
      "Epoch: 178000 y: tensor([[ 3.2085],\n",
      "        [ 5.1271],\n",
      "        [ 7.0457],\n",
      "        [ 8.9643],\n",
      "        [10.8829]], grad_fn=<AddBackward0>) cost: 0.015334969386458397 w: tensor([[0.8489],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2201], requires_grad=True)\n",
      "Epoch: 178400 y: tensor([[ 3.2084],\n",
      "        [ 5.1271],\n",
      "        [ 7.0457],\n",
      "        [ 8.9643],\n",
      "        [10.8830]], grad_fn=<AddBackward0>) cost: 0.015330495312809944 w: tensor([[0.8489],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2201], requires_grad=True)\n",
      "Epoch: 178800 y: tensor([[ 3.2084],\n",
      "        [ 5.1271],\n",
      "        [ 7.0457],\n",
      "        [ 8.9644],\n",
      "        [10.8831]], grad_fn=<AddBackward0>) cost: 0.015325990505516529 w: tensor([[0.8489],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2200], requires_grad=True)\n",
      "Epoch: 179200 y: tensor([[ 3.2084],\n",
      "        [ 5.1271],\n",
      "        [ 7.0458],\n",
      "        [ 8.9645],\n",
      "        [10.8831]], grad_fn=<AddBackward0>) cost: 0.015321522951126099 w: tensor([[0.8489],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2200], requires_grad=True)\n",
      "Epoch: 179600 y: tensor([[ 3.2084],\n",
      "        [ 5.1271],\n",
      "        [ 7.0458],\n",
      "        [ 8.9645],\n",
      "        [10.8832]], grad_fn=<AddBackward0>) cost: 0.015317028388381004 w: tensor([[0.8490],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2200], requires_grad=True)\n",
      "Epoch: 180000 y: tensor([[ 3.2084],\n",
      "        [ 5.1271],\n",
      "        [ 7.0459],\n",
      "        [ 8.9646],\n",
      "        [10.8833]], grad_fn=<AddBackward0>) cost: 0.01531257200986147 w: tensor([[0.8490],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2199], requires_grad=True)\n",
      "Epoch: 180400 y: tensor([[ 3.2084],\n",
      "        [ 5.1271],\n",
      "        [ 7.0459],\n",
      "        [ 8.9646],\n",
      "        [10.8834]], grad_fn=<AddBackward0>) cost: 0.015308087691664696 w: tensor([[0.8490],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2199], requires_grad=True)\n",
      "Epoch: 180800 y: tensor([[ 3.2084],\n",
      "        [ 5.1272],\n",
      "        [ 7.0459],\n",
      "        [ 8.9647],\n",
      "        [10.8835]], grad_fn=<AddBackward0>) cost: 0.015303641557693481 w: tensor([[0.8490],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2199], requires_grad=True)\n",
      "Epoch: 181200 y: tensor([[ 3.2084],\n",
      "        [ 5.1272],\n",
      "        [ 7.0460],\n",
      "        [ 8.9648],\n",
      "        [10.8836]], grad_fn=<AddBackward0>) cost: 0.015299166552722454 w: tensor([[0.8491],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2198], requires_grad=True)\n",
      "Epoch: 181600 y: tensor([[ 3.2083],\n",
      "        [ 5.1272],\n",
      "        [ 7.0460],\n",
      "        [ 8.9648],\n",
      "        [10.8836]], grad_fn=<AddBackward0>) cost: 0.015294728800654411 w: tensor([[0.8491],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2198], requires_grad=True)\n",
      "Epoch: 182000 y: tensor([[ 3.2083],\n",
      "        [ 5.1272],\n",
      "        [ 7.0460],\n",
      "        [ 8.9649],\n",
      "        [10.8837]], grad_fn=<AddBackward0>) cost: 0.01529026497155428 w: tensor([[0.8491],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2198], requires_grad=True)\n",
      "Epoch: 182400 y: tensor([[ 3.2083],\n",
      "        [ 5.1272],\n",
      "        [ 7.0461],\n",
      "        [ 8.9649],\n",
      "        [10.8838]], grad_fn=<AddBackward0>) cost: 0.015285836532711983 w: tensor([[0.8491],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2197], requires_grad=True)\n",
      "Epoch: 182800 y: tensor([[ 3.2083],\n",
      "        [ 5.1272],\n",
      "        [ 7.0461],\n",
      "        [ 8.9650],\n",
      "        [10.8839]], grad_fn=<AddBackward0>) cost: 0.015281381085515022 w: tensor([[0.8492],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2197], requires_grad=True)\n",
      "Epoch: 183200 y: tensor([[ 3.2083],\n",
      "        [ 5.1272],\n",
      "        [ 7.0461],\n",
      "        [ 8.9651],\n",
      "        [10.8840]], grad_fn=<AddBackward0>) cost: 0.015276962891221046 w: tensor([[0.8492],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2196], requires_grad=True)\n",
      "Epoch: 183600 y: tensor([[ 3.2083],\n",
      "        [ 5.1272],\n",
      "        [ 7.0462],\n",
      "        [ 8.9651],\n",
      "        [10.8841]], grad_fn=<AddBackward0>) cost: 0.015272515825927258 w: tensor([[0.8492],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2196], requires_grad=True)\n",
      "Epoch: 184000 y: tensor([[ 3.2083],\n",
      "        [ 5.1272],\n",
      "        [ 7.0462],\n",
      "        [ 8.9652],\n",
      "        [10.8842]], grad_fn=<AddBackward0>) cost: 0.015268106944859028 w: tensor([[0.8492],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2196], requires_grad=True)\n",
      "Epoch: 184400 y: tensor([[ 3.2083],\n",
      "        [ 5.1273],\n",
      "        [ 7.0463],\n",
      "        [ 8.9652],\n",
      "        [10.8842]], grad_fn=<AddBackward0>) cost: 0.015263671986758709 w: tensor([[0.8493],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2195], requires_grad=True)\n",
      "Epoch: 184800 y: tensor([[ 3.2083],\n",
      "        [ 5.1273],\n",
      "        [ 7.0463],\n",
      "        [ 8.9653],\n",
      "        [10.8843]], grad_fn=<AddBackward0>) cost: 0.0152592733502388 w: tensor([[0.8493],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2195], requires_grad=True)\n",
      "Epoch: 185200 y: tensor([[ 3.2082],\n",
      "        [ 5.1273],\n",
      "        [ 7.0463],\n",
      "        [ 8.9654],\n",
      "        [10.8844]], grad_fn=<AddBackward0>) cost: 0.015254847705364227 w: tensor([[0.8493],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2195], requires_grad=True)\n",
      "Epoch: 185600 y: tensor([[ 3.2082],\n",
      "        [ 5.1273],\n",
      "        [ 7.0464],\n",
      "        [ 8.9654],\n",
      "        [10.8845]], grad_fn=<AddBackward0>) cost: 0.01525045745074749 w: tensor([[0.8493],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2194], requires_grad=True)\n",
      "Epoch: 186000 y: tensor([[ 3.2082],\n",
      "        [ 5.1273],\n",
      "        [ 7.0464],\n",
      "        [ 8.9655],\n",
      "        [10.8846]], grad_fn=<AddBackward0>) cost: 0.015246041119098663 w: tensor([[0.8494],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2194], requires_grad=True)\n",
      "Epoch: 186400 y: tensor([[ 3.2082],\n",
      "        [ 5.1273],\n",
      "        [ 7.0464],\n",
      "        [ 8.9655],\n",
      "        [10.8847]], grad_fn=<AddBackward0>) cost: 0.015241662040352821 w: tensor([[0.8494],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2194], requires_grad=True)\n",
      "Epoch: 186800 y: tensor([[ 3.2082],\n",
      "        [ 5.1273],\n",
      "        [ 7.0465],\n",
      "        [ 8.9656],\n",
      "        [10.8847]], grad_fn=<AddBackward0>) cost: 0.015237255021929741 w: tensor([[0.8494],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2193], requires_grad=True)\n",
      "Epoch: 187200 y: tensor([[ 3.2082],\n",
      "        [ 5.1273],\n",
      "        [ 7.0465],\n",
      "        [ 8.9657],\n",
      "        [10.8848]], grad_fn=<AddBackward0>) cost: 0.015232885256409645 w: tensor([[0.8494],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2193], requires_grad=True)\n",
      "Epoch: 187600 y: tensor([[ 3.2082],\n",
      "        [ 5.1274],\n",
      "        [ 7.0465],\n",
      "        [ 8.9657],\n",
      "        [10.8849]], grad_fn=<AddBackward0>) cost: 0.01522848755121231 w: tensor([[0.8494],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2193], requires_grad=True)\n",
      "Epoch: 188000 y: tensor([[ 3.2082],\n",
      "        [ 5.1274],\n",
      "        [ 7.0466],\n",
      "        [ 8.9658],\n",
      "        [10.8850]], grad_fn=<AddBackward0>) cost: 0.015224126167595387 w: tensor([[0.8495],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2192], requires_grad=True)\n",
      "Epoch: 188400 y: tensor([[ 3.2081],\n",
      "        [ 5.1274],\n",
      "        [ 7.0466],\n",
      "        [ 8.9658],\n",
      "        [10.8851]], grad_fn=<AddBackward0>) cost: 0.015219740569591522 w: tensor([[0.8495],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2192], requires_grad=True)\n",
      "Epoch: 188800 y: tensor([[ 3.2081],\n",
      "        [ 5.1274],\n",
      "        [ 7.0466],\n",
      "        [ 8.9659],\n",
      "        [10.8852]], grad_fn=<AddBackward0>) cost: 0.01521538756787777 w: tensor([[0.8495],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2191], requires_grad=True)\n",
      "Epoch: 189200 y: tensor([[ 3.2081],\n",
      "        [ 5.1274],\n",
      "        [ 7.0467],\n",
      "        [ 8.9660],\n",
      "        [10.8852]], grad_fn=<AddBackward0>) cost: 0.015211011283099651 w: tensor([[0.8495],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2191], requires_grad=True)\n",
      "Epoch: 189600 y: tensor([[ 3.2081],\n",
      "        [ 5.1274],\n",
      "        [ 7.0467],\n",
      "        [ 8.9660],\n",
      "        [10.8853]], grad_fn=<AddBackward0>) cost: 0.015206669457256794 w: tensor([[0.8496],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2191], requires_grad=True)\n",
      "Epoch: 190000 y: tensor([[ 3.2081],\n",
      "        [ 5.1274],\n",
      "        [ 7.0468],\n",
      "        [ 8.9661],\n",
      "        [10.8854]], grad_fn=<AddBackward0>) cost: 0.015202301554381847 w: tensor([[0.8496],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2190], requires_grad=True)\n",
      "Epoch: 190400 y: tensor([[ 3.2081],\n",
      "        [ 5.1274],\n",
      "        [ 7.0468],\n",
      "        [ 8.9661],\n",
      "        [10.8855]], grad_fn=<AddBackward0>) cost: 0.015197968110442162 w: tensor([[0.8496],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2190], requires_grad=True)\n",
      "Epoch: 190800 y: tensor([[ 3.2081],\n",
      "        [ 5.1274],\n",
      "        [ 7.0468],\n",
      "        [ 8.9662],\n",
      "        [10.8856]], grad_fn=<AddBackward0>) cost: 0.01519361138343811 w: tensor([[0.8496],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2190], requires_grad=True)\n",
      "Epoch: 191200 y: tensor([[ 3.2081],\n",
      "        [ 5.1275],\n",
      "        [ 7.0469],\n",
      "        [ 8.9663],\n",
      "        [10.8857]], grad_fn=<AddBackward0>) cost: 0.015189290046691895 w: tensor([[0.8497],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2189], requires_grad=True)\n",
      "Epoch: 191600 y: tensor([[ 3.2081],\n",
      "        [ 5.1275],\n",
      "        [ 7.0469],\n",
      "        [ 8.9663],\n",
      "        [10.8857]], grad_fn=<AddBackward0>) cost: 0.015184941701591015 w: tensor([[0.8497],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2189], requires_grad=True)\n",
      "Epoch: 192000 y: tensor([[ 3.2080],\n",
      "        [ 5.1275],\n",
      "        [ 7.0469],\n",
      "        [ 8.9664],\n",
      "        [10.8858]], grad_fn=<AddBackward0>) cost: 0.015180627815425396 w: tensor([[0.8497],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2189], requires_grad=True)\n",
      "Epoch: 192400 y: tensor([[ 3.2080],\n",
      "        [ 5.1275],\n",
      "        [ 7.0470],\n",
      "        [ 8.9664],\n",
      "        [10.8859]], grad_fn=<AddBackward0>) cost: 0.015176291577517986 w: tensor([[0.8497],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2188], requires_grad=True)\n",
      "Epoch: 192800 y: tensor([[ 3.2080],\n",
      "        [ 5.1275],\n",
      "        [ 7.0470],\n",
      "        [ 8.9665],\n",
      "        [10.8860]], grad_fn=<AddBackward0>) cost: 0.015171987004578114 w: tensor([[0.8498],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2188], requires_grad=True)\n",
      "Epoch: 193200 y: tensor([[ 3.2080],\n",
      "        [ 5.1275],\n",
      "        [ 7.0470],\n",
      "        [ 8.9666],\n",
      "        [10.8861]], grad_fn=<AddBackward0>) cost: 0.0151676582172513 w: tensor([[0.8498],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2188], requires_grad=True)\n",
      "Epoch: 193600 y: tensor([[ 3.2080],\n",
      "        [ 5.1275],\n",
      "        [ 7.0471],\n",
      "        [ 8.9666],\n",
      "        [10.8862]], grad_fn=<AddBackward0>) cost: 0.015163364820182323 w: tensor([[0.8498],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2187], requires_grad=True)\n",
      "Epoch: 194000 y: tensor([[ 3.2080],\n",
      "        [ 5.1275],\n",
      "        [ 7.0471],\n",
      "        [ 8.9667],\n",
      "        [10.8862]], grad_fn=<AddBackward0>) cost: 0.015159045346081257 w: tensor([[0.8498],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2187], requires_grad=True)\n",
      "Epoch: 194400 y: tensor([[ 3.2080],\n",
      "        [ 5.1276],\n",
      "        [ 7.0471],\n",
      "        [ 8.9667],\n",
      "        [10.8863]], grad_fn=<AddBackward0>) cost: 0.0151547621935606 w: tensor([[0.8499],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2186], requires_grad=True)\n",
      "Epoch: 194800 y: tensor([[ 3.2080],\n",
      "        [ 5.1276],\n",
      "        [ 7.0472],\n",
      "        [ 8.9668],\n",
      "        [10.8864]], grad_fn=<AddBackward0>) cost: 0.01515045203268528 w: tensor([[0.8499],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2186], requires_grad=True)\n",
      "Epoch: 195200 y: tensor([[ 3.2079],\n",
      "        [ 5.1276],\n",
      "        [ 7.0472],\n",
      "        [ 8.9669],\n",
      "        [10.8865]], grad_fn=<AddBackward0>) cost: 0.015146179124712944 w: tensor([[0.8499],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2186], requires_grad=True)\n",
      "Epoch: 195600 y: tensor([[ 3.2079],\n",
      "        [ 5.1276],\n",
      "        [ 7.0473],\n",
      "        [ 8.9669],\n",
      "        [10.8866]], grad_fn=<AddBackward0>) cost: 0.015141879208385944 w: tensor([[0.8499],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2185], requires_grad=True)\n",
      "Epoch: 196000 y: tensor([[ 3.2079],\n",
      "        [ 5.1276],\n",
      "        [ 7.0473],\n",
      "        [ 8.9670],\n",
      "        [10.8867]], grad_fn=<AddBackward0>) cost: 0.01513761468231678 w: tensor([[0.8499],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2185], requires_grad=True)\n",
      "Epoch: 196400 y: tensor([[ 3.2079],\n",
      "        [ 5.1276],\n",
      "        [ 7.0473],\n",
      "        [ 8.9670],\n",
      "        [10.8867]], grad_fn=<AddBackward0>) cost: 0.015133324079215527 w: tensor([[0.8500],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2185], requires_grad=True)\n",
      "Epoch: 196800 y: tensor([[ 3.2079],\n",
      "        [ 5.1276],\n",
      "        [ 7.0474],\n",
      "        [ 8.9671],\n",
      "        [10.8868]], grad_fn=<AddBackward0>) cost: 0.015129068866372108 w: tensor([[0.8500],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2184], requires_grad=True)\n",
      "Epoch: 197200 y: tensor([[ 3.2079],\n",
      "        [ 5.1276],\n",
      "        [ 7.0474],\n",
      "        [ 8.9671],\n",
      "        [10.8869]], grad_fn=<AddBackward0>) cost: 0.015124788507819176 w: tensor([[0.8500],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2184], requires_grad=True)\n",
      "Epoch: 197600 y: tensor([[ 3.2079],\n",
      "        [ 5.1277],\n",
      "        [ 7.0474],\n",
      "        [ 8.9672],\n",
      "        [10.8870]], grad_fn=<AddBackward0>) cost: 0.01512054167687893 w: tensor([[0.8500],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2184], requires_grad=True)\n",
      "Epoch: 198000 y: tensor([[ 3.2079],\n",
      "        [ 5.1277],\n",
      "        [ 7.0475],\n",
      "        [ 8.9673],\n",
      "        [10.8871]], grad_fn=<AddBackward0>) cost: 0.015116271562874317 w: tensor([[0.8501],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2183], requires_grad=True)\n",
      "Epoch: 198400 y: tensor([[ 3.2078],\n",
      "        [ 5.1277],\n",
      "        [ 7.0475],\n",
      "        [ 8.9673],\n",
      "        [10.8872]], grad_fn=<AddBackward0>) cost: 0.015112037770450115 w: tensor([[0.8501],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2183], requires_grad=True)\n",
      "Epoch: 198800 y: tensor([[ 3.2078],\n",
      "        [ 5.1277],\n",
      "        [ 7.0475],\n",
      "        [ 8.9674],\n",
      "        [10.8872]], grad_fn=<AddBackward0>) cost: 0.015107656829059124 w: tensor([[0.8501],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2183], requires_grad=True)\n",
      "Epoch: 199200 y: tensor([[ 3.2078],\n",
      "        [ 5.1277],\n",
      "        [ 7.0475],\n",
      "        [ 8.9674],\n",
      "        [10.8872]], grad_fn=<AddBackward0>) cost: 0.015102749690413475 w: tensor([[0.8501],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2182], requires_grad=True)\n",
      "Epoch: 199600 y: tensor([[ 3.2078],\n",
      "        [ 5.1276],\n",
      "        [ 7.0475],\n",
      "        [ 8.9674],\n",
      "        [10.8873]], grad_fn=<AddBackward0>) cost: 0.01509789377450943 w: tensor([[0.8502],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2182], requires_grad=True)\n",
      "Epoch: 200000 y: tensor([[ 3.2077],\n",
      "        [ 5.1276],\n",
      "        [ 7.0475],\n",
      "        [ 8.9674],\n",
      "        [10.8873]], grad_fn=<AddBackward0>) cost: 0.015093001537024975 w: tensor([[0.8502],\n",
      "        [1.0697]], requires_grad=True) b: tensor([0.2181], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer=optim.SGD([w,b], lr=1e-6)\n",
    "epochs=200001\n",
    "for epoch in range(epochs):\n",
    "    y=x_data2.matmul(w)+b\n",
    "    cost=torch.mean((t_data2-y)**2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%400==0:\n",
    "        print('Epoch:',epoch, 'y:',y, 'cost:',cost.item(),'w:',w, 'b:',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 93  88  93]\n",
      " [ 89  91  90]\n",
      " [ 96  98 100]\n",
      " [ 73  66  70]\n",
      " [ 53  46  55]\n",
      " [ 69  74  77]\n",
      " [ 47  56  60]\n",
      " [ 87  79  90]\n",
      " [ 79  70  88]\n",
      " [ 69  70  73]\n",
      " [ 70  65  74]\n",
      " [ 93  95  91]\n",
      " [ 79  80  73]\n",
      " [ 70  73  78]\n",
      " [ 93  89  96]\n",
      " [ 78  75  68]\n",
      " [ 81  90  93]\n",
      " [ 88  92  86]\n",
      " [ 78  83  77]\n",
      " [ 82  86  90]\n",
      " [ 86  82  89]\n",
      " [ 78  83  85]\n",
      " [ 76  83  71]\n",
      " [ 96  93  95]]\n",
      "[[185]\n",
      " [180]\n",
      " [196]\n",
      " [142]\n",
      " [101]\n",
      " [149]\n",
      " [115]\n",
      " [175]\n",
      " [164]\n",
      " [141]\n",
      " [141]\n",
      " [184]\n",
      " [152]\n",
      " [148]\n",
      " [192]\n",
      " [147]\n",
      " [183]\n",
      " [177]\n",
      " [159]\n",
      " [177]\n",
      " [175]\n",
      " [175]\n",
      " [149]\n",
      " [192]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('data/data-01-test-score.csv')\n",
    "data=np.array(df.values)\n",
    "x_data=data[:,:3].reshape(-1, 3)\n",
    "t_data=data[:,-1].reshape(-1, 1)\n",
    "print(x_data)\n",
    "print(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 93.,  88.,  93.],\n",
      "        [ 89.,  91.,  90.],\n",
      "        [ 96.,  98., 100.],\n",
      "        [ 73.,  66.,  70.],\n",
      "        [ 53.,  46.,  55.],\n",
      "        [ 69.,  74.,  77.],\n",
      "        [ 47.,  56.,  60.],\n",
      "        [ 87.,  79.,  90.],\n",
      "        [ 79.,  70.,  88.],\n",
      "        [ 69.,  70.,  73.],\n",
      "        [ 70.,  65.,  74.],\n",
      "        [ 93.,  95.,  91.],\n",
      "        [ 79.,  80.,  73.],\n",
      "        [ 70.,  73.,  78.],\n",
      "        [ 93.,  89.,  96.],\n",
      "        [ 78.,  75.,  68.],\n",
      "        [ 81.,  90.,  93.],\n",
      "        [ 88.,  92.,  86.],\n",
      "        [ 78.,  83.,  77.],\n",
      "        [ 82.,  86.,  90.],\n",
      "        [ 86.,  82.,  89.],\n",
      "        [ 78.,  83.,  85.],\n",
      "        [ 76.,  83.,  71.],\n",
      "        [ 96.,  93.,  95.]])\n",
      "tensor([[185.],\n",
      "        [180.],\n",
      "        [196.],\n",
      "        [142.],\n",
      "        [101.],\n",
      "        [149.],\n",
      "        [115.],\n",
      "        [175.],\n",
      "        [164.],\n",
      "        [141.],\n",
      "        [141.],\n",
      "        [184.],\n",
      "        [152.],\n",
      "        [148.],\n",
      "        [192.],\n",
      "        [147.],\n",
      "        [183.],\n",
      "        [177.],\n",
      "        [159.],\n",
      "        [177.],\n",
      "        [175.],\n",
      "        [175.],\n",
      "        [149.],\n",
      "        [192.]])\n"
     ]
    }
   ],
   "source": [
    "x_data3=torch.from_numpy(x_data).float()\n",
    "t_data3=torch.from_numpy(t_data).float()\n",
    "print(x_data3)\n",
    "print(t_data3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], requires_grad=True)\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w=torch.zeros((3,1), requires_grad=True)\n",
    "b=torch.zeros(1, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 cost: 26966.458984375 w: tensor([[0.0263],\n",
      "        [0.0264],\n",
      "        [0.0271]], requires_grad=True) b: 0.0003249166766181588\n",
      "epoch: 1000 cost: 11.63180160522461 w: tensor([[0.6597],\n",
      "        [0.6613],\n",
      "        [0.7047]], requires_grad=True) b: 0.0082217026501894\n",
      "epoch: 2000 cost: 11.230006217956543 w: tensor([[0.6512],\n",
      "        [0.6531],\n",
      "        [0.7209]], requires_grad=True) b: 0.00818737130612135\n",
      "epoch: 3000 cost: 10.859905242919922 w: tensor([[0.6430],\n",
      "        [0.6453],\n",
      "        [0.7365]], requires_grad=True) b: 0.008147812448441982\n",
      "epoch: 4000 cost: 10.518826484680176 w: tensor([[0.6350],\n",
      "        [0.6380],\n",
      "        [0.7514]], requires_grad=True) b: 0.008103235624730587\n",
      "epoch: 5000 cost: 10.20454216003418 w: tensor([[0.6273],\n",
      "        [0.6310],\n",
      "        [0.7658]], requires_grad=True) b: 0.008053780533373356\n",
      "epoch: 6000 cost: 9.915019989013672 w: tensor([[0.6197],\n",
      "        [0.6244],\n",
      "        [0.7795]], requires_grad=True) b: 0.007999715395271778\n",
      "epoch: 7000 cost: 9.647990226745605 w: tensor([[0.6124],\n",
      "        [0.6182],\n",
      "        [0.7927]], requires_grad=True) b: 0.007941234856843948\n",
      "epoch: 8000 cost: 9.401676177978516 w: tensor([[0.6053],\n",
      "        [0.6123],\n",
      "        [0.8054]], requires_grad=True) b: 0.007878516800701618\n",
      "epoch: 9000 cost: 9.174539566040039 w: tensor([[0.5984],\n",
      "        [0.6067],\n",
      "        [0.8175]], requires_grad=True) b: 0.007811655290424824\n",
      "epoch: 10000 cost: 8.965060234069824 w: tensor([[0.5916],\n",
      "        [0.6014],\n",
      "        [0.8292]], requires_grad=True) b: 0.007740949746221304\n",
      "epoch: 11000 cost: 8.771721839904785 w: tensor([[0.5851],\n",
      "        [0.5964],\n",
      "        [0.8404]], requires_grad=True) b: 0.007666361518204212\n",
      "epoch: 12000 cost: 8.593199729919434 w: tensor([[0.5788],\n",
      "        [0.5917],\n",
      "        [0.8512]], requires_grad=True) b: 0.007588227279484272\n",
      "epoch: 13000 cost: 8.428305625915527 w: tensor([[0.5726],\n",
      "        [0.5872],\n",
      "        [0.8615]], requires_grad=True) b: 0.0075066969729959965\n",
      "epoch: 14000 cost: 8.276079177856445 w: tensor([[0.5666],\n",
      "        [0.5830],\n",
      "        [0.8714]], requires_grad=True) b: 0.007421871181577444\n",
      "epoch: 15000 cost: 8.13548469543457 w: tensor([[0.5608],\n",
      "        [0.5791],\n",
      "        [0.8810]], requires_grad=True) b: 0.007333745248615742\n",
      "epoch: 16000 cost: 8.005546569824219 w: tensor([[0.5551],\n",
      "        [0.5753],\n",
      "        [0.8901]], requires_grad=True) b: 0.007242530584335327\n",
      "epoch: 17000 cost: 7.885392665863037 w: tensor([[0.5496],\n",
      "        [0.5718],\n",
      "        [0.8989]], requires_grad=True) b: 0.00714844511821866\n",
      "epoch: 18000 cost: 7.774258136749268 w: tensor([[0.5442],\n",
      "        [0.5685],\n",
      "        [0.9073]], requires_grad=True) b: 0.007051556836813688\n",
      "epoch: 19000 cost: 7.6714959144592285 w: tensor([[0.5390],\n",
      "        [0.5654],\n",
      "        [0.9155]], requires_grad=True) b: 0.0069519574753940105\n",
      "epoch: 20000 cost: 7.5764479637146 w: tensor([[0.5340],\n",
      "        [0.5624],\n",
      "        [0.9232]], requires_grad=True) b: 0.006849747151136398\n"
     ]
    }
   ],
   "source": [
    "cost_list=[]\n",
    "optimizer=optim.SGD([w,b], lr=1e-6)\n",
    "epochs=20001\n",
    "for epoch in range(epochs):\n",
    "    y=x_data3.matmul(w)+b\n",
    "\n",
    "    cost=torch.mean((y-t_data3)**2)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%1000==0:\n",
    "        cost_list.append([epoch, cost.item()])\n",
    "        print('epoch:',epoch, 'cost:', cost.item(), 'w:',w, 'b:',b.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27643b41c50>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "costs=np.array(cost_list).T\n",
    "plt.plot(costs[0],costs[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
